{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Self-Supervised CMSF-KM tests.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyikNXbYxhq6","executionInfo":{"status":"ok","timestamp":1650695137792,"user_tz":420,"elapsed":12,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"fc206d14-671c-456d-ec9e-77955315474e"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}],"source":["#GPU runtime required, should give CUDA version\n","!nvcc --version"]},{"cell_type":"code","source":["!pip install faiss-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFauSYcBymkd","executionInfo":{"status":"ok","timestamp":1650695149254,"user_tz":420,"elapsed":11467,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"86b16559-8880-433c-ba27-9edd72b13640"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 84 kB/s \n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}]},{"cell_type":"code","source":["import faiss\n","import torch\n","import cv2\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"sbLSB0x9ypbr","executionInfo":{"status":"ok","timestamp":1650695156008,"user_tz":420,"elapsed":6762,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SA5CzMz1tAp","executionInfo":{"status":"ok","timestamp":1650695174554,"user_tz":420,"elapsed":18550,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"9d7195a1-78a8-48d0-b1d4-f1709fcd74fb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!cp -r /content/gdrive/MyDrive/Explainable_Wound_Classification/CMSF/self_supervised/* /content"],"metadata":{"id":"lu1Z3VWPP2fk","executionInfo":{"status":"ok","timestamp":1650695178913,"user_tz":420,"elapsed":4369,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!python train_msf_km.py \\\n","  --cos \\\n","  --weak_strong \\\n","  --learning_rate 0.05 \\\n","  --batch_size 32 \\\n","  --num_workers 2 \\\n","  --epochs 200 \\\n","  --print_freq 10 \\\n","  --arch resnet50 \\\n","  --topk 5 \\\n","  --momentum 0.99 \\\n","  --mem_bank_size 128000 \\\n","  --num_clusters 4 \\\n","  --checkpoint_path /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output \\\n","  /content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5hVP2qRyuZ5","executionInfo":{"status":"ok","timestamp":1650696101391,"user_tz":420,"elapsed":897067,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"da07c2a4-a81f-4173-8fb6-47681b4e8093"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/train_msf_km.py\n","import builtins\n","import os\n","import sys\n","import time\n","import argparse\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torchvision import transforms, datasets\n","\n","from PIL import ImageFilter\n","from util import adjust_learning_rate, AverageMeter, subset_classes\n","import models.resnet as resnet\n","from tools import get_logger\n","\n","import pdb\n","import faiss\n","\n","\n","def parse_option():\n","\n","    parser = argparse.ArgumentParser('argument for training')\n","\n","    parser.add_argument('data', type=str, help='path to dataset')\n","    parser.add_argument('--dataset', type=str, default='imagenet',\n","                        choices=['imagenet', 'imagenet100'],\n","                        help='use full or subset of the dataset')\n","    parser.add_argument('--debug', action='store_true', help='whether in debug mode or not')\n","\n","    parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n","    parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n","    parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n","    parser.add_argument('--num_workers', type=int, default=24, help='num of workers to use')\n","    parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n","\n","    # optimization\n","    parser.add_argument('--learning_rate', type=float, default=0.01, help='learning rate')\n","    parser.add_argument('--lr_decay_epochs', type=str, default='90,120', help='where to decay lr, can be a list')\n","    parser.add_argument('--lr_decay_rate', type=float, default=0.2, help='decay rate for learning rate')\n","    parser.add_argument('--cos', action='store_true',\n","                        help='whether to cosine learning rate or not')\n","    parser.add_argument('--weight_decay', type=float, default=1e-4, help='weight decay')\n","    parser.add_argument('--sgd_momentum', type=float, default=0.9, help='SGD momentum')\n","\n","    # model definition\n","    parser.add_argument('--arch', type=str, default='alexnet',\n","                        choices=['alexnet', 'resnet18', 'resnet50', 'mobilenet'])\n","\n","    # Mean Shift\n","    parser.add_argument('--momentum', type=float, default=0.99)\n","    parser.add_argument('--mem_bank_size', type=int, default=128000)\n","    parser.add_argument('--topk', type=int, default=5)\n","    parser.add_argument('--num_clusters', type=int, default=50000)\n","    parser.add_argument('--weak_strong', action='store_true',\n","                        help='whether to strong/strong or weak/strong augmentation')\n","\n","    parser.add_argument('--weights', type=str, help='weights to initialize the model from')\n","    parser.add_argument('--resume', default='', type=str,\n","                        help='path to latest checkpoint (default: none)')\n","\n","    # GPU setting\n","    parser.add_argument('--gpu', default=None, type=int, help='GPU id to use.')\n","\n","    parser.add_argument('--checkpoint_path', default='output/mean_shift_default', type=str,\n","                        help='where to save checkpoints. ')\n","\n","    opt = parser.parse_args()\n","\n","    iterations = opt.lr_decay_epochs.split(',')\n","    opt.lr_decay_epochs = list([])\n","    for it in iterations:\n","        opt.lr_decay_epochs.append(int(it))\n","\n","    return opt\n","\n","\n","# Extended version of ImageFolder to return index of image too.\n","class ImageFolderEx(datasets.ImageFolder):\n","    def __getitem__(self, index):\n","        sample, target = super(ImageFolderEx, self).__getitem__(index)\n","        return index, sample, target\n","\n","\n","def get_mlp(inp_dim, hidden_dim, out_dim):\n","    mlp = nn.Sequential(\n","        nn.Linear(inp_dim, hidden_dim),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.ReLU(inplace=True),\n","        nn.Linear(hidden_dim, out_dim),\n","    )\n","    return mlp\n","\n","\n","def faiss_kmeans(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    d = feats.shape[-1]\n","    clus = faiss.Clustering(d, nmb_clusters)\n","    clus.niter = 20\n","    clus.max_points_per_centroid = 10000000\n","\n","    index = faiss.IndexFlatL2(d)\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    index = faiss.index_cpu_to_all_gpus(index, co)\n","\n","    # perform the training\n","    clus.train(feats, index)\n","    _, train_a = index.search(feats, 1)\n","\n","    return list(train_a[:, 0])\n","\n","\n","class ConstrainedMeanShiftKM(nn.Module):\n","    def __init__(self, arch, m=0.99, mem_bank_size=128000, topk=5, dataset_size=100, num_clusters=50000):\n","        super(ConstrainedMeanShiftKM, self).__init__()\n","\n","        # save parameters\n","        self.m = m\n","        self.mem_bank_size = mem_bank_size\n","        self.topk = topk\n","        self.dataset_size = dataset_size\n","        self.num_clusters = num_clusters\n","\n","        # create encoders and projection layers\n","        # both encoders should have same arch\n","        if 'resnet' in arch:\n","            self.encoder_q = resnet.__dict__[arch]()\n","            self.encoder_t = resnet.__dict__[arch]()\n","\n","        # save output embedding dimensions\n","        # assuming that both encoders have same dim\n","        feat_dim = self.encoder_q.fc.in_features\n","        hidden_dim = feat_dim * 2\n","        proj_dim = feat_dim // 4\n","\n","        # projection layers\n","        self.encoder_t.fc = get_mlp(feat_dim, hidden_dim, proj_dim)\n","        self.encoder_q.fc = get_mlp(feat_dim, hidden_dim, proj_dim)\n","\n","        # prediction layer\n","        self.predict_q = get_mlp(proj_dim, hidden_dim, proj_dim)\n","\n","        # copy query encoder weights to target encoder\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data.copy_(param_q.data)\n","            param_t.requires_grad = False\n","\n","        print(\"using mem-bank size {}\".format(self.mem_bank_size))\n","        # setup queue (For Storing Random Targets)\n","        self.register_buffer('queue', torch.randn(self.mem_bank_size, proj_dim))\n","        self.register_buffer('pool', torch.randn(self.dataset_size, proj_dim))\n","        self.register_buffer('pseudo_labels', 0*torch.ones(self.dataset_size).long())\n","        # normalize the queue embeddings\n","        self.queue = nn.functional.normalize(self.queue, dim=1)\n","        # initialize the labels queue (For Purity measurement)\n","        self.register_buffer('labels', -1*torch.ones(self.mem_bank_size).long())\n","        self.register_buffer('index_queue', -1 * torch.ones(self.mem_bank_size).long())\n","        # setup the queue pointer\n","        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n","\n","    @torch.no_grad()\n","    def _momentum_update_target_encoder(self):\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data = param_t.data * self.m + param_q.data * (1. - self.m)\n","\n","    @torch.no_grad()\n","    def data_parallel(self):\n","        self.encoder_q = torch.nn.DataParallel(self.encoder_q)\n","        self.encoder_t = torch.nn.DataParallel(self.encoder_t)\n","        self.predict_q = torch.nn.DataParallel(self.predict_q)\n","\n","    @torch.no_grad()\n","    def cluster(self):\n","        print('start clustering ... num clusters: {}'.format(self.num_clusters))\n","        cluster_assignment = faiss_kmeans(self.pool.clone().cpu(), self.num_clusters)\n","        self.pseudo_labels = torch.tensor(cluster_assignment).cuda()\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue(self, targets, labels, indices):\n","        batch_size = targets.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","        assert self.mem_bank_size % batch_size == 0 \n","\n","        # replace the targets at ptr (dequeue and enqueue)\n","        self.pool[indices, :] = targets\n","        self.queue[ptr:ptr + batch_size] = targets\n","        self.labels[ptr:ptr + batch_size] = labels\n","        self.index_queue[ptr:ptr + batch_size] = indices\n","        ptr = (ptr + batch_size) % self.mem_bank_size  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","    def forward(self, im_q, im_t, labels, indices):\n","        # compute query features\n","        feat_q = self.encoder_q(im_q)\n","        # compute predictions for instance level regression loss\n","        query = self.predict_q(feat_q)\n","        query = nn.functional.normalize(query, dim=1)\n","\n","        # compute target features\n","        with torch.no_grad():\n","            # update the target encoder\n","            self._momentum_update_target_encoder()\n","\n","            # shuffle targets\n","            shuffle_ids, reverse_ids = get_shuffle_ids(im_t.shape[0])\n","            im_t = im_t[shuffle_ids]\n","\n","            # forward through the target encoder\n","            current_target = self.encoder_t(im_t)\n","            current_target = nn.functional.normalize(current_target, dim=1)\n","\n","            # undo shuffle\n","            current_target = current_target[reverse_ids].detach()\n","\n","            # update the memory-bank\n","            self._dequeue_and_enqueue(current_target, labels, indices)\n","\n","        targets = self.queue.clone().detach()\n","\n","        # get pseudo of target and memory bank samples\n","        current_target_pseudo_labels = self.pseudo_labels[indices]\n","        targets_pseudo_labels = self.pseudo_labels[self.index_queue]\n","\n","        # create a mask to constrain the search space\n","        b = current_target_pseudo_labels.shape[0]\n","        m = targets_pseudo_labels.shape[0]\n","        lx = current_target_pseudo_labels.unsqueeze(1).expand((b, m))\n","        lm = targets_pseudo_labels.unsqueeze(0).expand((b, m))\n","        msk = lx != lm\n","\n","        # calculate distances between vectors\n","        dist_t = 2 - 2 * torch.einsum('bc,kc->bk', [current_target, targets])\n","        dist_q = 2 - 2 * torch.einsum('bc,kc->bk', [query, targets])\n","\n","        # select the k nearest neighbors [with smallest distance (largest=False)] based on current target\n","        _, unconstrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # select the k nearest neighbors based on constrained memory bank\n","        dist_t[torch.where(msk)] = 5.0\n","        _, constrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # calculate mean shift regression loss\n","        nn_dist_q_constrained = torch.gather(dist_q, 1, constrained_nn_index)\n","        nn_dist_q_unconstrained = torch.gather(dist_q, 1, unconstrained_nn_index)\n","\n","        # purity based on memory bank\n","        labels = labels.unsqueeze(1).expand(nn_dist_q_unconstrained.shape[0], nn_dist_q_unconstrained.shape[1])\n","        labels_queue = self.labels.clone().detach()\n","        labels_queue = labels_queue.unsqueeze(0).expand((nn_dist_q_unconstrained.shape[0], self.mem_bank_size))\n","        labels_queue = torch.gather(labels_queue, dim=1, index=unconstrained_nn_index)\n","        matches = (labels_queue == labels).float()\n","        purity = (matches.sum(dim=1) / self.topk).mean()\n","\n","        loss = ((nn_dist_q_constrained.sum(dim=1) / self.topk).mean()\n","                + (nn_dist_q_unconstrained.sum(dim=1) / self.topk).mean()) / 2.0\n","\n","        return loss, purity\n","\n","\n","def get_shuffle_ids(bsz):\n","    \"\"\"generate shuffle ids for ShuffleBN\"\"\"\n","    forward_inds = torch.randperm(bsz).long().cuda()\n","    backward_inds = torch.zeros(bsz).long().cuda()\n","    value = torch.arange(bsz).long().cuda()\n","    backward_inds.index_copy_(0, forward_inds, value)\n","    return forward_inds, backward_inds\n","\n","\n","class TwoCropsTransform:\n","    \"\"\"Take two random crops of one image as the query and target.\"\"\"\n","    def __init__(self, weak_transform, strong_transform):\n","        self.weak_transform = weak_transform\n","        self.strong_transform = strong_transform\n","        print(self.weak_transform)\n","        print(self.strong_transform)\n","\n","    def __call__(self, x):\n","        q = self.strong_transform(x)\n","        t = self.weak_transform(x)\n","        return [q, t]\n","\n","\n","class GaussianBlur(object):\n","    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n","\n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","\n","    def __call__(self, x):\n","        sigma = random.uniform(self.sigma[0], self.sigma[1])\n","        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n","        return x\n","\n","\n","# Create train loader\n","def get_train_loader(opt):\n","    traindir = os.path.join(opt.data, 'train')\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","\n","    augmentation_strong = [\n","        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.RandomApply([\n","            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n","        ], p=0.8),\n","        transforms.RandomGrayscale(p=0.2),\n","        transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize\n","    ]\n","\n","    augmentation_weak = [\n","        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]\n","\n","    if opt.weak_strong:\n","        train_dataset = ImageFolderEx(\n","            traindir,\n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_strong))\n","        )\n","    else:\n","        train_dataset = ImageFolderEx(\n","            traindir,\n","            TwoCropsTransform(transforms.Compose(augmentation_strong), transforms.Compose(augmentation_strong))\n","        )\n","\n","    if opt.dataset == 'imagenet100':\n","        subset_classes(train_dataset, num_classes=100)\n","\n","    print('==> train dataset')\n","    print(train_dataset)\n","\n","    # NOTE: remove drop_last\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=opt.batch_size, shuffle=True,\n","        num_workers=opt.num_workers, pin_memory=True, drop_last=True)\n","\n","    return train_loader\n","\n","\n","def main():\n","    args = parse_option()\n","    os.makedirs(args.checkpoint_path, exist_ok=True)\n","\n","    if not args.debug:\n","        os.environ['PYTHONBREAKPOINT'] = '0'\n","        logger = get_logger(\n","            logpath=os.path.join(args.checkpoint_path, 'logs'),\n","            filepath=os.path.abspath(__file__)\n","        )\n","\n","        def print_pass(*arg):\n","            logger.info(*arg)\n","        builtins.print = print_pass\n","\n","    if args.gpu is not None:\n","        print(\"Use GPU: {} for training\".format(args.gpu))\n","\n","    print(args)\n","\n","    train_loader = get_train_loader(args)\n","\n","    mean_shift = ConstrainedMeanShiftKM(\n","        args.arch,\n","        m=args.momentum,\n","        mem_bank_size=args.mem_bank_size,\n","        topk=args.topk,\n","        dataset_size=len(train_loader.dataset),\n","        num_clusters=args.num_clusters\n","    )\n","\n","    mean_shift.data_parallel()\n","    mean_shift = mean_shift.cuda()\n","    print(mean_shift)\n","\n","    params = [p for p in mean_shift.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params,\n","                                lr=args.learning_rate,\n","                                momentum=args.sgd_momentum,\n","                                weight_decay=args.weight_decay)\n","\n","    cudnn.benchmark = True\n","    args.start_epoch = 1\n","\n","    if args.weights:\n","        print('==> load weights from checkpoint: {}'.format(args.weights))\n","        ckpt = torch.load(args.weights)\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        if 'model' in ckpt:\n","            sd = ckpt['model']\n","        else:\n","            sd = ckpt['state_dict']\n","        msg = mean_shift.load_state_dict(sd, strict=False)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        args.start_epoch = ckpt['epoch'] + 1\n","        print(msg)\n","\n","    if args.resume:\n","        print('==> resume from checkpoint: {}'.format(args.resume))\n","        ckpt = torch.load(args.resume, map_location='cpu')\n","        # sd = ckpt['state_dict']\n","        # sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        mean_shift.load_state_dict(ckpt['state_dict'], strict=True)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        args.start_epoch = ckpt['epoch'] + 1\n","\n","    for epoch in range(args.start_epoch, args.epochs + 1):\n","\n","        adjust_learning_rate(epoch, args, optimizer)\n","        print(\"==> training...\")\n","\n","        time1 = time.time()\n","\n","        train(epoch, train_loader, mean_shift, optimizer, args)\n","        mean_shift.cluster()\n","        time2 = time.time()\n","        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n","\n","        # saving the model\n","        if epoch % args.save_freq == 0:\n","            print('==> Saving...')\n","            state = {\n","                'opt': args,\n","                'state_dict': mean_shift.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epoch,\n","            }\n","\n","            save_file = os.path.join(args.checkpoint_path, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n","            torch.save(state, save_file)\n","\n","            # help release GPU memory\n","            del state\n","            torch.cuda.empty_cache()\n","\n","\n","def train(epoch, train_loader, mean_shift, optimizer, opt):\n","    \"\"\"\n","    one epoch training for CompReSS\n","    \"\"\"\n","    mean_shift.train()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    loss_meter = AverageMeter()\n","    purity_meter = AverageMeter()\n","\n","    end = time.time()\n","    for idx, (indices, (im_q, im_t), labels) in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","        im_q = im_q.cuda(non_blocking=True)\n","        im_t = im_t.cuda(non_blocking=True)\n","        labels = labels.cuda(non_blocking=True)\n","\n","        # ===================forward=====================\n","        loss, purity = mean_shift(im_q=im_q, im_t=im_t, labels=labels, indices=indices)\n","\n","        # ===================backward=====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ===================meters=====================\n","        loss_meter.update(loss.item(), im_q.size(0))\n","        purity_meter.update(purity.item(), im_q.size(0))\n","\n","        torch.cuda.synchronize()\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        # print info\n","        if (idx + 1) % opt.print_freq == 0:\n","            print('Train: [{0}][{1}/{2}]\\t'\n","                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'purity {purity.val:.3f} ({purity.avg:.3f})\\t'\n","                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'.format(\n","                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                   data_time=data_time,\n","                   purity=purity_meter,\n","                   loss=loss_meter))\n","            sys.stdout.flush()\n","            sys.stdout.flush()\n","\n","    return loss_meter.avg\n","\n","\n","if __name__ == '__main__':\n","    main()\n","\n","Namespace(arch='resnet50', batch_size=32, checkpoint_path='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output', cos=True, data='/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/', dataset='imagenet', debug=False, epochs=200, gpu=None, learning_rate=0.05, lr_decay_epochs=[90, 120], lr_decay_rate=0.2, mem_bank_size=128000, momentum=0.99, num_clusters=4, num_workers=2, print_freq=10, resume='', save_freq=10, sgd_momentum=0.9, topk=5, weak_strong=True, weight_decay=0.0001, weights=None)\n","Compose(\n","    RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n","    RandomHorizontalFlip(p=0.5)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","Compose(\n","    RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n","    RandomApply(\n","    p=0.8\n","    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])\n",")\n","    RandomGrayscale(p=0.2)\n","    RandomApply(\n","    p=0.5\n","    <__main__.GaussianBlur object at 0x7fd942d2f650>\n",")\n","    RandomHorizontalFlip(p=0.5)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","==> train dataset\n","Dataset ImageFolderEx\n","    Number of datapoints: 177\n","    Root location: /content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/train\n","    StandardTransform\n","Transform: <__main__.TwoCropsTransform object at 0x7fd942d2f410>\n","using mem-bank size 128000\n","ConstrainedMeanShiftKM(\n","  (encoder_q): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","      (fc): Sequential(\n","        (0): Linear(in_features=2048, out_features=4096, bias=True)\n","        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Linear(in_features=4096, out_features=512, bias=True)\n","      )\n","    )\n","  )\n","  (encoder_t): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","      (fc): Sequential(\n","        (0): Linear(in_features=2048, out_features=4096, bias=True)\n","        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Linear(in_features=4096, out_features=512, bias=True)\n","      )\n","    )\n","  )\n","  (predict_q): DataParallel(\n","    (module): Sequential(\n","      (0): Linear(in_features=512, out_features=4096, bias=True)\n","      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=4096, out_features=512, bias=True)\n","    )\n","  )\n",")\n","LR: 0.05\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 1, total time 33.28\n","LR: 0.04999691581204152\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 2, total time 5.90\n","LR: 0.04998766400914329\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 3, total time 3.14\n","LR: 0.049972246874049255\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 4, total time 3.07\n","LR: 0.04995066821070679\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 5, total time 3.07\n","LR: 0.0499229333433282\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 6, total time 3.07\n","LR: 0.049889049115077\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 7, total time 3.10\n","LR: 0.0498490238863795\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 8, total time 3.02\n","LR: 0.04980286753286195\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 9, total time 3.06\n","LR: 0.04975059144291394\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 10, total time 3.07\n","==> Saving...\n","LR: 0.04969220851487845\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 11, total time 3.18\n","LR: 0.04962773315386935\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 12, total time 3.09\n","LR: 0.049557181268217225\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 13, total time 3.47\n","LR: 0.049480570265544144\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 14, total time 3.58\n","LR: 0.049397919048468686\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 15, total time 3.37\n","LR: 0.049309248009941915\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 16, total time 3.18\n","LR: 0.04921457902821578\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 17, total time 3.13\n","LR: 0.049113935461444956\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 18, total time 3.20\n","LR: 0.04900734214192358\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 19, total time 3.20\n","LR: 0.048894825369958254\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 20, total time 3.21\n","==> Saving...\n","LR: 0.048776412907378844\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 21, total time 3.16\n","LR: 0.048652133970688634\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 22, total time 3.05\n","LR: 0.04852201922385564\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 23, total time 3.33\n","LR: 0.04838610077074669\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 24, total time 3.46\n","LR: 0.04824441214720629\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 25, total time 3.41\n","LR: 0.04809698831278217\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 26, total time 3.11\n","LR: 0.04794386564209953\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 27, total time 3.12\n","LR: 0.04778508191588613\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 28, total time 3.08\n","LR: 0.04762067631165049\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 29, total time 3.16\n","LR: 0.047450689394015394\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 30, total time 3.14\n","==> Saving...\n","LR: 0.047275163104709195\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 31, total time 3.32\n","LR: 0.047094140752217344\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 32, total time 3.36\n","LR: 0.04690766700109659\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 33, total time 3.85\n","LR: 0.04671578786095479\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 34, total time 3.86\n","LR: 0.046518550675098594\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 35, total time 3.26\n","LR: 0.04631600410885231\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 36, total time 3.33\n","LR: 0.04610819813755038\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 37, total time 3.32\n","LR: 0.04589518403420676\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 38, total time 3.31\n","LR: 0.04567701435686405\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 39, total time 3.38\n","LR: 0.04545374293562559\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 40, total time 3.39\n","==> Saving...\n","LR: 0.04522542485937369\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 41, total time 3.44\n","LR: 0.04499211646217727\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 42, total time 3.30\n","LR: 0.04475387530939226\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 43, total time 3.57\n","LR: 0.044510760183458245\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 44, total time 3.65\n","LR: 0.044262831069394735\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 45, total time 3.69\n","LR: 0.04401014914000078\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 46, total time 3.37\n","LR: 0.043752776740761494\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 47, total time 3.39\n","LR: 0.043490777374465245\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 48, total time 3.35\n","LR: 0.04322421568553529\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 49, total time 3.40\n","LR: 0.04295315744407972\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 50, total time 3.41\n","==> Saving...\n","LR: 0.04267766952966369\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 51, total time 3.40\n","LR: 0.04239781991480786\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 52, total time 3.25\n","LR: 0.04211367764821722\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 53, total time 3.68\n","LR: 0.041825312837744336\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 54, total time 3.70\n","LR: 0.0415327966330913\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 55, total time 3.63\n","LR: 0.041236201208254594\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 56, total time 3.36\n","LR: 0.040935599743717244\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 57, total time 3.36\n","LR: 0.04063106640839264\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 58, total time 3.33\n","LR: 0.040322676341324415\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 59, total time 3.42\n","LR: 0.040010505633147106\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 60, total time 3.39\n","==> Saving...\n","LR: 0.03969463130731184\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 61, total time 3.25\n","LR: 0.03937513130108197\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 62, total time 3.22\n","LR: 0.03905208444630327\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 63, total time 3.43\n","LR: 0.0387255704499533\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 64, total time 3.56\n","LR: 0.038395669874474916\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 65, total time 3.46\n","LR: 0.03806246411789872\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 66, total time 3.25\n","LR: 0.03772603539375929\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 67, total time 3.27\n","LR: 0.03738646671081019\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 68, total time 3.28\n","LR: 0.037043841852542884\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 69, total time 3.22\n","LR: 0.036698245356514336\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 70, total time 3.19\n","==> Saving...\n","LR: 0.03634976249348867\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 71, total time 3.27\n","LR: 0.035998479246397874\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 72, total time 3.37\n","LR: 0.03564448228912682\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 73, total time 3.74\n","LR: 0.035287858965127726\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 74, total time 3.86\n","LR: 0.034928697265869516\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 75, total time 3.42\n","LR: 0.03456708580912725\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 76, total time 3.36\n","LR: 0.03420311381711696\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 77, total time 3.47\n","LR: 0.033836871094481434\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 78, total time 3.42\n","LR: 0.033468448006132294\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 79, total time 3.35\n","LR: 0.033097935454953736\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 80, total time 3.51\n","==> Saving...\n","LR: 0.032725424859373686\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 81, total time 3.39\n","LR: 0.0323510081308076\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 82, total time 3.43\n","LR: 0.03197477765098074\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 83, total time 3.96\n","LR: 0.03159682624913432\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 84, total time 3.60\n","LR: 0.031217247179121367\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 85, total time 3.30\n","LR: 0.03083613409639764\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 86, total time 3.42\n","LR: 0.03045358103491357\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 87, total time 3.39\n","LR: 0.03006968238391282\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 88, total time 3.44\n","LR: 0.02968453286464312\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 89, total time 3.44\n","LR: 0.029298227506985238\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 90, total time 3.35\n","==> Saving...\n","LR: 0.028910861626005774\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 91, total time 3.40\n","LR: 0.028522530798439572\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 92, total time 3.24\n","LR: 0.028133330839107615\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 93, total time 3.71\n","LR: 0.027743357777276136\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 94, total time 3.70\n","LR: 0.02735270783296286\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 95, total time 3.35\n","LR: 0.026961477393196126\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 96, total time 3.25\n","LR: 0.02656976298823284\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 97, total time 3.28\n","LR: 0.026177661267741067\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 98, total time 3.32\n","LR: 0.02578526897695321\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 99, total time 3.36\n","LR: 0.02539268293279552\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 100, total time 3.26\n","==> Saving...\n","LR: 0.025\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 101, total time 3.26\n","LR: 0.02460731706720449\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 102, total time 3.19\n","LR: 0.024214731023046793\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 103, total time 3.41\n","LR: 0.023822338732258936\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 104, total time 3.47\n","LR: 0.023430237011767167\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 105, total time 3.40\n","LR: 0.02303852260680388\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 106, total time 3.18\n","LR: 0.022647292167037144\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 107, total time 3.18\n","LR: 0.02225664222272387\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 108, total time 3.18\n","LR: 0.0218666691608924\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 109, total time 3.29\n","LR: 0.02147746920156044\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 110, total time 3.25\n","==> Saving...\n","LR: 0.021089138373994232\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 111, total time 3.46\n","LR: 0.02070177249301476\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 112, total time 3.38\n","LR: 0.020315467135356886\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 113, total time 3.81\n","LR: 0.01993031761608719\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 114, total time 3.89\n","LR: 0.019546418965086444\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 115, total time 3.38\n","LR: 0.019163865903602362\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 116, total time 3.29\n","LR: 0.01878275282087863\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 117, total time 3.40\n","LR: 0.01840317375086568\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 118, total time 3.36\n","LR: 0.018025222349019272\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 119, total time 3.37\n","LR: 0.017648991869192405\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 120, total time 3.37\n","==> Saving...\n","LR: 0.017274575140626323\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 121, total time 3.25\n","LR: 0.016902064545046263\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 122, total time 3.27\n","LR: 0.016531551993867716\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 123, total time 3.66\n","LR: 0.016163128905518576\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 124, total time 3.78\n","LR: 0.01579688618288306\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 125, total time 3.60\n","LR: 0.015432914190872763\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 126, total time 3.32\n","LR: 0.015071302734130482\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 127, total time 3.31\n","LR: 0.014712141034872282\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 128, total time 3.31\n","LR: 0.014355517710873185\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 129, total time 3.42\n","LR: 0.014001520753602122\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 130, total time 3.40\n","==> Saving...\n","LR: 0.013650237506511332\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 131, total time 3.22\n","LR: 0.01330175464348567\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 132, total time 3.26\n","LR: 0.012956158147457115\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 133, total time 3.73\n","LR: 0.01261353328918981\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 134, total time 3.61\n","LR: 0.012273964606240717\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 135, total time 3.43\n","LR: 0.01193753588210128\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 136, total time 3.27\n","LR: 0.01160433012552508\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 137, total time 3.28\n","LR: 0.011274429550046703\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 138, total time 3.35\n","LR: 0.010947915553696733\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 139, total time 3.35\n","LR: 0.010624868698918037\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 140, total time 3.31\n","==> Saving...\n","LR: 0.010305368692688175\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 141, total time 3.46\n","LR: 0.009989494366852904\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 142, total time 3.37\n","LR: 0.009677323658675586\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 143, total time 3.87\n","LR: 0.00936893359160737\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 144, total time 3.75\n","LR: 0.009064400256282757\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 145, total time 3.73\n","LR: 0.008763798791745412\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 146, total time 3.41\n","LR: 0.008467203366908708\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 147, total time 3.40\n","LR: 0.008174687162255665\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 148, total time 3.47\n","LR: 0.007886322351782783\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 149, total time 3.36\n","LR: 0.0076021800851921425\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 150, total time 3.42\n","==> Saving...\n","LR: 0.0073223304703363135\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 151, total time 3.41\n","LR: 0.007046842555920283\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 152, total time 3.48\n","LR: 0.006775784314464717\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 153, total time 3.91\n","LR: 0.006509222625534755\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 154, total time 3.89\n","LR: 0.0062472232592385105\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 155, total time 3.41\n","LR: 0.005989850859999227\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 156, total time 3.42\n","LR: 0.005737168930605272\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 157, total time 3.46\n","LR: 0.005489239816541761\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 158, total time 3.45\n","LR: 0.00524612469060774\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 159, total time 3.40\n","LR: 0.005007883537822735\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 160, total time 3.43\n","==> Saving...\n","LR: 0.004774575140626317\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 161, total time 3.18\n","LR: 0.004546257064374418\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 162, total time 3.15\n","LR: 0.004322985643135957\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 163, total time 3.48\n","LR: 0.004104815965793249\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 164, total time 3.74\n","LR: 0.003891801862449629\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 165, total time 3.32\n","LR: 0.0036839958911477014\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 166, total time 3.21\n","LR: 0.0034814493249014063\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 167, total time 3.18\n","LR: 0.0032842121390452175\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 168, total time 3.26\n","LR: 0.0030923329989034107\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 169, total time 3.23\n","LR: 0.0029058592477826635\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 170, total time 3.28\n","==> Saving...\n","LR: 0.0027248368952908055\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 171, total time 3.42\n","LR: 0.002549310605984612\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 172, total time 3.31\n","LR: 0.0023793236883495163\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 173, total time 3.80\n","LR: 0.002214918084113873\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 174, total time 3.98\n","LR: 0.0020561343579004773\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 175, total time 3.55\n","LR: 0.0019030116872178371\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 176, total time 3.42\n","LR: 0.0017555878527937164\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 177, total time 3.53\n","LR: 0.0016138992292533156\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 178, total time 3.36\n","LR: 0.0014779807761443637\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 179, total time 3.40\n","LR: 0.0013478660293113677\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 180, total time 3.39\n","==> Saving...\n","LR: 0.0012235870926211618\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 181, total time 3.35\n","LR: 0.001105174630041747\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 182, total time 3.36\n","LR: 0.0009926578580764262\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 183, total time 4.03\n","LR: 0.0008860645385550509\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 184, total time 3.92\n","LR: 0.0007854209717842259\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 185, total time 3.42\n","LR: 0.0006907519900580862\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 186, total time 3.52\n","LR: 0.0006020809515313169\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 187, total time 3.40\n","LR: 0.0005194297344558535\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 188, total time 3.58\n","LR: 0.000442818731782782\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 189, total time 3.46\n","LR: 0.00037226684613065334\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 190, total time 3.54\n","==> Saving...\n","LR: 0.00030779148512155856\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 191, total time 3.23\n","LR: 0.0002494085570860616\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 192, total time 3.19\n","LR: 0.0001971324671380559\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 193, total time 3.54\n","LR: 0.00015097611362051012\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 194, total time 3.51\n","LR: 0.0001109508849230001\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 195, total time 3.51\n","LR: 7.70666566718009e-05\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 196, total time 3.25\n","LR: 4.933178929321103e-05\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 197, total time 3.23\n","LR: 2.775312595075241e-05\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 198, total time 3.18\n","LR: 1.233599085671e-05\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 199, total time 3.27\n","LR: 3.0841879584853073e-06\n","==> training...\n","start clustering ... num clusters: 4\n","epoch 200, total time 3.29\n","==> Saving...\n"]}]},{"cell_type":"code","source":["!python eval_linear.py \\\n","  --workers 2 \\\n","  --arch resnet50 \\\n","  --batch-size 32 \\\n","  --save /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval \\\n","  --weights /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth \\\n","  /content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GyyuUjs-kKK","executionInfo":{"status":"ok","timestamp":1650696185464,"user_tz":420,"elapsed":84079,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"b472039a-4274-4a2b-8b43-7eefca8a0229"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/eval_linear.py\n","import argparse\n","import os\n","import random\n","import shutil\n","import time\n","import warnings\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torch.nn.functional as F\n","\n","from tools import *\n","#from models.alexnet import AlexNet\n","#from models.mobilenet import MobileNetV2\n","import models.resnet as resnet\n","\n","\n","parser = argparse.ArgumentParser(description='Unsupervised distillation')\n","parser.add_argument('data', metavar='DIR',\n","                    help='path to dataset')\n","parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n","                    help='number of data loading workers (default: 4)')\n","parser.add_argument('-a', '--arch', default='resnet18',\n","                    help='model architecture: ' +\n","                         ' | '.join(model_names) +\n","                         ' (default: resnet18)')\n","parser.add_argument('--epochs', default=40, type=int, metavar='N',\n","                    help='number of total epochs to run')\n","parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n","                    help='manual epoch number (useful on restarts)')\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    metavar='N',\n","                    help='mini-batch size (default: 256), this is the total '\n","                         'batch size of all GPUs on the current node when '\n","                         'using Data Parallel or Distributed Data Parallel')\n","parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n","                    metavar='LR', help='initial learning rate', dest='lr')\n","parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n","                    help='momentum')\n","parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n","                    metavar='W', help='weight decay (default: 1e-4)',\n","                    dest='weight_decay')\n","parser.add_argument('-p', '--print-freq', default=10, type=int,\n","                    metavar='N', help='print frequency (default: 10)')\n","parser.add_argument('--resume', default='', type=str, metavar='PATH',\n","                    help='path to latest checkpoint (default: none)')\n","parser.add_argument('--seed', default=None, type=int,\n","                    help='seed for initializing training. ')\n","parser.add_argument('--save', default='./output/distill_1', type=str,\n","                    help='experiment output directory')\n","parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n","                    help='evaluate model on validation set')\n","parser.add_argument('--weights', dest='weights', type=str, required=True,\n","                    help='pre-trained model weights')\n","parser.add_argument('--lr_schedule', type=str, default='15,30,40',\n","                    help='lr drop schedule')\n","\n","best_acc1 = 0\n","\n","\n","def main():\n","    global logger\n","\n","    args = parser.parse_args()\n","    makedirs(args.save)\n","    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n","    logger.info(args)\n","\n","    if args.seed is not None:\n","        random.seed(args.seed)\n","        torch.manual_seed(args.seed)\n","        cudnn.deterministic = True\n","        warnings.warn('You have chosen to seed training. '\n","                      'This will turn on the CUDNN deterministic setting, '\n","                      'which can slow down your training considerably! '\n","                      'You may see unexpected behavior when restarting '\n","                      'from checkpoints.')\n","\n","    main_worker(args)\n","\n","import pdb\n","\n","\n","def load_weights(model, wts_path):\n","    wts = torch.load(wts_path)\n","    # pdb.set_trace()\n","    if 'state_dict' in wts:\n","        ckpt = wts['state_dict']\n","    elif 'model' in wts:\n","        ckpt = wts['model']\n","    else:\n","        ckpt = wts\n","\n","    #pdb.set_trace()\n","    ckpt = {k.replace('encoder_q.', ''): v for k, v in ckpt.items()}\n","    ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n","    state_dict = {}\n","\n","    for m_key, m_val in model.state_dict().items():\n","        if m_key in ckpt:\n","            state_dict[m_key] = ckpt[m_key]\n","        else:\n","            state_dict[m_key] = m_val\n","            print('not copied => ' + m_key)\n","\n","    model.load_state_dict(state_dict)\n","    print(model)\n","\n","\n","def get_model(arch, wts_path):\n","    if arch == 'alexnet':\n","        model = AlexNet()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif arch == 'pt_alexnet':\n","        model = models.alexnet()\n","        classif = list(model.classifier.children())[:5]\n","        model.classifier = nn.Sequential(*classif)\n","        load_weights(model, wts_path)\n","    elif arch == 'mobilenet':\n","        model = MobileNetV2()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif 'resnet' in arch:\n","        model = resnet.__dict__[arch]()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","\n","    for p in model.parameters():\n","        p.requires_grad = False\n","\n","    return model\n","\n","\n","def main_worker(args):\n","    global best_acc1\n","\n","    # Data loading code\n","    traindir = os.path.join(args.data, 'train')\n","    valdir = os.path.join(args.data, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","\n","    train_dataset = datasets.ImageFolder(traindir, train_transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=args.batch_size, shuffle=True,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        datasets.ImageFolder(valdir, val_transform),\n","        batch_size=args.batch_size, shuffle=False,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    train_val_loader = torch.utils.data.DataLoader(\n","        datasets.ImageFolder(traindir, val_transform),\n","        batch_size=args.batch_size, shuffle=False,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    backbone = get_model(args.arch, args.weights)\n","    backbone = nn.DataParallel(backbone).cuda()\n","    backbone.eval()\n","\n","\n","    cached_feats = '%s/var_mean.pth.tar' % args.save\n","    if not os.path.exists(cached_feats):\n","        train_feats, _ = get_feats(train_val_loader, backbone, args)\n","        train_var, train_mean = torch.var_mean(train_feats, dim=0)\n","        torch.save((train_var, train_mean), cached_feats)\n","    else:\n","        train_var, train_mean = torch.load(cached_feats)\n","\n","    linear = nn.Sequential(\n","        Normalize(),\n","        FullBatchNorm(train_var, train_mean),\n","        nn.Linear(get_channels(args.arch), len(train_dataset.classes)),\n","    )\n","    linear = linear.cuda()\n","\n","    optimizer = torch.optim.SGD(linear.parameters(),\n","                                args.lr,\n","                                momentum=args.momentum,\n","                                weight_decay=args.weight_decay)\n","\n","    sched = [int(x) for x in args.lr_schedule.split(',')]\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer, milestones=sched\n","    )\n","\n","    # optionally resume from a checkpoint\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            logger.info(\"=> loading checkpoint '{}'\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint['epoch']\n","            linear.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(args.resume, checkpoint['epoch']))\n","        else:\n","            logger.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n","\n","    cudnn.benchmark = True\n","\n","    if args.evaluate:\n","        validate(val_loader, backbone, linear, args)\n","        return\n","\n","    for epoch in range(args.start_epoch, args.epochs):\n","        # train for one epoch\n","        train(train_loader, backbone, linear, optimizer, epoch, args)\n","\n","        # evaluate on validation set\n","        acc1 = validate(val_loader, backbone, linear, args)\n","\n","        # modify lr\n","        lr_scheduler.step()\n","        # logger.info('LR: {:f}'.format(lr_scheduler.get_last_lr()[-1]))\n","\n","        # remember best acc@1 and save checkpoint\n","        is_best = acc1 > best_acc1\n","        best_acc1 = max(acc1, best_acc1)\n","\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': linear.state_dict(),\n","            'best_acc1': best_acc1,\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","        }, is_best, args.save)\n","\n","\n","class Normalize(nn.Module):\n","    def forward(self, x):\n","        return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","class FullBatchNorm(nn.Module):\n","    def __init__(self, var, mean):\n","        super(FullBatchNorm, self).__init__()\n","        self.register_buffer('inv_std', (1.0 / torch.sqrt(var + 1e-5)))\n","        self.register_buffer('mean', mean)\n","\n","    def forward(self, x):\n","        return (x - self.mean) * self.inv_std\n","\n","\n","def get_channels(arch):\n","    if arch == 'alexnet':\n","        c = 4096\n","    elif arch == 'pt_alexnet':\n","        c = 4096\n","    elif arch == 'resnet50':\n","        c = 2048\n","    elif arch == 'resnet18':\n","        c = 512\n","    elif arch == 'mobilenet':\n","        c = 1280\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","    return c\n","\n","\n","def train(train_loader, backbone, linear, optimizer, epoch, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(\n","        len(train_loader),\n","        [batch_time, data_time, losses, top1, top5],\n","        prefix=\"Epoch: [{}]\".format(epoch))\n","\n","    # switch to train mode\n","    backbone.eval()\n","    linear.train()\n","\n","    end = time.time()\n","    for i, (images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # compute output\n","        with torch.no_grad():\n","            output = backbone(images)\n","        output = linear(output)\n","        loss = F.cross_entropy(output, target)\n","\n","        # measure accuracy and record loss\n","        acc1, acc5 = accuracy(output, target, topk=(1, 4))\n","        losses.update(loss.item(), images.size(0))\n","        top1.update(acc1[0], images.size(0))\n","        top5.update(acc5[0], images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % args.print_freq == 0:\n","            logger.info(progress.display(i))\n","\n","\n","def validate(val_loader, backbone, linear, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(\n","        len(val_loader),\n","        [batch_time, losses, top1, top5],\n","        prefix='Test: ')\n","\n","    backbone.eval()\n","    linear.eval()\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (images, target) in enumerate(val_loader):\n","            images = images.cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = backbone(images)\n","            output = linear(output)\n","            loss = F.cross_entropy(output, target)\n","\n","            # measure accuracy and record loss\n","            acc1, acc5 = accuracy(output, target, topk=(1, 4))\n","            losses.update(loss.item(), images.size(0))\n","            top1.update(acc1[0], images.size(0))\n","            top5.update(acc5[0], images.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","        # TODO: this should also be done with the ProgressMeter\n","        logger.info(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n","              .format(top1=top1, top5=top5))\n","\n","    return top1.avg\n","\n","\n","def normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","def get_feats(loader, model, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, ptr = None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = normalize(model(images)).cpu()\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets)\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","    return feats, labels\n","\n","\n","if __name__ == '__main__':\n","    main()\n","\n","Namespace(arch='resnet50', batch_size=32, data='/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/', epochs=40, evaluate=False, lr=0.01, lr_schedule='15,30,40', momentum=0.9, print_freq=10, resume='', save='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval', seed=None, start_epoch=0, weight_decay=0.0001, weights='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth', workers=2)\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","  (fc): Sequential()\n",")\n","Epoch: [0][0/6]\tTime  1.152 ( 1.152)\tData  0.391 ( 0.391)\tLoss 1.4905e+00 (1.4905e+00)\tAcc@1  18.75 ( 18.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime 11.624 (11.624)\tLoss 2.7451e+00 (2.7451e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5 100.00 (100.00)\n"," * Acc@1 50.000 Acc@5 100.000\n","Epoch: [1][0/6]\tTime  0.394 ( 0.394)\tData  0.301 ( 0.301)\tLoss 1.7909e+00 (1.7909e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.340 ( 0.340)\tLoss 1.7410e+00 (1.7410e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n"," * Acc@1 52.174 Acc@5 100.000\n","Epoch: [2][0/6]\tTime  0.422 ( 0.422)\tData  0.333 ( 0.333)\tLoss 3.9072e+00 (3.9072e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.344 ( 0.344)\tLoss 2.9632e+00 (2.9632e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 45.652 Acc@5 100.000\n","Epoch: [3][0/6]\tTime  0.400 ( 0.400)\tData  0.312 ( 0.312)\tLoss 3.2545e+00 (3.2545e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.337 ( 0.337)\tLoss 3.9808e+00 (3.9808e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 39.130 Acc@5 100.000\n","Epoch: [4][0/6]\tTime  0.429 ( 0.429)\tData  0.338 ( 0.338)\tLoss 1.9984e+00 (1.9984e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.332 ( 0.332)\tLoss 2.9647e+00 (2.9647e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 63.043 Acc@5 100.000\n","Epoch: [5][0/6]\tTime  0.418 ( 0.418)\tData  0.326 ( 0.326)\tLoss 3.1383e+00 (3.1383e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.343 ( 0.343)\tLoss 2.9618e+00 (2.9618e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 50.000 Acc@5 100.000\n","Epoch: [6][0/6]\tTime  0.394 ( 0.394)\tData  0.301 ( 0.301)\tLoss 2.6091e+00 (2.6091e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.340 ( 0.340)\tLoss 3.0414e+00 (3.0414e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5 100.00 (100.00)\n"," * Acc@1 52.174 Acc@5 100.000\n","Epoch: [7][0/6]\tTime  0.432 ( 0.432)\tData  0.340 ( 0.340)\tLoss 2.3329e+00 (2.3329e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.348 ( 0.348)\tLoss 3.7582e+00 (3.7582e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 30.435 Acc@5 100.000\n","Epoch: [8][0/6]\tTime  0.395 ( 0.395)\tData  0.303 ( 0.303)\tLoss 5.5590e+00 (5.5590e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.335 ( 0.335)\tLoss 4.4716e+00 (4.4716e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 34.783 Acc@5 100.000\n","Epoch: [9][0/6]\tTime  0.418 ( 0.418)\tData  0.326 ( 0.326)\tLoss 5.4939e+00 (5.4939e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.338 ( 0.338)\tLoss 3.0523e+00 (3.0523e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 36.957 Acc@5 100.000\n","Epoch: [10][0/6]\tTime  0.420 ( 0.420)\tData  0.328 ( 0.328)\tLoss 2.9780e+00 (2.9780e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.342 ( 0.342)\tLoss 3.3085e+00 (3.3085e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n"," * Acc@1 60.870 Acc@5 100.000\n","Epoch: [11][0/6]\tTime  0.448 ( 0.448)\tData  0.353 ( 0.353)\tLoss 2.9628e+00 (2.9628e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.355 ( 0.355)\tLoss 1.0511e+01 (1.0511e+01)\tAcc@1  21.88 ( 21.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 34.783 Acc@5 100.000\n","Epoch: [12][0/6]\tTime  0.420 ( 0.420)\tData  0.329 ( 0.329)\tLoss 3.4419e+00 (3.4419e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.346 ( 0.346)\tLoss 2.3986e+00 (2.3986e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 63.043 Acc@5 100.000\n","Epoch: [13][0/6]\tTime  0.397 ( 0.397)\tData  0.305 ( 0.305)\tLoss 1.4281e+00 (1.4281e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.345 ( 0.345)\tLoss 3.9360e+00 (3.9360e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 45.652 Acc@5 100.000\n","Epoch: [14][0/6]\tTime  0.394 ( 0.394)\tData  0.302 ( 0.302)\tLoss 2.0772e+00 (2.0772e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.354 ( 0.354)\tLoss 8.2222e+00 (8.2222e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5 100.00 (100.00)\n"," * Acc@1 56.522 Acc@5 100.000\n","Epoch: [15][0/6]\tTime  0.389 ( 0.389)\tData  0.297 ( 0.297)\tLoss 9.1602e+00 (9.1602e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.344 ( 0.344)\tLoss 5.5469e+00 (5.5469e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 63.043 Acc@5 100.000\n","Epoch: [16][0/6]\tTime  0.414 ( 0.414)\tData  0.313 ( 0.313)\tLoss 3.3726e+00 (3.3726e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.334 ( 0.334)\tLoss 3.9604e+00 (3.9604e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 47.826 Acc@5 100.000\n","Epoch: [17][0/6]\tTime  0.393 ( 0.393)\tData  0.299 ( 0.299)\tLoss 3.0871e+00 (3.0871e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.344 ( 0.344)\tLoss 3.1720e+00 (3.1720e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n"," * Acc@1 56.522 Acc@5 100.000\n","Epoch: [18][0/6]\tTime  0.404 ( 0.404)\tData  0.311 ( 0.311)\tLoss 4.2393e+00 (4.2393e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.346 ( 0.346)\tLoss 2.5511e+00 (2.5511e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n"," * Acc@1 69.565 Acc@5 100.000\n","Epoch: [19][0/6]\tTime  0.405 ( 0.405)\tData  0.314 ( 0.314)\tLoss 2.3056e+00 (2.3056e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.358 ( 0.358)\tLoss 2.5145e+00 (2.5145e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n"," * Acc@1 60.870 Acc@5 100.000\n","Epoch: [20][0/6]\tTime  0.396 ( 0.396)\tData  0.303 ( 0.303)\tLoss 2.4317e+00 (2.4317e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.344 ( 0.344)\tLoss 2.1259e+00 (2.1259e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 58.696 Acc@5 100.000\n","Epoch: [21][0/6]\tTime  0.408 ( 0.408)\tData  0.313 ( 0.313)\tLoss 1.7634e+00 (1.7634e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.339 ( 0.339)\tLoss 1.6245e+00 (1.6245e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [22][0/6]\tTime  0.395 ( 0.395)\tData  0.303 ( 0.303)\tLoss 1.3125e+00 (1.3125e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.345 ( 0.345)\tLoss 1.4460e+00 (1.4460e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n"," * Acc@1 67.391 Acc@5 100.000\n","Epoch: [23][0/6]\tTime  0.429 ( 0.429)\tData  0.339 ( 0.339)\tLoss 1.2272e+00 (1.2272e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.338 ( 0.338)\tLoss 1.5804e+00 (1.5804e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n"," * Acc@1 58.696 Acc@5 100.000\n","Epoch: [24][0/6]\tTime  0.411 ( 0.411)\tData  0.319 ( 0.319)\tLoss 1.6302e+00 (1.6302e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.343 ( 0.343)\tLoss 1.6915e+00 (1.6915e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n"," * Acc@1 58.696 Acc@5 100.000\n","Epoch: [25][0/6]\tTime  0.407 ( 0.407)\tData  0.314 ( 0.314)\tLoss 1.5098e+00 (1.5098e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.336 ( 0.336)\tLoss 1.5174e+00 (1.5174e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n"," * Acc@1 58.696 Acc@5 100.000\n","Epoch: [26][0/6]\tTime  0.424 ( 0.424)\tData  0.329 ( 0.329)\tLoss 1.3519e+00 (1.3519e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.356 ( 0.356)\tLoss 1.3524e+00 (1.3524e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n"," * Acc@1 58.696 Acc@5 100.000\n","Epoch: [27][0/6]\tTime  0.419 ( 0.419)\tData  0.327 ( 0.327)\tLoss 9.2833e-01 (9.2833e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.349 ( 0.349)\tLoss 1.3933e+00 (1.3933e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n"," * Acc@1 60.870 Acc@5 100.000\n","Epoch: [28][0/6]\tTime  0.394 ( 0.394)\tData  0.301 ( 0.301)\tLoss 1.8660e+00 (1.8660e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.360 ( 0.360)\tLoss 1.2575e+00 (1.2575e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 60.870 Acc@5 100.000\n","Epoch: [29][0/6]\tTime  0.373 ( 0.373)\tData  0.281 ( 0.281)\tLoss 1.3965e+00 (1.3965e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.342 ( 0.342)\tLoss 1.2018e+00 (1.2018e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [30][0/6]\tTime  0.435 ( 0.435)\tData  0.339 ( 0.339)\tLoss 3.2181e-01 (3.2181e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.345 ( 0.345)\tLoss 1.1620e+00 (1.1620e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 67.391 Acc@5 100.000\n","Epoch: [31][0/6]\tTime  0.402 ( 0.402)\tData  0.310 ( 0.310)\tLoss 7.1378e-01 (7.1378e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.343 ( 0.343)\tLoss 1.1029e+00 (1.1029e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [32][0/6]\tTime  0.403 ( 0.403)\tData  0.311 ( 0.311)\tLoss 1.4133e+00 (1.4133e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.342 ( 0.342)\tLoss 1.0805e+00 (1.0805e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 63.043 Acc@5 100.000\n","Epoch: [33][0/6]\tTime  0.442 ( 0.442)\tData  0.352 ( 0.352)\tLoss 1.1717e+00 (1.1717e+00)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.351 ( 0.351)\tLoss 1.0816e+00 (1.0816e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 60.870 Acc@5 100.000\n","Epoch: [34][0/6]\tTime  0.394 ( 0.394)\tData  0.303 ( 0.303)\tLoss 8.3064e-01 (8.3064e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.341 ( 0.341)\tLoss 1.1034e+00 (1.1034e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [35][0/6]\tTime  0.421 ( 0.421)\tData  0.317 ( 0.317)\tLoss 9.8285e-01 (9.8285e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.347 ( 0.347)\tLoss 1.1565e+00 (1.1565e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [36][0/6]\tTime  0.425 ( 0.425)\tData  0.332 ( 0.332)\tLoss 9.9262e-01 (9.9262e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.345 ( 0.345)\tLoss 1.2041e+00 (1.2041e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [37][0/6]\tTime  0.392 ( 0.392)\tData  0.302 ( 0.302)\tLoss 5.1621e-01 (5.1621e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.339 ( 0.339)\tLoss 1.2204e+00 (1.2204e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n","Epoch: [38][0/6]\tTime  0.398 ( 0.398)\tData  0.307 ( 0.307)\tLoss 7.3035e-01 (7.3035e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.355 ( 0.355)\tLoss 1.2113e+00 (1.2113e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 67.391 Acc@5 100.000\n","Epoch: [39][0/6]\tTime  0.395 ( 0.395)\tData  0.304 ( 0.304)\tLoss 8.5808e-01 (8.5808e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n","Test: [0/2]\tTime  0.341 ( 0.341)\tLoss 1.1998e+00 (1.1998e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n"," * Acc@1 65.217 Acc@5 100.000\n"]}]},{"cell_type":"code","source":["best_model = torch.load('/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval/model_best.pth.tar')\n","best_model"],"metadata":{"id":"30P4T4QqL6Kc","executionInfo":{"status":"ok","timestamp":1650696189506,"user_tz":420,"elapsed":4047,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0015e1f6-0e9b-46c5-cc58-c25243e0ceac"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'best_acc1': tensor(69.5652, device='cuda:0'),\n"," 'epoch': 19,\n"," 'lr_scheduler': {'_get_lr_called_within_step': False,\n","  '_last_lr': [0.001],\n","  '_step_count': 20,\n","  'base_lrs': [0.01],\n","  'gamma': 0.1,\n","  'last_epoch': 19,\n","  'milestones': Counter({15: 1, 30: 1, 40: 1}),\n","  'verbose': False},\n"," 'optimizer': {'param_groups': [{'dampening': 0,\n","    'initial_lr': 0.01,\n","    'lr': 0.001,\n","    'momentum': 0.9,\n","    'nesterov': False,\n","    'params': [0, 1],\n","    'weight_decay': 0.0001}],\n","  'state': {0: {'momentum_buffer': tensor([[ 0.0014,  0.3129, -0.1872,  ...,  0.5888,  0.8816,  1.1801],\n","            [-0.0050, -0.5733,  0.1858,  ..., -0.4423, -0.5145, -0.9843],\n","            [ 0.0339,  0.2576, -0.1483,  ..., -0.1294, -0.5596, -0.3135],\n","            [-0.0304,  0.0027,  0.1497,  ..., -0.0171,  0.1925,  0.1176]],\n","           device='cuda:0')},\n","   1: {'momentum_buffer': tensor([ 0.8012, -0.6098,  0.1089, -0.3003], device='cuda:0')}}},\n"," 'state_dict': OrderedDict([('1.inv_std',\n","               tensor([ 54.6979, 101.8308, 163.3377,  ...,  62.7535, 115.0278,  96.3503],\n","                      device='cuda:0')),\n","              ('1.mean',\n","               tensor([0.0140, 0.0191, 0.0180,  ..., 0.0130, 0.0199, 0.0178], device='cuda:0')),\n","              ('2.weight',\n","               tensor([[-0.0240,  0.0251, -0.0115,  ...,  0.0245, -0.0211,  0.0292],\n","                       [-0.0137, -0.0458, -0.0272,  ..., -0.0143, -0.0332,  0.0488],\n","                       [ 0.0085,  0.0236, -0.0075,  ..., -0.0156,  0.0401, -0.0719],\n","                       [ 0.0070, -0.0258,  0.0576,  ..., -0.0268,  0.0306,  0.0256]],\n","                      device='cuda:0')),\n","              ('2.bias',\n","               tensor([-0.0164,  0.0100, -0.0116,  0.0254], device='cuda:0'))])}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!python eval_linear.py \\\n","  --workers 2 \\\n","  --arch resnet50 \\\n","  --batch-size 32 \\\n","  --evaluate \\\n","  --resume /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval/model_best.pth.tar \\\n","  --save /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval \\\n","  --weights /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth \\\n","  /content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kc7Kg4IdSy03","executionInfo":{"status":"ok","timestamp":1650696367506,"user_tz":420,"elapsed":9425,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"c3ac7fbb-8d29-40a2-e33f-04a4e24a73b5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/eval_linear.py\n","import argparse\n","import os\n","import random\n","import shutil\n","import time\n","import warnings\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torch.nn.functional as F\n","\n","from tools import *\n","#from models.alexnet import AlexNet\n","#from models.mobilenet import MobileNetV2\n","import models.resnet as resnet\n","\n","\n","parser = argparse.ArgumentParser(description='Unsupervised distillation')\n","parser.add_argument('data', metavar='DIR',\n","                    help='path to dataset')\n","parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n","                    help='number of data loading workers (default: 4)')\n","parser.add_argument('-a', '--arch', default='resnet18',\n","                    help='model architecture: ' +\n","                         ' | '.join(model_names) +\n","                         ' (default: resnet18)')\n","parser.add_argument('--epochs', default=40, type=int, metavar='N',\n","                    help='number of total epochs to run')\n","parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n","                    help='manual epoch number (useful on restarts)')\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    metavar='N',\n","                    help='mini-batch size (default: 256), this is the total '\n","                         'batch size of all GPUs on the current node when '\n","                         'using Data Parallel or Distributed Data Parallel')\n","parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n","                    metavar='LR', help='initial learning rate', dest='lr')\n","parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n","                    help='momentum')\n","parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n","                    metavar='W', help='weight decay (default: 1e-4)',\n","                    dest='weight_decay')\n","parser.add_argument('-p', '--print-freq', default=10, type=int,\n","                    metavar='N', help='print frequency (default: 10)')\n","parser.add_argument('--resume', default='', type=str, metavar='PATH',\n","                    help='path to latest checkpoint (default: none)')\n","parser.add_argument('--seed', default=None, type=int,\n","                    help='seed for initializing training. ')\n","parser.add_argument('--save', default='./output/distill_1', type=str,\n","                    help='experiment output directory')\n","parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n","                    help='evaluate model on validation set')\n","parser.add_argument('--weights', dest='weights', type=str, required=True,\n","                    help='pre-trained model weights')\n","parser.add_argument('--lr_schedule', type=str, default='15,30,40',\n","                    help='lr drop schedule')\n","\n","best_acc1 = 0\n","\n","\n","def main():\n","    global logger\n","\n","    args = parser.parse_args()\n","    makedirs(args.save)\n","    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n","    logger.info(args)\n","\n","    if args.seed is not None:\n","        random.seed(args.seed)\n","        torch.manual_seed(args.seed)\n","        cudnn.deterministic = True\n","        warnings.warn('You have chosen to seed training. '\n","                      'This will turn on the CUDNN deterministic setting, '\n","                      'which can slow down your training considerably! '\n","                      'You may see unexpected behavior when restarting '\n","                      'from checkpoints.')\n","\n","    main_worker(args)\n","\n","import pdb\n","\n","\n","def load_weights(model, wts_path):\n","    wts = torch.load(wts_path)\n","    # pdb.set_trace()\n","    if 'state_dict' in wts:\n","        ckpt = wts['state_dict']\n","    elif 'model' in wts:\n","        ckpt = wts['model']\n","    else:\n","        ckpt = wts\n","\n","    #pdb.set_trace()\n","    ckpt = {k.replace('encoder_q.', ''): v for k, v in ckpt.items()}\n","    ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n","    state_dict = {}\n","\n","    for m_key, m_val in model.state_dict().items():\n","        if m_key in ckpt:\n","            state_dict[m_key] = ckpt[m_key]\n","        else:\n","            state_dict[m_key] = m_val\n","            print('not copied => ' + m_key)\n","\n","    model.load_state_dict(state_dict)\n","    print(model)\n","\n","\n","def get_model(arch, wts_path):\n","    if arch == 'alexnet':\n","        model = AlexNet()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif arch == 'pt_alexnet':\n","        model = models.alexnet()\n","        classif = list(model.classifier.children())[:5]\n","        model.classifier = nn.Sequential(*classif)\n","        load_weights(model, wts_path)\n","    elif arch == 'mobilenet':\n","        model = MobileNetV2()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif 'resnet' in arch:\n","        model = resnet.__dict__[arch]()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","\n","    for p in model.parameters():\n","        p.requires_grad = False\n","\n","    return model\n","\n","\n","def main_worker(args):\n","    global best_acc1\n","\n","    # Data loading code\n","    traindir = os.path.join(args.data, 'train')\n","    valdir = os.path.join(args.data, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","\n","    train_dataset = datasets.ImageFolder(traindir, train_transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=args.batch_size, shuffle=True,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        datasets.ImageFolder(valdir, val_transform),\n","        batch_size=args.batch_size, shuffle=False,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    train_val_loader = torch.utils.data.DataLoader(\n","        datasets.ImageFolder(traindir, val_transform),\n","        batch_size=args.batch_size, shuffle=False,\n","        num_workers=args.workers, pin_memory=True,\n","    )\n","\n","    backbone = get_model(args.arch, args.weights)\n","    backbone = nn.DataParallel(backbone).cuda()\n","    backbone.eval()\n","\n","\n","    cached_feats = '%s/var_mean.pth.tar' % args.save\n","    if not os.path.exists(cached_feats):\n","        train_feats, _ = get_feats(train_val_loader, backbone, args)\n","        train_var, train_mean = torch.var_mean(train_feats, dim=0)\n","        torch.save((train_var, train_mean), cached_feats)\n","    else:\n","        train_var, train_mean = torch.load(cached_feats)\n","\n","    linear = nn.Sequential(\n","        Normalize(),\n","        FullBatchNorm(train_var, train_mean),\n","        nn.Linear(get_channels(args.arch), len(train_dataset.classes)),\n","    )\n","    linear = linear.cuda()\n","\n","    optimizer = torch.optim.SGD(linear.parameters(),\n","                                args.lr,\n","                                momentum=args.momentum,\n","                                weight_decay=args.weight_decay)\n","\n","    sched = [int(x) for x in args.lr_schedule.split(',')]\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer, milestones=sched\n","    )\n","\n","    # optionally resume from a checkpoint\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            logger.info(\"=> loading checkpoint '{}'\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint['epoch']\n","            linear.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(args.resume, checkpoint['epoch']))\n","        else:\n","            logger.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n","\n","    cudnn.benchmark = True\n","\n","    if args.evaluate:\n","        validate(val_loader, backbone, linear, args)\n","        return\n","\n","    for epoch in range(args.start_epoch, args.epochs):\n","        # train for one epoch\n","        train(train_loader, backbone, linear, optimizer, epoch, args)\n","\n","        # evaluate on validation set\n","        acc1 = validate(val_loader, backbone, linear, args)\n","\n","        # modify lr\n","        lr_scheduler.step()\n","        # logger.info('LR: {:f}'.format(lr_scheduler.get_last_lr()[-1]))\n","\n","        # remember best acc@1 and save checkpoint\n","        is_best = acc1 > best_acc1\n","        best_acc1 = max(acc1, best_acc1)\n","\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': linear.state_dict(),\n","            'best_acc1': best_acc1,\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","        }, is_best, args.save)\n","\n","\n","class Normalize(nn.Module):\n","    def forward(self, x):\n","        return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","class FullBatchNorm(nn.Module):\n","    def __init__(self, var, mean):\n","        super(FullBatchNorm, self).__init__()\n","        self.register_buffer('inv_std', (1.0 / torch.sqrt(var + 1e-5)))\n","        self.register_buffer('mean', mean)\n","\n","    def forward(self, x):\n","        return (x - self.mean) * self.inv_std\n","\n","\n","def get_channels(arch):\n","    if arch == 'alexnet':\n","        c = 4096\n","    elif arch == 'pt_alexnet':\n","        c = 4096\n","    elif arch == 'resnet50':\n","        c = 2048\n","    elif arch == 'resnet18':\n","        c = 512\n","    elif arch == 'mobilenet':\n","        c = 1280\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","    return c\n","\n","\n","def train(train_loader, backbone, linear, optimizer, epoch, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(\n","        len(train_loader),\n","        [batch_time, data_time, losses, top1, top5],\n","        prefix=\"Epoch: [{}]\".format(epoch))\n","\n","    # switch to train mode\n","    backbone.eval()\n","    linear.train()\n","\n","    end = time.time()\n","    for i, (images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # compute output\n","        with torch.no_grad():\n","            output = backbone(images)\n","        output = linear(output)\n","        loss = F.cross_entropy(output, target)\n","\n","        # measure accuracy and record loss\n","        acc1, acc5 = accuracy(output, target, topk=(1, 4))\n","        losses.update(loss.item(), images.size(0))\n","        top1.update(acc1[0], images.size(0))\n","        top5.update(acc5[0], images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % args.print_freq == 0:\n","            logger.info(progress.display(i))\n","\n","\n","def validate(val_loader, backbone, linear, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(\n","        len(val_loader),\n","        [batch_time, losses, top1, top5],\n","        prefix='Test: ')\n","\n","    backbone.eval()\n","    linear.eval()\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (images, target) in enumerate(val_loader):\n","            images = images.cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = backbone(images)\n","            output = linear(output)\n","            loss = F.cross_entropy(output, target)\n","\n","            # measure accuracy and record loss\n","            acc1, acc5 = accuracy(output, target, topk=(1, 4))\n","            losses.update(loss.item(), images.size(0))\n","            top1.update(acc1[0], images.size(0))\n","            top5.update(acc5[0], images.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","        # TODO: this should also be done with the ProgressMeter\n","        logger.info(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n","              .format(top1=top1, top5=top5))\n","\n","    return top1.avg\n","\n","\n","def normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","def get_feats(loader, model, args):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, ptr = None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = normalize(model(images)).cpu()\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets)\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","    return feats, labels\n","\n","\n","if __name__ == '__main__':\n","    main()\n","\n","Namespace(arch='resnet50', batch_size=32, data='/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/', epochs=40, evaluate=True, lr=0.01, lr_schedule='15,30,40', momentum=0.9, print_freq=10, resume='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval/model_best.pth.tar', save='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval', seed=None, start_epoch=0, weight_decay=0.0001, weights='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth', workers=2)\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","  (fc): Sequential()\n",")\n","=> loading checkpoint '/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval/model_best.pth.tar'\n","=> loaded checkpoint '/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_eval/model_best.pth.tar' (epoch 19)\n","Test: [0/2]\tTime  1.015 ( 1.015)\tLoss 2.5511e+00 (2.5511e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n"," * Acc@1 69.565 Acc@5 100.000\n"]}]},{"cell_type":"code","source":["!python eval_knn.py \\\n","  --workers 2 \\\n","  --arch resnet50 \\\n","  --batch-size 32 \\\n","  --save /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_knn_eval \\\n","  --weights /content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth \\\n","  /content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/"],"metadata":{"id":"T40xShcuWUM4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650696396484,"user_tz":420,"elapsed":12970,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"78582038-9900-4d52-d879-2a3ac16ffcad"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/eval_knn.py\n","import builtins\n","from collections import Counter, OrderedDict\n","from random import shuffle\n","import argparse\n","import os\n","import random\n","import shutil\n","import time\n","import warnings\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torch.nn.functional as F\n","import numpy as np\n","import faiss\n","\n","from tools import *\n","from models.resnet import resnet18, resnet50\n","#from models.alexnet import AlexNet as alexnet\n","#from models.mobilenet import MobileNetV2 as mobilenet\n","# from models.resnet_swav import resnet50w5, resnet50 as swav_resnet50\n","# from models.resnet_byol import resnet50 as byol_resnet50\n","# from models.resnet_gn_ws import l_resnet18, l_resnet50\n","from eval_linear import load_weights\n","# from file_dataset import FileDataset\n","\n","\n","parser = argparse.ArgumentParser(description='NN evaluation')\n","parser.add_argument('data', metavar='DIR', help='path to dataset')\n","parser.add_argument('--dataset', type=str, default='imagenet',\n","                    choices=['imagenet', 'imagenet100', 'imagenet-lt'],\n","                    help='use full or subset of the dataset')\n","parser.add_argument('-j', '--workers', default=8, type=int,\n","                    help='number of data loading workers (default: 4)')\n","parser.add_argument('-a', '--arch', type=str, default='alexnet',\n","                        choices=['alexnet' , 'resnet18' , 'resnet50', 'mobilenet' ,\n","                                 'l_resnet18', 'l_resnet50', \n","                                 'two_resnet50', 'one_resnet50', \n","                                 'moco_alexnet' , 'moco_resnet18' , 'moco_resnet50', 'moco_mobilenet', 'resnet50w5', 'teacher_resnet18',  'teacher_resnet50',\n","                                 'sup_alexnet' , 'sup_resnet18' , 'sup_resnet50', 'sup_mobilenet', 'pt_alexnet', 'swav_resnet50', 'byol_resnet50'])\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    help='mini-batch size (default: 256), this is the total '\n","                         'batch size of all GPUs on the current node when '\n","                         'using Data Parallel or Distributed Data Parallel')\n","parser.add_argument('-p', '--print-freq', default=90, type=int,\n","                    help='print frequency (default: 10)')\n","parser.add_argument('--save', default='./output/cluster_alignment_1', type=str,\n","                    help='experiment output directory')\n","parser.add_argument('--weights', dest='weights', type=str,\n","                    help='pre-trained model weights')\n","parser.add_argument('--load_cache', action='store_true',\n","                    help='should the features be recomputed or loaded from the cache')\n","parser.add_argument('-k', default=1, type=int, help='k in kNN')\n","parser.add_argument('--debug', action='store_true', help='whether in debug mode or not')\n","\n","TEMP = 0.04\n","\n","\n","def main():\n","    global logger\n","\n","    args = parser.parse_args()\n","    makedirs(args.save)\n","\n","    if not args.debug:\n","        logger = get_logger(\n","            logpath=os.path.join(args.save, 'logs'),\n","            # logpath=os.path.join(args.save, 'knn.logs'),\n","            filepath=os.path.abspath(__file__)\n","        )\n","        def print_pass(*args):\n","            logger.info(*args)\n","        builtins.print = print_pass\n","\n","    print(args)\n","\n","    main_worker(args)\n","\n","\n","def get_model(args):\n","\n","    model = None\n","    if args.arch == 'alexnet' :\n","        model = alexnet()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_k' not in k}\n","        sd = {k.replace('encoder_q.', ''): v for k, v in sd.items()}\n","        sd = {('module.'+k): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=False)\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'pt_alexnet' :\n","        model = models.alexnet(num_classes=16000)\n","        checkpoint = torch.load(args.weights)\n","        sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=True)\n","        classif = list(model.classifier.children())[:5]\n","        model.classifier = nn.Sequential(*classif)\n","        model = torch.nn.DataParallel(model).cuda()\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'resnet18' :\n","        model = resnet18()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_k' not in k}\n","        sd = {k.replace('encoder_q.', ''): v for k, v in sd.items()}\n","        sd = {('module.'+k): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=False)\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'one_resnet50' :\n","        model = resnet50()\n","        model.fc = nn.Sequential()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'projection' not in k}\n","        sd = {k: v for k, v in sd.items() if 'prediction' not in k}\n","        sd = {k: v for k, v in sd.items() if 'pred_' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_two' not in k}\n","        sd = {k.replace('encoder_one.', ''): v for k, v in sd.items()}\n","        sd = {k.replace('backbone.', ''): v for k, v in sd.items()}\n","        model.load_state_dict(sd, strict=True)\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'two_resnet50' :\n","        model = resnet50()\n","        model.fc = nn.Sequential()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'projection' not in k}\n","        sd = {k: v for k, v in sd.items() if 'prediction' not in k}\n","        sd = {k: v for k, v in sd.items() if 'pred_' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_one' not in k}\n","        sd = {k.replace('encoder_two.', ''): v for k, v in sd.items()}\n","        sd = {k.replace('backbone.', ''): v for k, v in sd.items()}\n","        model.load_state_dict(sd, strict=True)\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'l_resnet18' :\n","        model = l_resnet18()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_k' not in k}\n","        sd = {k.replace('encoder_q.', ''): v for k, v in sd.items()}\n","        sd = {('module.'+k): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=False)\n","        print(model)\n","        print(msg)\n","\n","    elif 'teacher_' in args.arch:\n","        if 'resnet18' in args.arch:\n","            model = resnet18()\n","        elif 'resnet50' in args.arch:\n","            model = resnet50()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'predict_q' not in k}\n","        sd = {k: v for k, v in sd.items() if 'queue' not in k}\n","        new_sd = {}\n","        for key in sd.keys():\n","            if 'encoder_k' in key and 'running_' not in key:\n","                new_sd['module.' + key.replace('encoder_k.', '')] = sd[key]\n","            if 'encoder_q' in key and 'running_' in key:\n","                new_sd['module.' + key.replace('encoder_q.', '')] = sd[key]\n","        msg = model.load_state_dict(new_sd, strict=True)\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'mobilenet' :\n","        model = mobilenet()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        msg = model.load_state_dict(checkpoint['model'] , strict=False)\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'resnet50' :\n","        model = resnet50()\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_k' not in k}\n","        sd = {k.replace('encoder_q.', ''): v for k, v in sd.items()}\n","        sd = {('module.'+k): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=False)\n","        print(model)\n","        print(msg)\n","\n","    elif args.arch == 'byol_resnet50' :\n","        model = byol_resnet50()\n","        model.fc = nn.Sequential()\n","        checkpoint = torch.load(args.weights)\n","        if 'model' in checkpoint:\n","            sd = checkpoint['model']\n","        else:\n","            sd = checkpoint['state_dict']\n","        sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        sd = {k: v for k, v in sd.items() if 'fc' not in k}\n","        sd = {k: v for k, v in sd.items() if 'encoder_k' not in k}\n","        sd = {k: v for k, v in sd.items() if 'predict_q' not in k}\n","        sd = {k: v for k, v in sd.items() if 'queue' not in k}\n","        sd = {k.replace('encoder_q.', ''): v for k, v in sd.items()}\n","        msg = model.load_state_dict(sd, strict=True)\n","        print(model)\n","        print(msg)\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'moco_alexnet' :\n","        model = alexnet()\n","        model.fc = nn.Sequential()\n","        model = nn.Sequential(OrderedDict([('encoder_q', model)]))\n","        model = model.cuda()\n","        checkpoint = torch.load(args.weights)\n","        model.load_state_dict(checkpoint['state_dict'] , strict=False)\n","\n","    elif args.arch == 'moco_resnet18' :\n","        model = resnet18().cuda()\n","        model = nn.Sequential(OrderedDict([('encoder_q' , model)]))\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        msg = model.load_state_dict(checkpoint['state_dict'] , strict=False)\n","        print(msg)\n","        # model.module.encoder_q.fc = nn.Sequential()\n","\n","    elif args.arch == 'moco_mobilenet' :\n","        model = mobilenet()\n","        model.fc = nn.Sequential()\n","        model = nn.Sequential(OrderedDict([('encoder_q', model)]))\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        model.load_state_dict(checkpoint['state_dict'], strict=False)\n","\n","    elif args.arch == 'moco_resnet50' :\n","        model = resnet50().cuda()\n","        model = nn.Sequential(OrderedDict([('encoder_q' , model)]))\n","        model = torch.nn.DataParallel(model).cuda()\n","        checkpoint = torch.load(args.weights)\n","        model.load_state_dict(checkpoint['state_dict'] , strict=False)\n","        model.module.encoder_q.fc = nn.Sequential()\n","\n","    elif args.arch == 'resnet50w5':\n","        model = resnet50w5()\n","        model.l2norm = None\n","        load_weights(model, args.weights)\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'swav_resnet50':\n","        model = swav_resnet50()\n","        model.l2norm = None\n","        load_weights(model, args.weights)\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'sup_alexnet' :\n","        # model = models.alexnet(pretrained=True)\n","        # modules = list(model.children())[:-1]\n","        # classifier_modules = list(model.classifier.children())[:-1]\n","        # modules.append(Flatten())\n","        # modules.append(nn.Sequential(*classifier_modules))\n","        # model = nn.Sequential(*modules)\n","        # model = model.cuda()\n","        ####### modified #######\n","        model = models.alexnet(pretrained=False)\n","        model.classifier = nn.Sequential()\n","        modules = list(model.children())\n","        modules.append(nn.Flatten())\n","        model = nn.Sequential(*modules)\n","        model = model.cuda()\n","\n","    elif args.arch == 'sup_resnet18' :\n","        model = models.resnet18(pretrained=True)\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'sup_mobilenet' :\n","        model = models.mobilenet_v2(pretrained=True)\n","        model.classifier = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    elif args.arch == 'sup_resnet50' :\n","        model = models.resnet50(pretrained=True)\n","        model.fc = nn.Sequential()\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model\n","\n","\n","class ImageFolderEx(datasets.ImageFolder) :\n","    def __getitem__(self, index):\n","        sample, target = super(ImageFolderEx, self).__getitem__(index)\n","        return index, sample, target\n","\n","\n","# class FileDatasetEx(FileDataset) :\n","#     def __getitem__(self, index):\n","#         sample, target = super(FileDatasetEx, self).__getitem__(index)\n","#         return index, sample, target\n","\n","\n","def get_loaders(dataset_dir, bs, workers, dataset='imagenet'):\n","    traindir = os.path.join(dataset_dir, 'train')\n","    valdir = os.path.join(dataset_dir, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    augmentation = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    train_dataset = ImageFolderEx(traindir, augmentation)\n","    val_dataset = ImageFolderEx(valdir, augmentation)\n","\n","    if dataset == 'imagenet100':\n","        subset_classes(train_dataset, num_classes=100)\n","        subset_classes(val_dataset, num_classes=100)\n","\n","\n","    train_loader = DataLoader(\n","        train_dataset, batch_size=bs, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset, batch_size=bs, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    return train_loader, val_loader\n","\n","\n","def main_worker(args):\n","\n","    start = time.time()\n","    # Get train/val loader \n","    # ---------------------------------------------------------------\n","    train_loader, val_loader = get_loaders(args.data, args.batch_size, args.workers, args.dataset)\n","\n","    # Create and load the model\n","    # If you want to evaluate your model, modify this part and load your model\n","    # ------------------------------------------------------------------------\n","    # MODIFY 'get_model' TO EVALUATE YOUR MODEL\n","    model = get_model(args)\n","\n","    # ------------------------------------------------------------------------\n","    # Forward training samples throw the model and cache feats\n","    # ------------------------------------------------------------------------\n","    cudnn.benchmark = True\n","\n","    cached_feats = '%s/train_feats.pth.tar' % args.save\n","    if args.load_cache and os.path.exists(cached_feats):\n","        print('load train feats from cache =>')\n","        train_feats, train_labels, train_inds = torch.load(cached_feats)\n","    else:\n","        print('get train feats =>')\n","        train_feats, train_labels, train_inds = get_feats(train_loader, model, args.print_freq)\n","        torch.save((train_feats, train_labels, train_inds), cached_feats)\n","\n","    cached_feats = '%s/val_feats.pth.tar' % args.save\n","    if args.load_cache and os.path.exists(cached_feats):\n","        print('load val feats from cache =>')\n","        val_feats, val_labels, val_inds = torch.load(cached_feats)\n","    else:\n","        print('get val feats =>')\n","        val_feats, val_labels, val_inds = get_feats(val_loader, model, args.print_freq)\n","        torch.save((val_feats, val_labels, val_inds), cached_feats)\n","\n","    # ------------------------------------------------------------------------\n","    # Calculate NN accuracy on validation set\n","    # ------------------------------------------------------------------------\n","\n","    # train_feats = l2_normalize(train_feats)\n","    # val_feats = l2_normalize(val_feats)\n","\n","    # mean = torch.mean(train_feats, dim=0)\n","    # std = torch.std(train_feats, dim=0)\n","\n","    # stdmean = std.mean()\n","    # train_feats = train_feats / stdmean\n","    # val_feats = val_feats / stdmean\n","\n","    # train_feats = train_feats / std\n","    # val_feats = val_feats / std\n","\n","    # train_feats = (train_feats - mean) / std\n","    # val_feats = (val_feats - mean) / std\n","\n","    # train_feats = train_feats - mean\n","    # val_feats = val_feats - mean\n","\n","    # train_feats = train_feats / TEMP\n","    # val_feats = val_feats / TEMP\n","\n","    train_feats = l2_normalize(train_feats)\n","    val_feats = l2_normalize(val_feats)\n","\n","    for k in [1,20]:\n","        print(k)\n","        acc = faiss_knn(train_feats, train_labels, val_feats, val_labels, k)\n","        nn_time = time.time() - start\n","        print('=> time : {:.2f}s'.format(nn_time))\n","        print(' * Acc {:.2f}'.format(acc))\n","\n","\n","def l2_normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","def faiss_knn(feats_train, targets_train, feats_val, targets_val, k):\n","    feats_train = feats_train.numpy()\n","    targets_train = targets_train.numpy()\n","    feats_val = feats_val.numpy()\n","    targets_val = targets_val.numpy()\n","\n","    d = feats_train.shape[-1]\n","\n","    index = faiss.IndexFlatL2(d)  # build the index\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    gpu_index = faiss.index_cpu_to_all_gpus(index, co)\n","    gpu_index.add(feats_train)\n","\n","    D, I = gpu_index.search(feats_val, k)\n","\n","    pred = np.zeros(I.shape[0], dtype=np.int)\n","    conf_mat = np.zeros((1000, 1000), dtype=np.int)\n","    for i in range(I.shape[0]):\n","        votes = list(Counter(targets_train[I[i]]).items())\n","        shuffle(votes)\n","        pred[i] = max(votes, key=lambda x: x[1])[0]\n","        conf_mat[targets_val[i], pred[i]] += 1\n","\n","    acc = 100.0 * (pred == targets_val).mean()\n","    assert acc == (100.0 * (np.trace(conf_mat) / np.sum(conf_mat)))\n","\n","    # per_cat_acc = 100.0 * (np.diag(conf_mat) / np.sum(conf_mat, axis=1))\n","    # sparse_cats = [58, 155, 356, 747, 865, 234, 268, 384, 385, 491, 498, 538, 646, 650, 726, 860, 887, 15, 170, 231]\n","    # s = ' '.join('{}'.format(c) for c in sparse_cats)\n","    # print('==> cats: {}'.format(s))\n","    # s = ' '.join('{:.1f}'.format(a) for a in per_cat_acc[sparse_cats])\n","    # print('==> acc/cat: {}'.format(s))\n","    # print('==> mean acc: {}'.format(per_cat_acc[sparse_cats].mean()))\n","\n","    return acc\n","\n","\n","def get_feats(loader, model, print_freq):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, indices, ptr = None, None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (index, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = model(images).cpu()\n","            cur_indices = index.cpu()\n","\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","                indices = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets)\n","            indices.index_copy_(0, inds, cur_indices)\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","    return feats, labels, indices\n","\n","\n","def subset_classes(dataset, num_classes=10):\n","    np.random.seed(1234)\n","    all_classes = sorted(dataset.class_to_idx.items(), key=lambda x: x[1])\n","    subset_classes = [all_classes[i] for i in np.random.permutation(len(all_classes))[:num_classes]]\n","    subset_classes = sorted(subset_classes, key=lambda x: x[1])\n","    dataset.classes_to_idx = {c: i for i, (c, _) in enumerate(subset_classes)}\n","    dataset.classes = [c for c, _ in subset_classes]\n","    orig_to_new_inds = {orig_ind: new_ind for new_ind, (_, orig_ind) in enumerate(subset_classes)}\n","    dataset.samples = [(p, orig_to_new_inds[i]) for p, i in dataset.samples if i in orig_to_new_inds]\n","\n","\n","\n","if __name__ == '__main__':\n","    main()\n","\n","\n","Namespace(arch='resnet50', batch_size=32, data='/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_Labeled_images/', dataset='imagenet', debug=False, k=1, load_cache=False, print_freq=90, save='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output_knn_eval', weights='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/cmsf-km_4_cluster_output/ckpt_epoch_200.pth', workers=2)\n","DataParallel(\n","  (module): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Sequential()\n","  )\n",")\n","_IncompatibleKeys(missing_keys=[], unexpected_keys=['module.queue', 'module.pool', 'module.pseudo_labels', 'module.labels', 'module.index_queue', 'module.queue_ptr', 'module.encoder_t.conv1.weight', 'module.encoder_t.bn1.weight', 'module.encoder_t.bn1.bias', 'module.encoder_t.bn1.running_mean', 'module.encoder_t.bn1.running_var', 'module.encoder_t.bn1.num_batches_tracked', 'module.encoder_t.layer1.0.conv1.weight', 'module.encoder_t.layer1.0.bn1.weight', 'module.encoder_t.layer1.0.bn1.bias', 'module.encoder_t.layer1.0.bn1.running_mean', 'module.encoder_t.layer1.0.bn1.running_var', 'module.encoder_t.layer1.0.bn1.num_batches_tracked', 'module.encoder_t.layer1.0.conv2.weight', 'module.encoder_t.layer1.0.bn2.weight', 'module.encoder_t.layer1.0.bn2.bias', 'module.encoder_t.layer1.0.bn2.running_mean', 'module.encoder_t.layer1.0.bn2.running_var', 'module.encoder_t.layer1.0.bn2.num_batches_tracked', 'module.encoder_t.layer1.0.conv3.weight', 'module.encoder_t.layer1.0.bn3.weight', 'module.encoder_t.layer1.0.bn3.bias', 'module.encoder_t.layer1.0.bn3.running_mean', 'module.encoder_t.layer1.0.bn3.running_var', 'module.encoder_t.layer1.0.bn3.num_batches_tracked', 'module.encoder_t.layer1.0.downsample.0.weight', 'module.encoder_t.layer1.0.downsample.1.weight', 'module.encoder_t.layer1.0.downsample.1.bias', 'module.encoder_t.layer1.0.downsample.1.running_mean', 'module.encoder_t.layer1.0.downsample.1.running_var', 'module.encoder_t.layer1.0.downsample.1.num_batches_tracked', 'module.encoder_t.layer1.1.conv1.weight', 'module.encoder_t.layer1.1.bn1.weight', 'module.encoder_t.layer1.1.bn1.bias', 'module.encoder_t.layer1.1.bn1.running_mean', 'module.encoder_t.layer1.1.bn1.running_var', 'module.encoder_t.layer1.1.bn1.num_batches_tracked', 'module.encoder_t.layer1.1.conv2.weight', 'module.encoder_t.layer1.1.bn2.weight', 'module.encoder_t.layer1.1.bn2.bias', 'module.encoder_t.layer1.1.bn2.running_mean', 'module.encoder_t.layer1.1.bn2.running_var', 'module.encoder_t.layer1.1.bn2.num_batches_tracked', 'module.encoder_t.layer1.1.conv3.weight', 'module.encoder_t.layer1.1.bn3.weight', 'module.encoder_t.layer1.1.bn3.bias', 'module.encoder_t.layer1.1.bn3.running_mean', 'module.encoder_t.layer1.1.bn3.running_var', 'module.encoder_t.layer1.1.bn3.num_batches_tracked', 'module.encoder_t.layer1.2.conv1.weight', 'module.encoder_t.layer1.2.bn1.weight', 'module.encoder_t.layer1.2.bn1.bias', 'module.encoder_t.layer1.2.bn1.running_mean', 'module.encoder_t.layer1.2.bn1.running_var', 'module.encoder_t.layer1.2.bn1.num_batches_tracked', 'module.encoder_t.layer1.2.conv2.weight', 'module.encoder_t.layer1.2.bn2.weight', 'module.encoder_t.layer1.2.bn2.bias', 'module.encoder_t.layer1.2.bn2.running_mean', 'module.encoder_t.layer1.2.bn2.running_var', 'module.encoder_t.layer1.2.bn2.num_batches_tracked', 'module.encoder_t.layer1.2.conv3.weight', 'module.encoder_t.layer1.2.bn3.weight', 'module.encoder_t.layer1.2.bn3.bias', 'module.encoder_t.layer1.2.bn3.running_mean', 'module.encoder_t.layer1.2.bn3.running_var', 'module.encoder_t.layer1.2.bn3.num_batches_tracked', 'module.encoder_t.layer2.0.conv1.weight', 'module.encoder_t.layer2.0.bn1.weight', 'module.encoder_t.layer2.0.bn1.bias', 'module.encoder_t.layer2.0.bn1.running_mean', 'module.encoder_t.layer2.0.bn1.running_var', 'module.encoder_t.layer2.0.bn1.num_batches_tracked', 'module.encoder_t.layer2.0.conv2.weight', 'module.encoder_t.layer2.0.bn2.weight', 'module.encoder_t.layer2.0.bn2.bias', 'module.encoder_t.layer2.0.bn2.running_mean', 'module.encoder_t.layer2.0.bn2.running_var', 'module.encoder_t.layer2.0.bn2.num_batches_tracked', 'module.encoder_t.layer2.0.conv3.weight', 'module.encoder_t.layer2.0.bn3.weight', 'module.encoder_t.layer2.0.bn3.bias', 'module.encoder_t.layer2.0.bn3.running_mean', 'module.encoder_t.layer2.0.bn3.running_var', 'module.encoder_t.layer2.0.bn3.num_batches_tracked', 'module.encoder_t.layer2.0.downsample.0.weight', 'module.encoder_t.layer2.0.downsample.1.weight', 'module.encoder_t.layer2.0.downsample.1.bias', 'module.encoder_t.layer2.0.downsample.1.running_mean', 'module.encoder_t.layer2.0.downsample.1.running_var', 'module.encoder_t.layer2.0.downsample.1.num_batches_tracked', 'module.encoder_t.layer2.1.conv1.weight', 'module.encoder_t.layer2.1.bn1.weight', 'module.encoder_t.layer2.1.bn1.bias', 'module.encoder_t.layer2.1.bn1.running_mean', 'module.encoder_t.layer2.1.bn1.running_var', 'module.encoder_t.layer2.1.bn1.num_batches_tracked', 'module.encoder_t.layer2.1.conv2.weight', 'module.encoder_t.layer2.1.bn2.weight', 'module.encoder_t.layer2.1.bn2.bias', 'module.encoder_t.layer2.1.bn2.running_mean', 'module.encoder_t.layer2.1.bn2.running_var', 'module.encoder_t.layer2.1.bn2.num_batches_tracked', 'module.encoder_t.layer2.1.conv3.weight', 'module.encoder_t.layer2.1.bn3.weight', 'module.encoder_t.layer2.1.bn3.bias', 'module.encoder_t.layer2.1.bn3.running_mean', 'module.encoder_t.layer2.1.bn3.running_var', 'module.encoder_t.layer2.1.bn3.num_batches_tracked', 'module.encoder_t.layer2.2.conv1.weight', 'module.encoder_t.layer2.2.bn1.weight', 'module.encoder_t.layer2.2.bn1.bias', 'module.encoder_t.layer2.2.bn1.running_mean', 'module.encoder_t.layer2.2.bn1.running_var', 'module.encoder_t.layer2.2.bn1.num_batches_tracked', 'module.encoder_t.layer2.2.conv2.weight', 'module.encoder_t.layer2.2.bn2.weight', 'module.encoder_t.layer2.2.bn2.bias', 'module.encoder_t.layer2.2.bn2.running_mean', 'module.encoder_t.layer2.2.bn2.running_var', 'module.encoder_t.layer2.2.bn2.num_batches_tracked', 'module.encoder_t.layer2.2.conv3.weight', 'module.encoder_t.layer2.2.bn3.weight', 'module.encoder_t.layer2.2.bn3.bias', 'module.encoder_t.layer2.2.bn3.running_mean', 'module.encoder_t.layer2.2.bn3.running_var', 'module.encoder_t.layer2.2.bn3.num_batches_tracked', 'module.encoder_t.layer2.3.conv1.weight', 'module.encoder_t.layer2.3.bn1.weight', 'module.encoder_t.layer2.3.bn1.bias', 'module.encoder_t.layer2.3.bn1.running_mean', 'module.encoder_t.layer2.3.bn1.running_var', 'module.encoder_t.layer2.3.bn1.num_batches_tracked', 'module.encoder_t.layer2.3.conv2.weight', 'module.encoder_t.layer2.3.bn2.weight', 'module.encoder_t.layer2.3.bn2.bias', 'module.encoder_t.layer2.3.bn2.running_mean', 'module.encoder_t.layer2.3.bn2.running_var', 'module.encoder_t.layer2.3.bn2.num_batches_tracked', 'module.encoder_t.layer2.3.conv3.weight', 'module.encoder_t.layer2.3.bn3.weight', 'module.encoder_t.layer2.3.bn3.bias', 'module.encoder_t.layer2.3.bn3.running_mean', 'module.encoder_t.layer2.3.bn3.running_var', 'module.encoder_t.layer2.3.bn3.num_batches_tracked', 'module.encoder_t.layer3.0.conv1.weight', 'module.encoder_t.layer3.0.bn1.weight', 'module.encoder_t.layer3.0.bn1.bias', 'module.encoder_t.layer3.0.bn1.running_mean', 'module.encoder_t.layer3.0.bn1.running_var', 'module.encoder_t.layer3.0.bn1.num_batches_tracked', 'module.encoder_t.layer3.0.conv2.weight', 'module.encoder_t.layer3.0.bn2.weight', 'module.encoder_t.layer3.0.bn2.bias', 'module.encoder_t.layer3.0.bn2.running_mean', 'module.encoder_t.layer3.0.bn2.running_var', 'module.encoder_t.layer3.0.bn2.num_batches_tracked', 'module.encoder_t.layer3.0.conv3.weight', 'module.encoder_t.layer3.0.bn3.weight', 'module.encoder_t.layer3.0.bn3.bias', 'module.encoder_t.layer3.0.bn3.running_mean', 'module.encoder_t.layer3.0.bn3.running_var', 'module.encoder_t.layer3.0.bn3.num_batches_tracked', 'module.encoder_t.layer3.0.downsample.0.weight', 'module.encoder_t.layer3.0.downsample.1.weight', 'module.encoder_t.layer3.0.downsample.1.bias', 'module.encoder_t.layer3.0.downsample.1.running_mean', 'module.encoder_t.layer3.0.downsample.1.running_var', 'module.encoder_t.layer3.0.downsample.1.num_batches_tracked', 'module.encoder_t.layer3.1.conv1.weight', 'module.encoder_t.layer3.1.bn1.weight', 'module.encoder_t.layer3.1.bn1.bias', 'module.encoder_t.layer3.1.bn1.running_mean', 'module.encoder_t.layer3.1.bn1.running_var', 'module.encoder_t.layer3.1.bn1.num_batches_tracked', 'module.encoder_t.layer3.1.conv2.weight', 'module.encoder_t.layer3.1.bn2.weight', 'module.encoder_t.layer3.1.bn2.bias', 'module.encoder_t.layer3.1.bn2.running_mean', 'module.encoder_t.layer3.1.bn2.running_var', 'module.encoder_t.layer3.1.bn2.num_batches_tracked', 'module.encoder_t.layer3.1.conv3.weight', 'module.encoder_t.layer3.1.bn3.weight', 'module.encoder_t.layer3.1.bn3.bias', 'module.encoder_t.layer3.1.bn3.running_mean', 'module.encoder_t.layer3.1.bn3.running_var', 'module.encoder_t.layer3.1.bn3.num_batches_tracked', 'module.encoder_t.layer3.2.conv1.weight', 'module.encoder_t.layer3.2.bn1.weight', 'module.encoder_t.layer3.2.bn1.bias', 'module.encoder_t.layer3.2.bn1.running_mean', 'module.encoder_t.layer3.2.bn1.running_var', 'module.encoder_t.layer3.2.bn1.num_batches_tracked', 'module.encoder_t.layer3.2.conv2.weight', 'module.encoder_t.layer3.2.bn2.weight', 'module.encoder_t.layer3.2.bn2.bias', 'module.encoder_t.layer3.2.bn2.running_mean', 'module.encoder_t.layer3.2.bn2.running_var', 'module.encoder_t.layer3.2.bn2.num_batches_tracked', 'module.encoder_t.layer3.2.conv3.weight', 'module.encoder_t.layer3.2.bn3.weight', 'module.encoder_t.layer3.2.bn3.bias', 'module.encoder_t.layer3.2.bn3.running_mean', 'module.encoder_t.layer3.2.bn3.running_var', 'module.encoder_t.layer3.2.bn3.num_batches_tracked', 'module.encoder_t.layer3.3.conv1.weight', 'module.encoder_t.layer3.3.bn1.weight', 'module.encoder_t.layer3.3.bn1.bias', 'module.encoder_t.layer3.3.bn1.running_mean', 'module.encoder_t.layer3.3.bn1.running_var', 'module.encoder_t.layer3.3.bn1.num_batches_tracked', 'module.encoder_t.layer3.3.conv2.weight', 'module.encoder_t.layer3.3.bn2.weight', 'module.encoder_t.layer3.3.bn2.bias', 'module.encoder_t.layer3.3.bn2.running_mean', 'module.encoder_t.layer3.3.bn2.running_var', 'module.encoder_t.layer3.3.bn2.num_batches_tracked', 'module.encoder_t.layer3.3.conv3.weight', 'module.encoder_t.layer3.3.bn3.weight', 'module.encoder_t.layer3.3.bn3.bias', 'module.encoder_t.layer3.3.bn3.running_mean', 'module.encoder_t.layer3.3.bn3.running_var', 'module.encoder_t.layer3.3.bn3.num_batches_tracked', 'module.encoder_t.layer3.4.conv1.weight', 'module.encoder_t.layer3.4.bn1.weight', 'module.encoder_t.layer3.4.bn1.bias', 'module.encoder_t.layer3.4.bn1.running_mean', 'module.encoder_t.layer3.4.bn1.running_var', 'module.encoder_t.layer3.4.bn1.num_batches_tracked', 'module.encoder_t.layer3.4.conv2.weight', 'module.encoder_t.layer3.4.bn2.weight', 'module.encoder_t.layer3.4.bn2.bias', 'module.encoder_t.layer3.4.bn2.running_mean', 'module.encoder_t.layer3.4.bn2.running_var', 'module.encoder_t.layer3.4.bn2.num_batches_tracked', 'module.encoder_t.layer3.4.conv3.weight', 'module.encoder_t.layer3.4.bn3.weight', 'module.encoder_t.layer3.4.bn3.bias', 'module.encoder_t.layer3.4.bn3.running_mean', 'module.encoder_t.layer3.4.bn3.running_var', 'module.encoder_t.layer3.4.bn3.num_batches_tracked', 'module.encoder_t.layer3.5.conv1.weight', 'module.encoder_t.layer3.5.bn1.weight', 'module.encoder_t.layer3.5.bn1.bias', 'module.encoder_t.layer3.5.bn1.running_mean', 'module.encoder_t.layer3.5.bn1.running_var', 'module.encoder_t.layer3.5.bn1.num_batches_tracked', 'module.encoder_t.layer3.5.conv2.weight', 'module.encoder_t.layer3.5.bn2.weight', 'module.encoder_t.layer3.5.bn2.bias', 'module.encoder_t.layer3.5.bn2.running_mean', 'module.encoder_t.layer3.5.bn2.running_var', 'module.encoder_t.layer3.5.bn2.num_batches_tracked', 'module.encoder_t.layer3.5.conv3.weight', 'module.encoder_t.layer3.5.bn3.weight', 'module.encoder_t.layer3.5.bn3.bias', 'module.encoder_t.layer3.5.bn3.running_mean', 'module.encoder_t.layer3.5.bn3.running_var', 'module.encoder_t.layer3.5.bn3.num_batches_tracked', 'module.encoder_t.layer4.0.conv1.weight', 'module.encoder_t.layer4.0.bn1.weight', 'module.encoder_t.layer4.0.bn1.bias', 'module.encoder_t.layer4.0.bn1.running_mean', 'module.encoder_t.layer4.0.bn1.running_var', 'module.encoder_t.layer4.0.bn1.num_batches_tracked', 'module.encoder_t.layer4.0.conv2.weight', 'module.encoder_t.layer4.0.bn2.weight', 'module.encoder_t.layer4.0.bn2.bias', 'module.encoder_t.layer4.0.bn2.running_mean', 'module.encoder_t.layer4.0.bn2.running_var', 'module.encoder_t.layer4.0.bn2.num_batches_tracked', 'module.encoder_t.layer4.0.conv3.weight', 'module.encoder_t.layer4.0.bn3.weight', 'module.encoder_t.layer4.0.bn3.bias', 'module.encoder_t.layer4.0.bn3.running_mean', 'module.encoder_t.layer4.0.bn3.running_var', 'module.encoder_t.layer4.0.bn3.num_batches_tracked', 'module.encoder_t.layer4.0.downsample.0.weight', 'module.encoder_t.layer4.0.downsample.1.weight', 'module.encoder_t.layer4.0.downsample.1.bias', 'module.encoder_t.layer4.0.downsample.1.running_mean', 'module.encoder_t.layer4.0.downsample.1.running_var', 'module.encoder_t.layer4.0.downsample.1.num_batches_tracked', 'module.encoder_t.layer4.1.conv1.weight', 'module.encoder_t.layer4.1.bn1.weight', 'module.encoder_t.layer4.1.bn1.bias', 'module.encoder_t.layer4.1.bn1.running_mean', 'module.encoder_t.layer4.1.bn1.running_var', 'module.encoder_t.layer4.1.bn1.num_batches_tracked', 'module.encoder_t.layer4.1.conv2.weight', 'module.encoder_t.layer4.1.bn2.weight', 'module.encoder_t.layer4.1.bn2.bias', 'module.encoder_t.layer4.1.bn2.running_mean', 'module.encoder_t.layer4.1.bn2.running_var', 'module.encoder_t.layer4.1.bn2.num_batches_tracked', 'module.encoder_t.layer4.1.conv3.weight', 'module.encoder_t.layer4.1.bn3.weight', 'module.encoder_t.layer4.1.bn3.bias', 'module.encoder_t.layer4.1.bn3.running_mean', 'module.encoder_t.layer4.1.bn3.running_var', 'module.encoder_t.layer4.1.bn3.num_batches_tracked', 'module.encoder_t.layer4.2.conv1.weight', 'module.encoder_t.layer4.2.bn1.weight', 'module.encoder_t.layer4.2.bn1.bias', 'module.encoder_t.layer4.2.bn1.running_mean', 'module.encoder_t.layer4.2.bn1.running_var', 'module.encoder_t.layer4.2.bn1.num_batches_tracked', 'module.encoder_t.layer4.2.conv2.weight', 'module.encoder_t.layer4.2.bn2.weight', 'module.encoder_t.layer4.2.bn2.bias', 'module.encoder_t.layer4.2.bn2.running_mean', 'module.encoder_t.layer4.2.bn2.running_var', 'module.encoder_t.layer4.2.bn2.num_batches_tracked', 'module.encoder_t.layer4.2.conv3.weight', 'module.encoder_t.layer4.2.bn3.weight', 'module.encoder_t.layer4.2.bn3.bias', 'module.encoder_t.layer4.2.bn3.running_mean', 'module.encoder_t.layer4.2.bn3.running_var', 'module.encoder_t.layer4.2.bn3.num_batches_tracked', 'module.predict_q.0.weight', 'module.predict_q.0.bias', 'module.predict_q.1.weight', 'module.predict_q.1.bias', 'module.predict_q.1.running_mean', 'module.predict_q.1.running_var', 'module.predict_q.1.num_batches_tracked', 'module.predict_q.3.weight', 'module.predict_q.3.bias'])\n","get train feats =>\n","Test: [0/6]\tTime  1.192 ( 1.192)\n","get val feats =>\n","Test: [0/2]\tTime  0.364 ( 0.364)\n","1\n","eval_knn.py:488: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  pred = np.zeros(I.shape[0], dtype=np.int)\n","eval_knn.py:489: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  conf_mat = np.zeros((1000, 1000), dtype=np.int)\n","=> time : 10.20s\n"," * Acc 50.00\n","20\n","=> time : 10.35s\n"," * Acc 60.87\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"PQYfHE1ykfZQ"},"execution_count":null,"outputs":[]}]}