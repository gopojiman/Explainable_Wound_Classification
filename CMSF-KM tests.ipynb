{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CMSF-KM tests.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"2Kf8dwhPqGxx"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyikNXbYxhq6","executionInfo":{"status":"ok","timestamp":1651085705618,"user_tz":420,"elapsed":1258,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"0ef361b7-b736-46a4-9597-8324c1680900"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}],"source":["#GPU runtime required, should give CUDA version\n","!nvcc --version"]},{"cell_type":"code","source":["!pip install faiss-gpu\n","!pip install fuzzy-c-means"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFauSYcBymkd","executionInfo":{"status":"ok","timestamp":1651085711843,"user_tz":420,"elapsed":5500,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"2b687d93-73b8-42c4-d4ab-dec27705012b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.2)\n","Requirement already satisfied: fuzzy-c-means in /usr/local/lib/python3.7/dist-packages (1.6.3)\n","Requirement already satisfied: typer<0.4.0,>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.3.2)\n","Requirement already satisfied: numpy<2.0.0,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (1.21.6)\n","Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (1.9.0)\n","Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (4.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SA5CzMz1tAp","executionInfo":{"status":"ok","timestamp":1651085715531,"user_tz":420,"elapsed":3695,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"9a98fc31-d5e7-494e-a5c7-cd51aa109631"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!cp -r /content/gdrive/MyDrive/Explainable_Wound_Classification/CMSF/self_supervised/* /content\n","root_path = 'gdrive/MyDrive/Explainable_Wound_Classification/'"],"metadata":{"id":"lu1Z3VWPP2fk","executionInfo":{"status":"ok","timestamp":1651085715531,"user_tz":420,"elapsed":8,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import builtins\n","import os\n","import sys\n","import time\n","import argparse\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torchvision import transforms, datasets, models\n","\n","from PIL import ImageFilter, Image\n","from util import adjust_learning_rate, AverageMeter as AvgMeter, subset_classes\n","import models.resnet as resnet\n","\n","import pdb\n","import faiss\n","from fcmeans import FCM\n","\n","import numpy as np\n","import pandas as pd\n","import re\n","from collections import namedtuple\n","\n","import shutil\n","import warnings\n","\n","import torch.nn.parallel\n","import torch.optim\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","from tools import *"],"metadata":{"id":"sbLSB0x9ypbr","executionInfo":{"status":"ok","timestamp":1651085716930,"user_tz":420,"elapsed":1406,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#CMSF-KM"],"metadata":{"id":"eDcwok-ko9t1"}},{"cell_type":"markdown","source":["### Misc Functions"],"metadata":{"id":"_UM2GHuMpLbF"}},{"cell_type":"code","source":["def get_mlp(inp_dim, hidden_dim, out_dim):\n","    mlp = nn.Sequential(\n","        nn.Linear(inp_dim, hidden_dim),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.ReLU(inplace=True),\n","        nn.Linear(hidden_dim, out_dim),\n","    )\n","    return mlp"],"metadata":{"id":"_kesUL1R3Aey","executionInfo":{"status":"ok","timestamp":1651085716931,"user_tz":420,"elapsed":24,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def faiss_kmeans(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    d = feats.shape[-1]\n","    clus = faiss.Clustering(d, nmb_clusters)\n","    clus.niter = 20\n","    clus.max_points_per_centroid = 10000000\n","\n","    index = faiss.IndexFlatL2(d)\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    index = faiss.index_cpu_to_all_gpus(index, co)\n","\n","    # perform the training\n","    clus.train(feats, index)\n","    _, train_a = index.search(feats, 1)\n","\n","    return list(train_a[:, 0])"],"metadata":{"id":"UQ0DsdOY3ghX","executionInfo":{"status":"ok","timestamp":1651085716931,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def fuzzy_c_means(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    \n","    fcm = FCM(n_clusters=nmb_clusters)\n","    fcm.fit(feats)\n","\n","    return fcm.predict(feats)"],"metadata":{"id":"c3V34JDdO1Ql","executionInfo":{"status":"ok","timestamp":1651085716931,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def get_shuffle_ids(bsz):\n","    \"\"\"generate shuffle ids for ShuffleBN\"\"\"\n","    forward_inds = torch.randperm(bsz).long().cuda()\n","    backward_inds = torch.zeros(bsz).long().cuda()\n","    value = torch.arange(bsz).long().cuda()\n","    backward_inds.index_copy_(0, forward_inds, value)\n","    return forward_inds, backward_inds\n"],"metadata":{"id":"K2ZY6QzB7OrS","executionInfo":{"status":"ok","timestamp":1651085716932,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Model Architecture"],"metadata":{"id":"h0rrgRKnpUr6"}},{"cell_type":"code","source":["class ConstrainedMeanShiftKM(nn.Module):\n","    def __init__(self, arch, m=0.99, mem_bank_size=128000, topk=5, dataset_size=100, num_clusters=50000):\n","        super(ConstrainedMeanShiftKM, self).__init__()\n","\n","        # save parameters\n","        self.m = m\n","        self.mem_bank_size = mem_bank_size\n","        self.topk = topk\n","        self.dataset_size = dataset_size\n","        self.num_clusters = num_clusters\n","\n","        # create encoders and projection layers\n","        # both encoders should have same arch\n","        if 'resnet' in arch:\n","            self.encoder_q = resnet.__dict__[arch]()\n","            self.encoder_t = resnet.__dict__[arch]()\n","\n","        # save output embedding dimensions\n","        # assuming that both encoders have same dim\n","        feat_dim = self.encoder_q.fc.in_features\n","        hidden_dim = feat_dim * 2\n","        proj_dim = feat_dim // 4\n","\n","        # projection layers\n","        self.encoder_t.fc = get_mlp(feat_dim, hidden_dim, proj_dim)\n","        self.encoder_q.fc = get_mlp(feat_dim, hidden_dim, proj_dim)\n","\n","        # prediction layer\n","        self.predict_q = get_mlp(proj_dim, hidden_dim, proj_dim)\n","\n","        # copy query encoder weights to target encoder\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data.copy_(param_q.data)\n","            param_t.requires_grad = False\n","\n","        print(\"using mem-bank size {}\".format(self.mem_bank_size))\n","        # setup queue (For Storing Random Targets)\n","        self.register_buffer('queue', torch.randn(self.mem_bank_size, proj_dim))\n","        self.register_buffer('pool', torch.randn(self.dataset_size, proj_dim))\n","        self.register_buffer('pseudo_labels', 0*torch.ones(self.dataset_size).long())\n","        # normalize the queue embeddings\n","        self.queue = nn.functional.normalize(self.queue, dim=1)\n","        # initialize the labels queue (For Purity measurement)\n","        self.register_buffer('labels', -1*torch.ones(self.mem_bank_size).long())\n","        self.register_buffer('index_queue', -1 * torch.ones(self.mem_bank_size).long())\n","        # setup the queue pointer\n","        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n","\n","    @torch.no_grad()\n","    def _momentum_update_target_encoder(self):\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data = param_t.data * self.m + param_q.data * (1. - self.m)\n","\n","    @torch.no_grad()\n","    def data_parallel(self):\n","        self.encoder_q = torch.nn.DataParallel(self.encoder_q)\n","        self.encoder_t = torch.nn.DataParallel(self.encoder_t)\n","        self.predict_q = torch.nn.DataParallel(self.predict_q)\n","\n","    @torch.no_grad()\n","    def cluster(self):\n","        print('start clustering ... num clusters: {}'.format(self.num_clusters))\n","        cluster_assignment = fuzzy_c_means(self.pool.clone().cpu(), self.num_clusters)\n","        self.pseudo_labels = torch.tensor(cluster_assignment).cuda()\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue(self, targets, labels, indices):\n","        batch_size = targets.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","        assert self.mem_bank_size % batch_size == 0 \n","\n","        # replace the targets at ptr (dequeue and enqueue)\n","        self.pool[indices, :] = targets\n","        self.queue[ptr:ptr + batch_size] = targets\n","        self.labels[ptr:ptr + batch_size] = labels\n","        self.index_queue[ptr:ptr + batch_size] = indices\n","        ptr = (ptr + batch_size) % self.mem_bank_size  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","    def forward(self, im_q, im_t, labels, indices):\n","        # compute query features\n","        feat_q = self.encoder_q(im_q)\n","        # compute predictions for instance level regression loss\n","        query = self.predict_q(feat_q)\n","        query = nn.functional.normalize(query, dim=1)\n","\n","        # compute target features\n","        with torch.no_grad():\n","            # update the target encoder\n","            self._momentum_update_target_encoder()\n","\n","            # shuffle targets\n","            shuffle_ids, reverse_ids = get_shuffle_ids(im_t.shape[0])\n","            im_t = im_t[shuffle_ids]\n","\n","            # forward through the target encoder\n","            current_target = self.encoder_t(im_t)\n","            current_target = nn.functional.normalize(current_target, dim=1)\n","\n","            # undo shuffle\n","            current_target = current_target[reverse_ids].detach()\n","\n","            # update the memory-bank\n","            self._dequeue_and_enqueue(current_target, labels, indices)\n","\n","        targets = self.queue.clone().detach()\n","\n","        # get pseudo of target and memory bank samples\n","        current_target_pseudo_labels = self.pseudo_labels[indices]\n","        targets_pseudo_labels = self.pseudo_labels[self.index_queue]\n","\n","        # create a mask to constrain the search space\n","        b = current_target_pseudo_labels.shape[0]\n","        m = targets_pseudo_labels.shape[0]\n","        lx = current_target_pseudo_labels.unsqueeze(1).expand((b, m))\n","        lm = targets_pseudo_labels.unsqueeze(0).expand((b, m))\n","        msk = lx != lm\n","\n","        # calculate distances between vectors\n","        dist_t = 2 - 2 * torch.einsum('bc,kc->bk', [current_target, targets])\n","        dist_q = 2 - 2 * torch.einsum('bc,kc->bk', [query, targets])\n","\n","        # select the k nearest neighbors [with smallest distance (largest=False)] based on current target\n","        _, unconstrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # select the k nearest neighbors based on constrained memory bank\n","        dist_t[torch.where(msk)] = 5.0\n","        _, constrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # calculate mean shift regression loss\n","        nn_dist_q_constrained = torch.gather(dist_q, 1, constrained_nn_index)\n","        nn_dist_q_unconstrained = torch.gather(dist_q, 1, unconstrained_nn_index)\n","\n","        # purity based on memory bank\n","        labels = labels.unsqueeze(1).expand(nn_dist_q_unconstrained.shape[0], nn_dist_q_unconstrained.shape[1])\n","        labels_queue = self.labels.clone().detach()\n","        labels_queue = labels_queue.unsqueeze(0).expand((nn_dist_q_unconstrained.shape[0], self.mem_bank_size))\n","        labels_queue = torch.gather(labels_queue, dim=1, index=unconstrained_nn_index)\n","# TODO: Change matches here\n","        matches = (labels_queue == labels).float()\n","        purity = (matches.sum(dim=1) / self.topk).mean()\n","\n","        loss = ((nn_dist_q_constrained.sum(dim=1) / self.topk).mean()\n","                + (nn_dist_q_unconstrained.sum(dim=1) / self.topk).mean()) / 2.0\n","\n","        return loss, purity"],"metadata":{"id":"9WrVPdUa3m1Q","executionInfo":{"status":"ok","timestamp":1651085716932,"user_tz":420,"elapsed":21,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Transformations/Data Loading"],"metadata":{"id":"q9gXb5tmpnzD"}},{"cell_type":"code","source":["class TwoCropsTransform:\n","    \"\"\"Take two random crops of one image as the query and target.\"\"\"\n","    def __init__(self, weak_transform, strong_transform):\n","        self.weak_transform = weak_transform\n","        self.strong_transform = strong_transform\n","        print(self.weak_transform)\n","        print(self.strong_transform)\n","\n","    def __call__(self, x):\n","        q = self.strong_transform(x)\n","        t = self.weak_transform(x)\n","        return [q, t]\n","\n","\n","class GaussianBlur(object):\n","    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n","\n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","\n","    def __call__(self, x):\n","        sigma = random.uniform(self.sigma[0], self.sigma[1])\n","        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n","        return x"],"metadata":{"id":"8lqpv_uE7Dsp","executionInfo":{"status":"ok","timestamp":1651085716933,"user_tz":420,"elapsed":21,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class Image_Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, root_dir, label_fn, transform=None):\n","        \"\"\"\n","        Image dataset. Returns tensorized images and labels with index\n","        Args:\n","            root_dir: path to a cropped mouse image dataset.\n","            label_fn: function that returns the correct label given an image name\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.label_fn = label_fn\n","        self.transform = transform\n","\n","        samples = []\n","        targets = []\n","        for f in os.listdir(root_dir):\n","            samples.append(os.path.join(root_dir, f))\n","            targets.append(label_fn(f))\n","        \n","        self.samples = samples\n","        self.targets = targets\n","\n","    def pil_loader(self, path):\n","        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n","        with open(path, 'rb') as f:\n","            img = Image.open(f)\n","            return img.convert('RGB')\n","\n","    def __getitem__(self, index: int):\n","            \"\"\"\n","            Returns index, tensor data, and tensorized label.\n","            \"\"\"\n","            img = self.pil_loader(self.samples[index])\n","            target = self.targets[index]\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return index, img, torch.tensor(target)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __str__(self):\n","        return \"Image_Dataset:\\n\" + \"Found \" + str(len(self)) + \" images in \" + self.root_dir + \"\\n\""],"metadata":{"id":"S7XGxXyYA87o","executionInfo":{"status":"ok","timestamp":1651085716933,"user_tz":420,"elapsed":20,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Create train loader\n","def get_train_loader(datapath, label_fn, batch_size, num_workers, weak_strong=True):\n","    traindir = os.path.join(datapath, 'train')\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","\n","    augmentation_strong = [\n","        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.RandomApply([\n","            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n","        ], p=0.8),\n","        transforms.RandomGrayscale(p=0.2),\n","        transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize\n","    ]\n","\n","    augmentation_weak = [\n","        #transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]\n","\n","    if weak_strong:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_strong))\n","        )\n","    else:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_weak))\n","        )\n","\n","    print('==> train dataset')\n","    print(train_dataset)\n","\n","    # NOTE: remove drop_last\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, shuffle=True,\n","        num_workers=num_workers, pin_memory=True, drop_last=True)\n","\n","    return train_loader"],"metadata":{"id":"5MMumuTc7qmF","executionInfo":{"status":"ok","timestamp":1651085716934,"user_tz":420,"elapsed":20,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"6JT3uvt0pym_"}},{"cell_type":"code","source":["def train(epoch, train_loader, mean_shift, optimizer, print_freq):\n","    \"\"\"\n","    one epoch training\n","    \"\"\"\n","    mean_shift.train()\n","\n","    batch_time = AvgMeter()\n","    data_time = AvgMeter()\n","    loss_meter = AvgMeter()\n","    purity_meter = AvgMeter()\n","\n","    end = time.time()\n","    for idx, (indices, (im_q, im_t), labels) in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","        im_q = im_q.cuda(non_blocking=True)\n","        im_t = im_t.cuda(non_blocking=True)\n","        labels = labels.cuda(non_blocking=True)\n","\n","        # ===================forward=====================\n","        loss, purity = mean_shift(im_q=im_q, im_t=im_t, labels=labels, indices=indices)\n","\n","        # ===================backward=====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ===================meters=====================\n","        loss_meter.update(loss.item(), im_q.size(0))\n","        purity_meter.update(purity.item(), im_q.size(0))\n","\n","        torch.cuda.synchronize()\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        # print info\n","        if (idx + 1) % print_freq == 0:\n","            print('Train: [{0}][{1}/{2}]\\t'\n","                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'purity {purity.val:.3f} ({purity.avg:.3f})\\t'\n","                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'.format(\n","                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                   data_time=data_time,\n","                   purity=purity_meter,\n","                   loss=loss_meter))\n","            sys.stdout.flush()\n","            sys.stdout.flush()\n","\n","    return loss_meter.avg"],"metadata":{"id":"kbeHAYjbVSaV","executionInfo":{"status":"ok","timestamp":1651085716934,"user_tz":420,"elapsed":20,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#workaround struct to pass args to util script\n","LRArgs = namedtuple('LRArgs', ['cos', 'learning_rate', 'epochs', 'lr_decay_rate'])"],"metadata":{"id":"rXCJ1Q94dBEZ","executionInfo":{"status":"ok","timestamp":1651085716935,"user_tz":420,"elapsed":19,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def cmsf_km_main(data_path, checkpoint_path, label_fn, batch_size=16, num_workers=2, \n","                 epochs=200, print_freq=10, save_freq=10, weak_strong=True, \n","                 debug=False, arch='resnet50', momentum=0.99, mem_bank_size=128000, \n","                 topk=5, num_clusters=4, learning_rate=0.05, sgd_momentum=0.9, \n","                 weight_decay=1e-4, weights=None, resume=None, cos=True, \n","                 lr_decay_rate=0.2):\n","    \"\"\"\n","    todo: docstring\n","    \"\"\"\n","    opt = locals()\n","    del opt['label_fn']\n","\n","    os.makedirs(checkpoint_path, exist_ok=True)\n","\n","    train_loader = get_train_loader(data_path, label_fn, batch_size, num_workers, weak_strong)\n","\n","    mean_shift = ConstrainedMeanShiftKM(\n","        arch,\n","        m=momentum,\n","        mem_bank_size=mem_bank_size,\n","        topk=topk,\n","        dataset_size=len(train_loader.dataset),\n","        num_clusters=num_clusters\n","    )\n","\n","    mean_shift.data_parallel()\n","    mean_shift = mean_shift.cuda()\n","    print(mean_shift)\n","\n","    params = [p for p in mean_shift.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params,\n","                                lr=learning_rate,\n","                                momentum=sgd_momentum,\n","                                weight_decay=weight_decay)\n","\n","    cudnn.benchmark = True\n","    start_epoch = 1\n","\n","    if weights:\n","        print('==> load weights from checkpoint: {}'.format(weights))\n","        ckpt = torch.load(weights)\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        if 'model' in ckpt:\n","            sd = ckpt['model']\n","        else:\n","            sd = ckpt['state_dict']\n","        msg = mean_shift.load_state_dict(sd, strict=False)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        start_epoch = ckpt['epoch'] + 1\n","        print(msg)\n","\n","    if resume:\n","        print('==> resume from checkpoint: {}'.format(resume))\n","        ckpt = torch.load(resume, map_location='cpu')\n","        # sd = ckpt['state_dict']\n","        # sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        mean_shift.load_state_dict(ckpt['state_dict'], strict=True)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        start_epoch = ckpt['epoch'] + 1\n","\n","    lr_args = LRArgs(cos, learning_rate, epochs, lr_decay_rate)\n","\n","    for epoch in range(start_epoch, epochs + 1):\n","\n","        adjust_learning_rate(epoch, lr_args, optimizer)\n","        print(\"==> training...\")\n","\n","        time1 = time.time()\n","\n","        train(epoch, train_loader, mean_shift, optimizer, print_freq)\n","        mean_shift.cluster()\n","        time2 = time.time()\n","        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n","\n","        # saving the model\n","        if epoch % save_freq == 0:\n","            print('==> Saving...')\n","            state = {\n","                'opt': opt,\n","                'state_dict': mean_shift.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epoch,\n","            }\n","\n","            save_file = os.path.join(checkpoint_path, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n","            torch.save(state, save_file)\n","\n","            # help release GPU memory\n","            del state\n","            torch.cuda.empty_cache()"],"metadata":{"id":"nbS9piVdV8T_","executionInfo":{"status":"ok","timestamp":1651085716935,"user_tz":420,"elapsed":18,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# CMSF-KM Training"],"metadata":{"id":"55w0V6ivp5AT"}},{"cell_type":"code","source":["cmsf_km_main(\n","    data_path=root_path + 'Split_images', \n","    checkpoint_path=root_path + 'outputs/fuzzy_c_1', \n","    label_fn=lambda x: np.array(0),\n","    batch_size=16,\n","    num_workers=2,\n","    epochs=100,\n","    arch='resnet50',\n","    topk=6,\n","    num_clusters=4,\n","    learning_rate=0.05,\n","    mem_bank_size=128000,\n","    weak_strong=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udb2Oop0jJ7y","outputId":"fe2bff47-16d2-41f0-8af7-70431ab3900e","executionInfo":{"status":"ok","timestamp":1651086088080,"user_tz":420,"elapsed":371162,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    RandomHorizontalFlip(p=0.5)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    RandomHorizontalFlip(p=0.5)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","==> train dataset\n","Image_Dataset:\n","Found 191 images in gdrive/MyDrive/Explainable_Wound_Classification/Split_images/train\n","\n","using mem-bank size 128000\n","ConstrainedMeanShiftKM(\n","  (encoder_q): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","      (fc): Sequential(\n","        (0): Linear(in_features=2048, out_features=4096, bias=True)\n","        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Linear(in_features=4096, out_features=512, bias=True)\n","      )\n","    )\n","  )\n","  (encoder_t): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","      (fc): Sequential(\n","        (0): Linear(in_features=2048, out_features=4096, bias=True)\n","        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Linear(in_features=4096, out_features=512, bias=True)\n","      )\n","    )\n","  )\n","  (predict_q): DataParallel(\n","    (module): Sequential(\n","      (0): Linear(in_features=512, out_features=4096, bias=True)\n","      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=4096, out_features=512, bias=True)\n","    )\n","  )\n",")\n","LR: 0.05\n","==> training...\n","Train: [1][10/11]\tBT 0.237 (0.408)\tDT 0.000 (0.047)\tpurity 1.000 (0.996)\tloss 0.442 (0.704)\t\n","start clustering ... num clusters: 4\n","epoch 1, total time 4.81\n","LR: 0.04998766400914329\n","==> training...\n","Train: [2][10/11]\tBT 0.233 (0.272)\tDT 0.000 (0.028)\tpurity 1.000 (1.000)\tloss 0.475 (0.493)\t\n","start clustering ... num clusters: 4\n","epoch 2, total time 3.17\n","LR: 0.04995066821070679\n","==> training...\n","Train: [3][10/11]\tBT 0.239 (0.273)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.352 (0.425)\t\n","start clustering ... num clusters: 4\n","epoch 3, total time 3.36\n","LR: 0.049889049115077\n","==> training...\n","Train: [4][10/11]\tBT 0.238 (0.275)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.160 (0.280)\t\n","start clustering ... num clusters: 4\n","epoch 4, total time 3.24\n","LR: 0.04980286753286195\n","==> training...\n","Train: [5][10/11]\tBT 0.242 (0.278)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.315 (0.302)\t\n","start clustering ... num clusters: 4\n","epoch 5, total time 3.44\n","LR: 0.04969220851487845\n","==> training...\n","Train: [6][10/11]\tBT 0.241 (0.275)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.132 (0.208)\t\n","start clustering ... num clusters: 4\n","epoch 6, total time 3.24\n","LR: 0.049557181268217225\n","==> training...\n","Train: [7][10/11]\tBT 0.242 (0.278)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.153 (0.130)\t\n","start clustering ... num clusters: 4\n","epoch 7, total time 3.49\n","LR: 0.049397919048468686\n","==> training...\n","Train: [8][10/11]\tBT 0.247 (0.280)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.145 (0.110)\t\n","start clustering ... num clusters: 4\n","epoch 8, total time 3.34\n","LR: 0.04921457902821578\n","==> training...\n","Train: [9][10/11]\tBT 0.243 (0.281)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.167 (0.122)\t\n","start clustering ... num clusters: 4\n","epoch 9, total time 3.44\n","LR: 0.04900734214192358\n","==> training...\n","Train: [10][10/11]\tBT 0.244 (0.286)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.111 (0.076)\t\n","start clustering ... num clusters: 4\n","epoch 10, total time 3.41\n","==> Saving...\n","LR: 0.048776412907378844\n","==> training...\n","Train: [11][10/11]\tBT 0.245 (0.286)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.012 (0.062)\t\n","start clustering ... num clusters: 4\n","epoch 11, total time 3.30\n","LR: 0.04852201922385564\n","==> training...\n","Train: [12][10/11]\tBT 0.239 (0.279)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.014 (0.059)\t\n","start clustering ... num clusters: 4\n","epoch 12, total time 3.48\n","LR: 0.04824441214720629\n","==> training...\n","Train: [13][10/11]\tBT 0.242 (0.286)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.013 (0.052)\t\n","start clustering ... num clusters: 4\n","epoch 13, total time 3.44\n","LR: 0.04794386564209953\n","==> training...\n","Train: [14][10/11]\tBT 0.243 (0.291)\tDT 0.000 (0.039)\tpurity 1.000 (1.000)\tloss 0.005 (0.061)\t\n","start clustering ... num clusters: 4\n","epoch 14, total time 3.39\n","LR: 0.04762067631165049\n","==> training...\n","Train: [15][10/11]\tBT 0.238 (0.282)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.103 (0.084)\t\n","start clustering ... num clusters: 4\n","epoch 15, total time 3.33\n","LR: 0.047275163104709195\n","==> training...\n","Train: [16][10/11]\tBT 0.239 (0.287)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.012 (0.024)\t\n","start clustering ... num clusters: 4\n","epoch 16, total time 3.45\n","LR: 0.04690766700109659\n","==> training...\n","Train: [17][10/11]\tBT 0.242 (0.290)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.003 (0.055)\t\n","start clustering ... num clusters: 4\n","epoch 17, total time 3.34\n","LR: 0.046518550675098594\n","==> training...\n","Train: [18][10/11]\tBT 0.236 (0.276)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.004 (0.077)\t\n","start clustering ... num clusters: 4\n","epoch 18, total time 3.32\n","LR: 0.04610819813755038\n","==> training...\n","Train: [19][10/11]\tBT 0.237 (0.277)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.002 (0.033)\t\n","start clustering ... num clusters: 4\n","epoch 19, total time 3.40\n","LR: 0.04567701435686405\n","==> training...\n","Train: [20][10/11]\tBT 0.235 (0.278)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.022 (0.079)\t\n","start clustering ... num clusters: 4\n","epoch 20, total time 3.28\n","==> Saving...\n","LR: 0.04522542485937369\n","==> training...\n","Train: [21][10/11]\tBT 0.238 (0.285)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.003 (0.035)\t\n","start clustering ... num clusters: 4\n","epoch 21, total time 3.26\n","LR: 0.04475387530939226\n","==> training...\n","Train: [22][10/11]\tBT 0.239 (0.277)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.003 (0.014)\t\n","start clustering ... num clusters: 4\n","epoch 22, total time 3.21\n","LR: 0.044262831069394735\n","==> training...\n","Train: [23][10/11]\tBT 0.237 (0.279)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.012 (0.035)\t\n","start clustering ... num clusters: 4\n","epoch 23, total time 3.21\n","LR: 0.043752776740761494\n","==> training...\n","Train: [24][10/11]\tBT 0.238 (0.285)\tDT 0.000 (0.037)\tpurity 1.000 (1.000)\tloss 0.001 (0.050)\t\n","start clustering ... num clusters: 4\n","epoch 24, total time 3.37\n","LR: 0.04322421568553529\n","==> training...\n","Train: [25][10/11]\tBT 0.239 (0.288)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.002 (0.105)\t\n","start clustering ... num clusters: 4\n","epoch 25, total time 3.68\n","LR: 0.04267766952966369\n","==> training...\n","Train: [26][10/11]\tBT 0.237 (0.284)\tDT 0.000 (0.037)\tpurity 1.000 (1.000)\tloss 0.060 (0.043)\t\n","start clustering ... num clusters: 4\n","epoch 26, total time 3.30\n","LR: 0.04211367764821722\n","==> training...\n","Train: [27][10/11]\tBT 0.242 (0.287)\tDT 0.000 (0.038)\tpurity 1.000 (1.000)\tloss 0.034 (0.073)\t\n","start clustering ... num clusters: 4\n","epoch 27, total time 3.38\n","LR: 0.0415327966330913\n","==> training...\n","Train: [28][10/11]\tBT 0.240 (0.280)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.004 (0.058)\t\n","start clustering ... num clusters: 4\n","epoch 28, total time 3.38\n","LR: 0.040935599743717244\n","==> training...\n","Train: [29][10/11]\tBT 0.238 (0.279)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.014 (0.039)\t\n","start clustering ... num clusters: 4\n","epoch 29, total time 3.24\n","LR: 0.040322676341324415\n","==> training...\n","Train: [30][10/11]\tBT 0.239 (0.275)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.004 (0.082)\t\n","start clustering ... num clusters: 4\n","epoch 30, total time 3.21\n","==> Saving...\n","LR: 0.03969463130731184\n","==> training...\n","Train: [31][10/11]\tBT 0.243 (0.282)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.056 (0.038)\t\n","start clustering ... num clusters: 4\n","epoch 31, total time 3.24\n","LR: 0.03905208444630327\n","==> training...\n","Train: [32][10/11]\tBT 0.239 (0.278)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.090 (0.059)\t\n","start clustering ... num clusters: 4\n","epoch 32, total time 3.30\n","LR: 0.038395669874474916\n","==> training...\n","Train: [33][10/11]\tBT 0.241 (0.285)\tDT 0.000 (0.037)\tpurity 1.000 (1.000)\tloss 0.004 (0.025)\t\n","start clustering ... num clusters: 4\n","epoch 33, total time 3.34\n","LR: 0.03772603539375929\n","==> training...\n","Train: [34][10/11]\tBT 0.242 (0.291)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.005 (0.019)\t\n","start clustering ... num clusters: 4\n","epoch 34, total time 3.35\n","LR: 0.037043841852542884\n","==> training...\n","Train: [35][10/11]\tBT 0.245 (0.285)\tDT 0.001 (0.035)\tpurity 1.000 (1.000)\tloss 0.053 (0.038)\t\n","start clustering ... num clusters: 4\n","epoch 35, total time 3.32\n","LR: 0.03634976249348867\n","==> training...\n","Train: [36][10/11]\tBT 0.240 (0.293)\tDT 0.000 (0.039)\tpurity 1.000 (1.000)\tloss 0.002 (0.007)\t\n","start clustering ... num clusters: 4\n","epoch 36, total time 3.38\n","LR: 0.03564448228912682\n","==> training...\n","Train: [37][10/11]\tBT 0.240 (0.284)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.005 (0.064)\t\n","start clustering ... num clusters: 4\n","epoch 37, total time 3.28\n","LR: 0.034928697265869516\n","==> training...\n","Train: [38][10/11]\tBT 0.239 (0.279)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.008 (0.047)\t\n","start clustering ... num clusters: 4\n","epoch 38, total time 3.29\n","LR: 0.03420311381711696\n","==> training...\n","Train: [39][10/11]\tBT 0.238 (0.275)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.056 (0.054)\t\n","start clustering ... num clusters: 4\n","epoch 39, total time 3.21\n","LR: 0.033468448006132294\n","==> training...\n","Train: [40][10/11]\tBT 0.239 (0.276)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.004 (0.025)\t\n","start clustering ... num clusters: 4\n","epoch 40, total time 3.20\n","==> Saving...\n","LR: 0.032725424859373686\n","==> training...\n","Train: [41][10/11]\tBT 0.243 (0.280)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.020 (0.060)\t\n","start clustering ... num clusters: 4\n","epoch 41, total time 3.34\n","LR: 0.03197477765098074\n","==> training...\n","Train: [42][10/11]\tBT 0.238 (0.277)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.105 (0.028)\t\n","start clustering ... num clusters: 4\n","epoch 42, total time 3.24\n","LR: 0.031217247179121367\n","==> training...\n","Train: [43][10/11]\tBT 0.241 (0.285)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.039 (0.015)\t\n","start clustering ... num clusters: 4\n","epoch 43, total time 3.46\n","LR: 0.03045358103491357\n","==> training...\n","Train: [44][10/11]\tBT 0.240 (0.285)\tDT 0.000 (0.037)\tpurity 1.000 (1.000)\tloss 0.002 (0.031)\t\n","start clustering ... num clusters: 4\n","epoch 44, total time 3.43\n","LR: 0.02968453286464312\n","==> training...\n","Train: [45][10/11]\tBT 0.240 (0.283)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.177 (0.081)\t\n","start clustering ... num clusters: 4\n","epoch 45, total time 3.28\n","LR: 0.028910861626005774\n","==> training...\n","Train: [46][10/11]\tBT 0.241 (0.287)\tDT 0.000 (0.040)\tpurity 1.000 (1.000)\tloss 0.143 (0.030)\t\n","start clustering ... num clusters: 4\n","epoch 46, total time 3.25\n","LR: 0.028133330839107615\n","==> training...\n","Train: [47][10/11]\tBT 0.237 (0.283)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.177 (0.025)\t\n","start clustering ... num clusters: 4\n","epoch 47, total time 3.33\n","LR: 0.02735270783296286\n","==> training...\n","Train: [48][10/11]\tBT 0.237 (0.276)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.002 (0.016)\t\n","start clustering ... num clusters: 4\n","epoch 48, total time 3.23\n","LR: 0.02656976298823284\n","==> training...\n","Train: [49][10/11]\tBT 0.240 (0.271)\tDT 0.000 (0.029)\tpurity 1.000 (1.000)\tloss 0.002 (0.031)\t\n","start clustering ... num clusters: 4\n","epoch 49, total time 3.28\n","LR: 0.02578526897695321\n","==> training...\n","Train: [50][10/11]\tBT 0.239 (0.276)\tDT 0.000 (0.029)\tpurity 1.000 (1.000)\tloss 0.043 (0.020)\t\n","start clustering ... num clusters: 4\n","epoch 50, total time 3.22\n","==> Saving...\n","LR: 0.025\n","==> training...\n","Train: [51][10/11]\tBT 0.240 (0.281)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.003 (0.013)\t\n","start clustering ... num clusters: 4\n","epoch 51, total time 3.29\n","LR: 0.024214731023046793\n","==> training...\n","Train: [52][10/11]\tBT 0.238 (0.273)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.003 (0.017)\t\n","start clustering ... num clusters: 4\n","epoch 52, total time 3.33\n","LR: 0.023430237011767167\n","==> training...\n","Train: [53][10/11]\tBT 0.239 (0.282)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.008 (0.029)\t\n","start clustering ... num clusters: 4\n","epoch 53, total time 3.30\n","LR: 0.022647292167037144\n","==> training...\n","Train: [54][10/11]\tBT 0.240 (0.281)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.133 (0.024)\t\n","start clustering ... num clusters: 4\n","epoch 54, total time 3.22\n","LR: 0.0218666691608924\n","==> training...\n","Train: [55][10/11]\tBT 0.247 (0.282)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.001 (0.027)\t\n","start clustering ... num clusters: 4\n","epoch 55, total time 3.26\n","LR: 0.021089138373994232\n","==> training...\n","Train: [56][10/11]\tBT 0.239 (0.284)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.188 (0.049)\t\n","start clustering ... num clusters: 4\n","epoch 56, total time 3.29\n","LR: 0.020315467135356886\n","==> training...\n","Train: [57][10/11]\tBT 0.243 (0.284)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.139 (0.052)\t\n","start clustering ... num clusters: 4\n","epoch 57, total time 3.27\n","LR: 0.019546418965086444\n","==> training...\n","Train: [58][10/11]\tBT 0.240 (0.282)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.048 (0.047)\t\n","start clustering ... num clusters: 4\n","epoch 58, total time 3.30\n","LR: 0.01878275282087863\n","==> training...\n","Train: [59][10/11]\tBT 0.242 (0.278)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.023 (0.005)\t\n","start clustering ... num clusters: 4\n","epoch 59, total time 3.38\n","LR: 0.018025222349019272\n","==> training...\n","Train: [60][10/11]\tBT 0.240 (0.279)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.001 (0.006)\t\n","start clustering ... num clusters: 4\n","epoch 60, total time 3.25\n","==> Saving...\n","LR: 0.017274575140626323\n","==> training...\n","Train: [61][10/11]\tBT 0.237 (0.292)\tDT 0.000 (0.047)\tpurity 1.000 (1.000)\tloss 0.013 (0.033)\t\n","start clustering ... num clusters: 4\n","epoch 61, total time 3.38\n","LR: 0.016531551993867716\n","==> training...\n","Train: [62][10/11]\tBT 0.239 (0.274)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.118 (0.062)\t\n","start clustering ... num clusters: 4\n","epoch 62, total time 3.18\n","LR: 0.01579688618288306\n","==> training...\n","Train: [63][10/11]\tBT 0.242 (0.279)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.001 (0.007)\t\n","start clustering ... num clusters: 4\n","epoch 63, total time 3.31\n","LR: 0.015071302734130482\n","==> training...\n","Train: [64][10/11]\tBT 0.240 (0.286)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.001 (0.010)\t\n","start clustering ... num clusters: 4\n","epoch 64, total time 3.49\n","LR: 0.014355517710873185\n","==> training...\n","Train: [65][10/11]\tBT 0.238 (0.285)\tDT 0.000 (0.039)\tpurity 1.000 (1.000)\tloss 0.001 (0.049)\t\n","start clustering ... num clusters: 4\n","epoch 65, total time 3.45\n","LR: 0.013650237506511332\n","==> training...\n","Train: [66][10/11]\tBT 0.240 (0.281)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.004 (0.022)\t\n","start clustering ... num clusters: 4\n","epoch 66, total time 3.43\n","LR: 0.012956158147457115\n","==> training...\n","Train: [67][10/11]\tBT 0.237 (0.286)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.009 (0.010)\t\n","start clustering ... num clusters: 4\n","epoch 67, total time 3.29\n","LR: 0.012273964606240717\n","==> training...\n","Train: [68][10/11]\tBT 0.240 (0.276)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.002 (0.008)\t\n","start clustering ... num clusters: 4\n","epoch 68, total time 3.29\n","LR: 0.01160433012552508\n","==> training...\n","Train: [69][10/11]\tBT 0.239 (0.276)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.005 (0.007)\t\n","start clustering ... num clusters: 4\n","epoch 69, total time 3.22\n","LR: 0.010947915553696733\n","==> training...\n","Train: [70][10/11]\tBT 0.238 (0.275)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.007 (0.027)\t\n","start clustering ... num clusters: 4\n","epoch 70, total time 3.37\n","==> Saving...\n","LR: 0.010305368692688175\n","==> training...\n","Train: [71][10/11]\tBT 0.239 (0.294)\tDT 0.000 (0.047)\tpurity 1.000 (1.000)\tloss 0.004 (0.011)\t\n","start clustering ... num clusters: 4\n","epoch 71, total time 3.47\n","LR: 0.009677323658675586\n","==> training...\n","Train: [72][10/11]\tBT 0.236 (0.274)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.001 (0.031)\t\n","start clustering ... num clusters: 4\n","epoch 72, total time 3.29\n","LR: 0.009064400256282757\n","==> training...\n","Train: [73][10/11]\tBT 0.242 (0.278)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.007 (0.023)\t\n","start clustering ... num clusters: 4\n","epoch 73, total time 3.38\n","LR: 0.008467203366908708\n","==> training...\n","Train: [74][10/11]\tBT 0.238 (0.281)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.001 (0.031)\t\n","start clustering ... num clusters: 4\n","epoch 74, total time 3.51\n","LR: 0.007886322351782783\n","==> training...\n","Train: [75][10/11]\tBT 0.240 (0.284)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.002 (0.012)\t\n","start clustering ... num clusters: 4\n","epoch 75, total time 3.32\n","LR: 0.0073223304703363135\n","==> training...\n","Train: [76][10/11]\tBT 0.245 (0.292)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.002 (0.003)\t\n","start clustering ... num clusters: 4\n","epoch 76, total time 3.47\n","LR: 0.006775784314464717\n","==> training...\n","Train: [77][10/11]\tBT 0.242 (0.285)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.026 (0.027)\t\n","start clustering ... num clusters: 4\n","epoch 77, total time 3.41\n","LR: 0.0062472232592385105\n","==> training...\n","Train: [78][10/11]\tBT 0.240 (0.281)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.008 (0.013)\t\n","start clustering ... num clusters: 4\n","epoch 78, total time 3.27\n","LR: 0.005737168930605272\n","==> training...\n","Train: [79][10/11]\tBT 0.238 (0.274)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.002 (0.017)\t\n","start clustering ... num clusters: 4\n","epoch 79, total time 3.21\n","LR: 0.00524612469060774\n","==> training...\n","Train: [80][10/11]\tBT 0.239 (0.277)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.003 (0.005)\t\n","start clustering ... num clusters: 4\n","epoch 80, total time 3.28\n","==> Saving...\n","LR: 0.004774575140626317\n","==> training...\n","Train: [81][10/11]\tBT 0.243 (0.284)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.007 (0.009)\t\n","start clustering ... num clusters: 4\n","epoch 81, total time 3.28\n","LR: 0.004322985643135957\n","==> training...\n","Train: [82][10/11]\tBT 0.238 (0.274)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.002 (0.007)\t\n","start clustering ... num clusters: 4\n","epoch 82, total time 3.17\n","LR: 0.003891801862449629\n","==> training...\n","Train: [83][10/11]\tBT 0.240 (0.279)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.001 (0.010)\t\n","start clustering ... num clusters: 4\n","epoch 83, total time 3.22\n","LR: 0.0034814493249014063\n","==> training...\n","Train: [84][10/11]\tBT 0.240 (0.287)\tDT 0.000 (0.039)\tpurity 1.000 (1.000)\tloss 0.006 (0.009)\t\n","start clustering ... num clusters: 4\n","epoch 84, total time 3.43\n","LR: 0.0030923329989034107\n","==> training...\n","Train: [85][10/11]\tBT 0.238 (0.284)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.014 (0.011)\t\n","start clustering ... num clusters: 4\n","epoch 85, total time 3.32\n","LR: 0.0027248368952908055\n","==> training...\n","Train: [86][10/11]\tBT 0.241 (0.285)\tDT 0.000 (0.035)\tpurity 1.000 (1.000)\tloss 0.010 (0.005)\t\n","start clustering ... num clusters: 4\n","epoch 86, total time 3.33\n","LR: 0.0023793236883495163\n","==> training...\n","Train: [87][10/11]\tBT 0.239 (0.281)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.003 (0.005)\t\n","start clustering ... num clusters: 4\n","epoch 87, total time 3.51\n","LR: 0.0020561343579004773\n","==> training...\n","Train: [88][10/11]\tBT 0.238 (0.275)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.002 (0.006)\t\n","start clustering ... num clusters: 4\n","epoch 88, total time 3.20\n","LR: 0.0017555878527937164\n","==> training...\n","Train: [89][10/11]\tBT 0.238 (0.275)\tDT 0.000 (0.032)\tpurity 1.000 (1.000)\tloss 0.001 (0.006)\t\n","start clustering ... num clusters: 4\n","epoch 89, total time 3.23\n","LR: 0.0014779807761443637\n","==> training...\n","Train: [90][10/11]\tBT 0.240 (0.276)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.006 (0.007)\t\n","start clustering ... num clusters: 4\n","epoch 90, total time 3.32\n","==> Saving...\n","LR: 0.0012235870926211618\n","==> training...\n","Train: [91][10/11]\tBT 0.239 (0.281)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.006 (0.012)\t\n","start clustering ... num clusters: 4\n","epoch 91, total time 3.30\n","LR: 0.0009926578580764262\n","==> training...\n","Train: [92][10/11]\tBT 0.239 (0.278)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.018 (0.012)\t\n","start clustering ... num clusters: 4\n","epoch 92, total time 3.37\n","LR: 0.0007854209717842259\n","==> training...\n","Train: [93][10/11]\tBT 0.239 (0.275)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.001 (0.008)\t\n","start clustering ... num clusters: 4\n","epoch 93, total time 3.32\n","LR: 0.0006020809515313169\n","==> training...\n","Train: [94][10/11]\tBT 0.241 (0.283)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.009 (0.015)\t\n","start clustering ... num clusters: 4\n","epoch 94, total time 3.29\n","LR: 0.000442818731782782\n","==> training...\n","Train: [95][10/11]\tBT 0.240 (0.286)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.001 (0.013)\t\n","start clustering ... num clusters: 4\n","epoch 95, total time 3.32\n","LR: 0.00030779148512155856\n","==> training...\n","Train: [96][10/11]\tBT 0.240 (0.284)\tDT 0.000 (0.034)\tpurity 1.000 (1.000)\tloss 0.001 (0.008)\t\n","start clustering ... num clusters: 4\n","epoch 96, total time 3.35\n","LR: 0.0001971324671380559\n","==> training...\n","Train: [97][10/11]\tBT 0.239 (0.285)\tDT 0.000 (0.036)\tpurity 1.000 (1.000)\tloss 0.002 (0.008)\t\n","start clustering ... num clusters: 4\n","epoch 97, total time 3.42\n","LR: 0.0001109508849230001\n","==> training...\n","Train: [98][10/11]\tBT 0.238 (0.276)\tDT 0.000 (0.033)\tpurity 1.000 (1.000)\tloss 0.008 (0.017)\t\n","start clustering ... num clusters: 4\n","epoch 98, total time 3.19\n","LR: 4.933178929321103e-05\n","==> training...\n","Train: [99][10/11]\tBT 0.239 (0.278)\tDT 0.000 (0.031)\tpurity 1.000 (1.000)\tloss 0.012 (0.005)\t\n","start clustering ... num clusters: 4\n","epoch 99, total time 3.25\n","LR: 1.233599085671e-05\n","==> training...\n","Train: [100][10/11]\tBT 0.238 (0.274)\tDT 0.000 (0.030)\tpurity 1.000 (1.000)\tloss 0.004 (0.006)\t\n","start clustering ... num clusters: 4\n","epoch 100, total time 3.49\n","==> Saving...\n"]}]},{"cell_type":"markdown","source":["# Linear Evaluation"],"metadata":{"id":"rWpGZ0dmqWqI"}},{"cell_type":"markdown","source":["### Misc Setup"],"metadata":{"id":"VzeXb2y52ktA"}},{"cell_type":"code","source":["def load_weights(model, wts_path):\n","    wts = torch.load(wts_path)\n","    # pdb.set_trace()\n","    if 'state_dict' in wts:\n","        ckpt = wts['state_dict']\n","    elif 'model' in wts:\n","        ckpt = wts['model']\n","    else:\n","        ckpt = wts\n","\n","    ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n","    ckpt = {k: v for k, v in ckpt.items() if 'encoder_t' not in k}\n","    ckpt = {k.replace('encoder_q.', ''): v for k, v in ckpt.items()}\n","    state_dict = {}\n","\n","    for m_key, m_val in model.state_dict().items():\n","        if m_key in ckpt:\n","            state_dict[m_key] = ckpt[m_key]\n","        else:\n","            state_dict[m_key] = m_val\n","            print('not copied => ' + m_key)\n","\n","    model.load_state_dict(state_dict)"],"metadata":{"id":"6Edp6TK5qbKw","executionInfo":{"status":"ok","timestamp":1651086088083,"user_tz":420,"elapsed":28,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def get_model(arch, wts_path):\n","    if arch == 'alexnet':\n","        model = AlexNet()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif arch == 'pt_alexnet':\n","        model = models.alexnet()\n","        classif = list(model.classifier.children())[:5]\n","        model.classifier = nn.Sequential(*classif)\n","        load_weights(model, wts_path)\n","    elif arch == 'mobilenet':\n","        model = MobileNetV2()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    elif 'sup_resnet' in arch:\n","        model = models.__dict__[arch.replace('sup_', '')](pretrained=True)\n","        model.fc = nn.Sequential()\n","    elif 'resnet' in arch:\n","        model = models.__dict__[arch]()\n","        model.fc = nn.Sequential()\n","        load_weights(model, wts_path)\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","\n","    for p in model.parameters():\n","        p.requires_grad = False\n","\n","    return model"],"metadata":{"id":"llr6zKaHv_Mw","executionInfo":{"status":"ok","timestamp":1651086088084,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class Normalize(nn.Module):\n","    def forward(self, x):\n","        return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","class FullBatchNorm(nn.Module):\n","    def __init__(self, var, mean):\n","        super(FullBatchNorm, self).__init__()\n","        self.register_buffer('inv_std', (1.0 / torch.sqrt(var + 1e-5)))\n","        self.register_buffer('mean', mean)\n","\n","    def forward(self, x):\n","        return (x - self.mean) * self.inv_std"],"metadata":{"id":"L35H3XpAwAPY","executionInfo":{"status":"ok","timestamp":1651086088084,"user_tz":420,"elapsed":24,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_channels(arch):\n","    if arch == 'alexnet':\n","        c = 4096\n","    elif arch == 'pt_alexnet':\n","        c = 4096\n","    elif 'resnet50' in arch:\n","        c = 2048\n","    elif arch == 'resnet18':\n","        c = 512\n","    elif arch == 'mobilenet':\n","        c = 1280\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","    return c"],"metadata":{"id":"EJrHmVbWwOuX","executionInfo":{"status":"ok","timestamp":1651086088085,"user_tz":420,"elapsed":24,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)"],"metadata":{"id":"_G27DtRTwbnw","executionInfo":{"status":"ok","timestamp":1651086088086,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def get_feats(loader, model, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, ptr = None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = normalize(model(images)).cpu()\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets.argmax(axis=1))\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","    return feats, labels"],"metadata":{"id":"ue02EocuyLgy","executionInfo":{"status":"ok","timestamp":1651086088088,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"uYvYec8y2n8g"}},{"cell_type":"code","source":["def train(train_loader, backbone, linear, optimizer, epoch, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(train_loader),\n","        [batch_time, data_time, losses, top1, top2],\n","        prefix=\"Epoch: [{}]\".format(epoch))\n","\n","    # switch to train mode\n","    backbone.eval()\n","    linear.train()\n","\n","    end = time.time()\n","    for i, (indices, images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # compute output\n","        with torch.no_grad():\n","            output = backbone(images)\n","        output = linear(output)\n","        loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","        # measure accuracy and record loss\n","        acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","        losses.update(loss.item(), images.size(0))\n","        top1.update(acc1[0], images.size(0))\n","        top2.update(acc2[0], images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            logger.info(progress.display(i))"],"metadata":{"id":"1gWHh9br2g-T","executionInfo":{"status":"ok","timestamp":1651086088088,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def validate(val_loader, backbone, linear, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(val_loader),\n","        [batch_time, losses, top1, top2],\n","        prefix='Test: ')\n","\n","    backbone.eval()\n","    linear.eval()\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(val_loader):\n","            images = images.cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = backbone(images)\n","            output = linear(output)\n","            loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","            # measure accuracy and record loss\n","            \n","            acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","            losses.update(loss.item(), images.size(0))\n","            top1.update(acc1[0], images.size(0))\n","            top2.update(acc2[0], images.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                logger.info(progress.display(i))\n","\n","        # TODO: this should also be done with the ProgressMeter\n","        logger.info(' * Acc@1 {top1.avg:.3f} Acc@2 {top2.avg:.3f}'\n","              .format(top1=top1, top2=top2))\n","\n","    return top1.avg"],"metadata":{"id":"tzM_L9xK3qP2","executionInfo":{"status":"ok","timestamp":1651086088090,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def main_worker(data, label_fn, weights, save, logger, batch_size=16, workers=2, \n","                epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                resume=None, evaluate=False, n_classes=4):\n","    best_acc1 = 0\n","\n","    # Data loading code\n","    traindir = os.path.join(data, 'train')\n","    valdir = os.path.join(data, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    train_transform = transforms.Compose([\n","        #transforms.RandomResizedCrop(224),\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        #transforms.Resize(256),\n","        #transforms.CenterCrop(224),\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    train_dataset = Image_Dataset(traindir, label_fn, train_transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size, shuffle=True,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(valdir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    train_val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(traindir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    backbone = get_model(arch, weights)\n","    backbone = nn.DataParallel(backbone).cuda()\n","    backbone.eval()\n","\n","\n","    cached_feats = '%s/var_mean.pth.tar' % save\n","    if not os.path.exists(cached_feats):\n","        train_feats, _ = get_feats(train_val_loader, backbone, print_freq, logger)\n","        train_var, train_mean = torch.var_mean(train_feats, dim=0)\n","        torch.save((train_var, train_mean), cached_feats)\n","    else:\n","        train_var, train_mean = torch.load(cached_feats)\n","    if mlp:\n","        c = get_channels(arch)\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(c, c),\n","            nn.BatchNorm1d(c),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(c, n_classes),\n","            nn.Softmax()\n","        )\n","    else:\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(get_channels(arch), n_classes),\n","        )\n","\n","    print(backbone)\n","    print(linear)\n","\n","    linear = linear.cuda()\n","\n","    optimizer = torch.optim.SGD(linear.parameters(),\n","                                lr,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay)\n","\n","    sched = [int(x) for x in lr_schedule.split(',')]\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer, milestones=sched\n","    )\n","\n","    start_epoch = 0\n","    # optionally resume from a checkpoint\n","    if resume:\n","        if os.path.isfile(resume):\n","            logger.info(\"=> loading checkpoint '{}'\".format(resume))\n","            checkpoint = torch.load(resume)\n","            start_epoch = checkpoint['epoch']\n","            linear.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(resume, checkpoint['epoch']))\n","        else:\n","            logger.info(\"=> no checkpoint found at '{}'\".format(resume))\n","\n","    cudnn.benchmark = True\n","\n","    if evaluate:\n","        validate(val_loader, backbone, linear, print_freq, logger)\n","        return\n","\n","    for epoch in range(start_epoch, epochs):\n","        # train for one epoch\n","        train(train_loader, backbone, linear, optimizer, epoch, print_freq, logger)\n","\n","        # evaluate on validation set\n","        acc1 = validate(val_loader, backbone, linear, print_freq, logger)\n","\n","        # modify lr\n","        lr_scheduler.step()\n","        # logger.info('LR: {:f}'.format(lr_scheduler.get_last_lr()[-1]))\n","\n","        # remember best acc@1 and save checkpoint\n","        is_best = acc1 > best_acc1\n","        best_acc1 = max(acc1, best_acc1)\n","\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': linear.state_dict(),\n","            'best_acc1': best_acc1,\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","        }, is_best, save)\n","\n","    return backbone, linear"],"metadata":{"id":"_44olm-z7fG1","executionInfo":{"status":"ok","timestamp":1651086088090,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["!touch logger_init\n","def main_linear_eval(data, label_fn, weights, save, batch_size=16, workers=2, \n","                     epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                     momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                     resume=None, evaluate=False, seed=None, n_classes=4):\n","    args = locals()\n","    del args['label_fn']\n","\n","    makedirs(save)\n","    logger = get_logger(logpath=os.path.join(save, 'logs'), filepath='logger_init')\n","    logger.info(args)\n","\n","    if seed is not None:\n","        random.seed(seed)\n","        torch.manual_seed(seed)\n","        cudnn.deterministic = True\n","        warnings.warn('You have chosen to seed training. '\n","                      'This will turn on the CUDNN deterministic setting, '\n","                      'which can slow down your training considerably! '\n","                      'You may see unexpected behavior when restarting '\n","                      'from checkpoints.')\n","\n","    return main_worker(data, label_fn, weights, save, logger, batch_size, workers, \n","                epochs, arch, print_freq, mlp, lr, momentum, weight_decay, \n","                lr_schedule, resume, evaluate)"],"metadata":{"id":"EJy6AFcZDlK8","executionInfo":{"status":"ok","timestamp":1651086088596,"user_tz":420,"elapsed":527,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# Linear Evaluation Training"],"metadata":{"id":"AoS9kV5iOBUC"}},{"cell_type":"code","source":["labels_df = pd.read_csv(root_path + 'Cropped_Images_Wound_Stage_Probabilities.csv', index_col='Image')\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"Q613sTN9OH9z","executionInfo":{"status":"ok","timestamp":1651086088597,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"a64b0da5-ae92-4399-c4cb-7f419ccffeb7"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation\n","Image                                                                 \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000"],"text/html":["\n","  <div id=\"df-302a86df-5eb8-4737-b5a3-9fded990fe9c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-302a86df-5eb8-4737-b5a3-9fded990fe9c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-302a86df-5eb8-4737-b5a3-9fded990fe9c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-302a86df-5eb8-4737-b5a3-9fded990fe9c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["labels_df.loc['Day 8_A8-4-L.png'].to_numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpskZYsoPOrq","executionInfo":{"status":"ok","timestamp":1651086088598,"user_tz":420,"elapsed":14,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"a55c6cea-7491-4dc9-df28-4d6d1ccd573c"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.18181818, 0.09090909, 0.54545455, 0.18181818])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["backbone, linear = main_linear_eval(\n","    data='/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_images', \n","    label_fn=lambda x: labels_df.loc[x].to_numpy(), \n","    weights='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/fuzzy_c_1/ckpt_epoch_100.pth',\n","    save='/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/fuzzy_c_1/eval_100/', \n","    batch_size=16, \n","    workers=2, \n","    epochs=40, \n","    arch='resnet50', \n","    print_freq=10, \n","    mlp=True, \n","    lr=0.01)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqLRidzrRF3A","executionInfo":{"status":"ok","timestamp":1651086157614,"user_tz":420,"elapsed":69027,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"c87176a7-a587-4828-fdf7-9f0a4a60d836"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["logger_init\n","\n","{'data': '/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_images', 'weights': '/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/fuzzy_c_1/ckpt_epoch_100.pth', 'save': '/content/gdrive/MyDrive/Explainable_Wound_Classification/outputs/fuzzy_c_1/eval_100/', 'batch_size': 16, 'workers': 2, 'epochs': 40, 'arch': 'resnet50', 'print_freq': 10, 'mlp': True, 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_schedule': '15,30,40', 'resume': None, 'evaluate': False, 'seed': None, 'n_classes': 4}\n"]},{"output_type":"stream","name":"stdout","text":["DataParallel(\n","  (module): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Sequential()\n","  )\n",")\n","Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=2048, out_features=2048, bias=True)\n","  (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU(inplace=True)\n","  (5): Linear(in_features=2048, out_features=4, bias=True)\n","  (6): Softmax(dim=None)\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","Epoch: [0][ 0/12]\tTime  0.446 ( 0.446)\tData  0.365 ( 0.365)\tLoss 7.6223e-01 (7.6223e-01)\tAcc@1  12.50 ( 12.50)\tAcc@2  43.75 ( 43.75)\n","Epoch: [0][10/12]\tTime  0.059 ( 0.098)\tData  0.014 ( 0.043)\tLoss 7.3550e-01 (7.5555e-01)\tAcc@1  56.25 ( 36.36)\tAcc@2  87.50 ( 63.07)\n","Test: [0/2]\tTime  0.309 ( 0.309)\tLoss 7.5002e-01 (7.5002e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 68.750\n","Epoch: [1][ 0/12]\tTime  0.307 ( 0.307)\tData  0.261 ( 0.261)\tLoss 7.4393e-01 (7.4393e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  68.75 ( 68.75)\n","Epoch: [1][10/12]\tTime  0.063 ( 0.086)\tData  0.018 ( 0.039)\tLoss 7.3785e-01 (7.3593e-01)\tAcc@1  43.75 ( 53.98)\tAcc@2  68.75 ( 74.43)\n","Test: [0/2]\tTime  0.292 ( 0.292)\tLoss 7.5363e-01 (7.5363e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [2][ 0/12]\tTime  0.325 ( 0.325)\tData  0.279 ( 0.279)\tLoss 7.0074e-01 (7.0074e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  81.25 ( 81.25)\n","Epoch: [2][10/12]\tTime  0.109 ( 0.094)\tData  0.064 ( 0.046)\tLoss 7.1402e-01 (7.3099e-01)\tAcc@1  75.00 ( 51.70)\tAcc@2  87.50 ( 72.73)\n","Test: [0/2]\tTime  0.305 ( 0.305)\tLoss 7.4606e-01 (7.4606e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [3][ 0/12]\tTime  0.364 ( 0.364)\tData  0.272 ( 0.272)\tLoss 7.3449e-01 (7.3449e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  68.75 ( 68.75)\n","Epoch: [3][10/12]\tTime  0.076 ( 0.097)\tData  0.033 ( 0.038)\tLoss 7.1393e-01 (7.2652e-01)\tAcc@1  62.50 ( 55.68)\tAcc@2  68.75 ( 73.30)\n","Test: [0/2]\tTime  0.275 ( 0.275)\tLoss 7.4677e-01 (7.4677e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [4][ 0/12]\tTime  0.377 ( 0.377)\tData  0.317 ( 0.317)\tLoss 7.3896e-01 (7.3896e-01)\tAcc@1  43.75 ( 43.75)\tAcc@2  56.25 ( 56.25)\n","Epoch: [4][10/12]\tTime  0.049 ( 0.096)\tData  0.000 ( 0.045)\tLoss 7.0953e-01 (7.3087e-01)\tAcc@1  68.75 ( 56.25)\tAcc@2  87.50 ( 74.43)\n","Test: [0/2]\tTime  0.286 ( 0.286)\tLoss 7.4561e-01 (7.4561e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [5][ 0/12]\tTime  0.362 ( 0.362)\tData  0.313 ( 0.313)\tLoss 6.8941e-01 (6.8941e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  93.75 ( 93.75)\n","Epoch: [5][10/12]\tTime  0.095 ( 0.103)\tData  0.053 ( 0.056)\tLoss 7.5411e-01 (7.2882e-01)\tAcc@1  37.50 ( 55.11)\tAcc@2  50.00 ( 75.00)\n","Test: [0/2]\tTime  0.311 ( 0.311)\tLoss 7.4409e-01 (7.4409e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [6][ 0/12]\tTime  0.339 ( 0.339)\tData  0.294 ( 0.294)\tLoss 7.1099e-01 (7.1099e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  75.00 ( 75.00)\n","Epoch: [6][10/12]\tTime  0.071 ( 0.097)\tData  0.028 ( 0.047)\tLoss 7.3207e-01 (7.2900e-01)\tAcc@1  50.00 ( 58.52)\tAcc@2  62.50 ( 75.57)\n","Test: [0/2]\tTime  0.281 ( 0.281)\tLoss 7.4514e-01 (7.4514e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [7][ 0/12]\tTime  0.358 ( 0.358)\tData  0.291 ( 0.291)\tLoss 7.0961e-01 (7.0961e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  81.25 ( 81.25)\n","Epoch: [7][10/12]\tTime  0.067 ( 0.100)\tData  0.024 ( 0.045)\tLoss 7.5329e-01 (7.2983e-01)\tAcc@1  37.50 ( 55.11)\tAcc@2  62.50 ( 75.00)\n","Test: [0/2]\tTime  0.335 ( 0.335)\tLoss 7.4513e-01 (7.4513e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [8][ 0/12]\tTime  0.362 ( 0.362)\tData  0.317 ( 0.317)\tLoss 7.0463e-01 (7.0463e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [8][10/12]\tTime  0.100 ( 0.104)\tData  0.058 ( 0.054)\tLoss 7.4603e-01 (7.2789e-01)\tAcc@1  43.75 ( 57.95)\tAcc@2  68.75 ( 74.43)\n","Test: [0/2]\tTime  0.307 ( 0.307)\tLoss 7.4511e-01 (7.4511e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [9][ 0/12]\tTime  0.361 ( 0.361)\tData  0.307 ( 0.307)\tLoss 7.0297e-01 (7.0297e-01)\tAcc@1  81.25 ( 81.25)\tAcc@2  81.25 ( 81.25)\n","Epoch: [9][10/12]\tTime  0.103 ( 0.098)\tData  0.061 ( 0.047)\tLoss 7.4439e-01 (7.2702e-01)\tAcc@1  43.75 ( 56.82)\tAcc@2  75.00 ( 73.30)\n","Test: [0/2]\tTime  0.320 ( 0.320)\tLoss 7.4314e-01 (7.4314e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [10][ 0/12]\tTime  0.357 ( 0.357)\tData  0.293 ( 0.293)\tLoss 7.2264e-01 (7.2264e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n","Epoch: [10][10/12]\tTime  0.052 ( 0.098)\tData  0.009 ( 0.045)\tLoss 7.1043e-01 (7.2619e-01)\tAcc@1  75.00 ( 57.95)\tAcc@2  81.25 ( 74.43)\n","Test: [0/2]\tTime  0.282 ( 0.282)\tLoss 7.4355e-01 (7.4355e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [11][ 0/12]\tTime  0.297 ( 0.297)\tData  0.250 ( 0.250)\tLoss 7.1295e-01 (7.1295e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  87.50 ( 87.50)\n","Epoch: [11][10/12]\tTime  0.096 ( 0.088)\tData  0.053 ( 0.039)\tLoss 7.2826e-01 (7.2557e-01)\tAcc@1  62.50 ( 57.39)\tAcc@2  68.75 ( 75.57)\n","Test: [0/2]\tTime  0.281 ( 0.281)\tLoss 7.4629e-01 (7.4629e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [12][ 0/12]\tTime  0.339 ( 0.339)\tData  0.279 ( 0.279)\tLoss 7.3271e-01 (7.3271e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  50.00 ( 50.00)\n","Epoch: [12][10/12]\tTime  0.099 ( 0.093)\tData  0.057 ( 0.046)\tLoss 7.2064e-01 (7.2635e-01)\tAcc@1  62.50 ( 57.39)\tAcc@2  81.25 ( 73.30)\n","Test: [0/2]\tTime  0.273 ( 0.273)\tLoss 7.4287e-01 (7.4287e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [13][ 0/12]\tTime  0.305 ( 0.305)\tData  0.258 ( 0.258)\tLoss 7.2303e-01 (7.2303e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n","Epoch: [13][10/12]\tTime  0.046 ( 0.088)\tData  0.000 ( 0.036)\tLoss 7.5420e-01 (7.2521e-01)\tAcc@1  43.75 ( 59.66)\tAcc@2  62.50 ( 76.14)\n","Test: [0/2]\tTime  0.288 ( 0.288)\tLoss 7.4385e-01 (7.4385e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [14][ 0/12]\tTime  0.289 ( 0.289)\tData  0.242 ( 0.242)\tLoss 6.9994e-01 (6.9994e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  81.25 ( 81.25)\n","Epoch: [14][10/12]\tTime  0.084 ( 0.085)\tData  0.040 ( 0.037)\tLoss 7.2997e-01 (7.2518e-01)\tAcc@1  50.00 ( 58.52)\tAcc@2  81.25 ( 75.57)\n","Test: [0/2]\tTime  0.262 ( 0.262)\tLoss 7.4289e-01 (7.4289e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [15][ 0/12]\tTime  0.283 ( 0.283)\tData  0.236 ( 0.236)\tLoss 7.2602e-01 (7.2602e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  75.00 ( 75.00)\n","Epoch: [15][10/12]\tTime  0.081 ( 0.090)\tData  0.038 ( 0.041)\tLoss 7.5117e-01 (7.2530e-01)\tAcc@1  50.00 ( 58.52)\tAcc@2  68.75 ( 75.57)\n","Test: [0/2]\tTime  0.274 ( 0.274)\tLoss 7.4248e-01 (7.4248e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [16][ 0/12]\tTime  0.296 ( 0.296)\tData  0.247 ( 0.247)\tLoss 7.1596e-01 (7.1596e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  75.00 ( 75.00)\n","Epoch: [16][10/12]\tTime  0.048 ( 0.087)\tData  0.000 ( 0.037)\tLoss 7.4083e-01 (7.2081e-01)\tAcc@1  50.00 ( 61.93)\tAcc@2  75.00 ( 77.84)\n","Test: [0/2]\tTime  0.276 ( 0.276)\tLoss 7.4224e-01 (7.4224e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [17][ 0/12]\tTime  0.317 ( 0.317)\tData  0.258 ( 0.258)\tLoss 7.4414e-01 (7.4414e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  75.00 ( 75.00)\n","Epoch: [17][10/12]\tTime  0.049 ( 0.087)\tData  0.000 ( 0.036)\tLoss 7.0275e-01 (7.2554e-01)\tAcc@1  75.00 ( 59.09)\tAcc@2  81.25 ( 73.86)\n","Test: [0/2]\tTime  0.275 ( 0.275)\tLoss 7.4273e-01 (7.4273e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [18][ 0/12]\tTime  0.279 ( 0.279)\tData  0.228 ( 0.228)\tLoss 7.0286e-01 (7.0286e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [18][10/12]\tTime  0.066 ( 0.089)\tData  0.023 ( 0.039)\tLoss 7.2917e-01 (7.2663e-01)\tAcc@1  50.00 ( 58.52)\tAcc@2  75.00 ( 75.57)\n","Test: [0/2]\tTime  0.262 ( 0.262)\tLoss 7.4287e-01 (7.4287e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [19][ 0/12]\tTime  0.313 ( 0.313)\tData  0.249 ( 0.249)\tLoss 7.2439e-01 (7.2439e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  68.75 ( 68.75)\n","Epoch: [19][10/12]\tTime  0.062 ( 0.085)\tData  0.017 ( 0.035)\tLoss 7.0250e-01 (7.2435e-01)\tAcc@1  75.00 ( 60.80)\tAcc@2  93.75 ( 75.57)\n","Test: [0/2]\tTime  0.275 ( 0.275)\tLoss 7.4283e-01 (7.4283e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [20][ 0/12]\tTime  0.287 ( 0.287)\tData  0.239 ( 0.239)\tLoss 7.1232e-01 (7.1232e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  75.00 ( 75.00)\n","Epoch: [20][10/12]\tTime  0.084 ( 0.085)\tData  0.040 ( 0.036)\tLoss 7.1907e-01 (7.2723e-01)\tAcc@1  56.25 ( 56.82)\tAcc@2  75.00 ( 73.30)\n","Test: [0/2]\tTime  0.277 ( 0.277)\tLoss 7.4249e-01 (7.4249e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [21][ 0/12]\tTime  0.322 ( 0.322)\tData  0.274 ( 0.274)\tLoss 7.2126e-01 (7.2126e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  87.50 ( 87.50)\n","Epoch: [21][10/12]\tTime  0.099 ( 0.093)\tData  0.056 ( 0.046)\tLoss 7.1097e-01 (7.2573e-01)\tAcc@1  62.50 ( 57.95)\tAcc@2  75.00 ( 76.70)\n","Test: [0/2]\tTime  0.265 ( 0.265)\tLoss 7.4241e-01 (7.4241e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [22][ 0/12]\tTime  0.304 ( 0.304)\tData  0.244 ( 0.244)\tLoss 7.2190e-01 (7.2190e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [22][10/12]\tTime  0.084 ( 0.087)\tData  0.042 ( 0.038)\tLoss 7.1327e-01 (7.2443e-01)\tAcc@1  68.75 ( 59.66)\tAcc@2  87.50 ( 75.57)\n","Test: [0/2]\tTime  0.279 ( 0.279)\tLoss 7.4183e-01 (7.4183e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [23][ 0/12]\tTime  0.291 ( 0.291)\tData  0.245 ( 0.245)\tLoss 7.0222e-01 (7.0222e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  68.75 ( 68.75)\n","Epoch: [23][10/12]\tTime  0.048 ( 0.086)\tData  0.000 ( 0.038)\tLoss 7.2091e-01 (7.2683e-01)\tAcc@1  68.75 ( 58.52)\tAcc@2  87.50 ( 75.00)\n","Test: [0/2]\tTime  0.262 ( 0.262)\tLoss 7.4207e-01 (7.4207e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 50.000 Acc@2 71.875\n","Epoch: [24][ 0/12]\tTime  0.302 ( 0.302)\tData  0.254 ( 0.254)\tLoss 7.6626e-01 (7.6626e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  56.25 ( 56.25)\n","Epoch: [24][10/12]\tTime  0.084 ( 0.088)\tData  0.041 ( 0.040)\tLoss 7.5232e-01 (7.2375e-01)\tAcc@1  37.50 ( 60.23)\tAcc@2  43.75 ( 77.27)\n","Test: [0/2]\tTime  0.285 ( 0.285)\tLoss 7.4227e-01 (7.4227e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [25][ 0/12]\tTime  0.287 ( 0.287)\tData  0.241 ( 0.241)\tLoss 7.4716e-01 (7.4716e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  50.00 ( 50.00)\n","Epoch: [25][10/12]\tTime  0.076 ( 0.086)\tData  0.033 ( 0.038)\tLoss 7.0764e-01 (7.2068e-01)\tAcc@1  62.50 ( 61.93)\tAcc@2  87.50 ( 76.14)\n","Test: [0/2]\tTime  0.269 ( 0.269)\tLoss 7.4168e-01 (7.4168e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [26][ 0/12]\tTime  0.331 ( 0.331)\tData  0.278 ( 0.278)\tLoss 7.2409e-01 (7.2409e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  81.25 ( 81.25)\n","Epoch: [26][10/12]\tTime  0.064 ( 0.086)\tData  0.019 ( 0.038)\tLoss 7.0264e-01 (7.2471e-01)\tAcc@1  87.50 ( 60.80)\tAcc@2  87.50 ( 74.43)\n","Test: [0/2]\tTime  0.270 ( 0.270)\tLoss 7.4214e-01 (7.4214e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [27][ 0/12]\tTime  0.359 ( 0.359)\tData  0.314 ( 0.314)\tLoss 7.1555e-01 (7.1555e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [27][10/12]\tTime  0.074 ( 0.093)\tData  0.030 ( 0.046)\tLoss 7.4572e-01 (7.2533e-01)\tAcc@1  43.75 ( 60.23)\tAcc@2  62.50 ( 75.57)\n","Test: [0/2]\tTime  0.277 ( 0.277)\tLoss 7.4281e-01 (7.4281e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [28][ 0/12]\tTime  0.314 ( 0.314)\tData  0.266 ( 0.266)\tLoss 6.9899e-01 (6.9899e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  87.50 ( 87.50)\n","Epoch: [28][10/12]\tTime  0.097 ( 0.089)\tData  0.054 ( 0.040)\tLoss 7.3099e-01 (7.2089e-01)\tAcc@1  56.25 ( 60.23)\tAcc@2  75.00 ( 76.70)\n","Test: [0/2]\tTime  0.281 ( 0.281)\tLoss 7.4309e-01 (7.4309e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [29][ 0/12]\tTime  0.333 ( 0.333)\tData  0.286 ( 0.286)\tLoss 6.9426e-01 (6.9426e-01)\tAcc@1  81.25 ( 81.25)\tAcc@2  87.50 ( 87.50)\n","Epoch: [29][10/12]\tTime  0.061 ( 0.091)\tData  0.016 ( 0.044)\tLoss 7.2240e-01 (7.2685e-01)\tAcc@1  75.00 ( 59.66)\tAcc@2  87.50 ( 74.43)\n","Test: [0/2]\tTime  0.276 ( 0.276)\tLoss 7.4282e-01 (7.4282e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [30][ 0/12]\tTime  0.289 ( 0.289)\tData  0.243 ( 0.243)\tLoss 7.3874e-01 (7.3874e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n","Epoch: [30][10/12]\tTime  0.085 ( 0.087)\tData  0.043 ( 0.039)\tLoss 7.3036e-01 (7.2523e-01)\tAcc@1  50.00 ( 59.09)\tAcc@2  62.50 ( 74.43)\n","Test: [0/2]\tTime  0.280 ( 0.280)\tLoss 7.4257e-01 (7.4257e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [31][ 0/12]\tTime  0.311 ( 0.311)\tData  0.264 ( 0.264)\tLoss 7.4500e-01 (7.4500e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  68.75 ( 68.75)\n","Epoch: [31][10/12]\tTime  0.085 ( 0.086)\tData  0.042 ( 0.038)\tLoss 7.3002e-01 (7.2473e-01)\tAcc@1  56.25 ( 57.39)\tAcc@2  75.00 ( 76.14)\n","Test: [0/2]\tTime  0.267 ( 0.267)\tLoss 7.4247e-01 (7.4247e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [32][ 0/12]\tTime  0.294 ( 0.294)\tData  0.249 ( 0.249)\tLoss 7.3895e-01 (7.3895e-01)\tAcc@1  43.75 ( 43.75)\tAcc@2  68.75 ( 68.75)\n","Epoch: [32][10/12]\tTime  0.066 ( 0.087)\tData  0.022 ( 0.040)\tLoss 7.0222e-01 (7.2646e-01)\tAcc@1  75.00 ( 60.23)\tAcc@2  87.50 ( 75.00)\n","Test: [0/2]\tTime  0.275 ( 0.275)\tLoss 7.4232e-01 (7.4232e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [33][ 0/12]\tTime  0.296 ( 0.296)\tData  0.250 ( 0.250)\tLoss 7.5461e-01 (7.5461e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  50.00 ( 50.00)\n","Epoch: [33][10/12]\tTime  0.063 ( 0.086)\tData  0.018 ( 0.038)\tLoss 7.4151e-01 (7.2523e-01)\tAcc@1  56.25 ( 60.80)\tAcc@2  75.00 ( 75.00)\n","Test: [0/2]\tTime  0.271 ( 0.271)\tLoss 7.4218e-01 (7.4218e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [34][ 0/12]\tTime  0.353 ( 0.353)\tData  0.286 ( 0.286)\tLoss 6.9642e-01 (6.9642e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [34][10/12]\tTime  0.098 ( 0.092)\tData  0.056 ( 0.040)\tLoss 7.4836e-01 (7.2493e-01)\tAcc@1  62.50 ( 60.23)\tAcc@2  68.75 ( 74.43)\n","Test: [0/2]\tTime  0.267 ( 0.267)\tLoss 7.4238e-01 (7.4238e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [35][ 0/12]\tTime  0.330 ( 0.330)\tData  0.280 ( 0.280)\tLoss 7.0873e-01 (7.0873e-01)\tAcc@1  68.75 ( 68.75)\tAcc@2  87.50 ( 87.50)\n","Epoch: [35][10/12]\tTime  0.065 ( 0.093)\tData  0.021 ( 0.044)\tLoss 7.3657e-01 (7.2385e-01)\tAcc@1  56.25 ( 61.93)\tAcc@2  68.75 ( 77.84)\n","Test: [0/2]\tTime  0.268 ( 0.268)\tLoss 7.4268e-01 (7.4268e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [36][ 0/12]\tTime  0.330 ( 0.330)\tData  0.284 ( 0.284)\tLoss 7.6514e-01 (7.6514e-01)\tAcc@1  43.75 ( 43.75)\tAcc@2  50.00 ( 50.00)\n","Epoch: [36][10/12]\tTime  0.073 ( 0.089)\tData  0.030 ( 0.039)\tLoss 7.2934e-01 (7.2390e-01)\tAcc@1  56.25 ( 60.23)\tAcc@2  68.75 ( 76.70)\n","Test: [0/2]\tTime  0.271 ( 0.271)\tLoss 7.4249e-01 (7.4249e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [37][ 0/12]\tTime  0.319 ( 0.319)\tData  0.269 ( 0.269)\tLoss 7.2854e-01 (7.2854e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  81.25 ( 81.25)\n","Epoch: [37][10/12]\tTime  0.069 ( 0.090)\tData  0.026 ( 0.042)\tLoss 7.0665e-01 (7.2537e-01)\tAcc@1  68.75 ( 57.95)\tAcc@2  81.25 ( 73.86)\n","Test: [0/2]\tTime  0.269 ( 0.269)\tLoss 7.4255e-01 (7.4255e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [38][ 0/12]\tTime  0.320 ( 0.320)\tData  0.274 ( 0.274)\tLoss 7.2476e-01 (7.2476e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  81.25 ( 81.25)\n","Epoch: [38][10/12]\tTime  0.069 ( 0.084)\tData  0.026 ( 0.036)\tLoss 7.2747e-01 (7.2053e-01)\tAcc@1  56.25 ( 63.07)\tAcc@2  81.25 ( 76.70)\n","Test: [0/2]\tTime  0.273 ( 0.273)\tLoss 7.4238e-01 (7.4238e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n","Epoch: [39][ 0/12]\tTime  0.307 ( 0.307)\tData  0.251 ( 0.251)\tLoss 7.5436e-01 (7.5436e-01)\tAcc@1  43.75 ( 43.75)\tAcc@2  68.75 ( 68.75)\n","Epoch: [39][10/12]\tTime  0.050 ( 0.084)\tData  0.000 ( 0.032)\tLoss 7.1906e-01 (7.2589e-01)\tAcc@1  62.50 ( 60.80)\tAcc@2  68.75 ( 75.00)\n","Test: [0/2]\tTime  0.287 ( 0.287)\tLoss 7.4275e-01 (7.4275e-01)\tAcc@1  56.25 ( 56.25)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 53.125 Acc@2 71.875\n"]}]},{"cell_type":"markdown","source":["# Test Set"],"metadata":{"id":"CKb0QIw72KxA"}},{"cell_type":"code","source":["test_dataset = Image_Dataset(\n","    '/content/gdrive/MyDrive/Explainable_Wound_Classification/Split_images/test', \n","    lambda x: labels_df.loc[x].to_numpy(), \n","    transforms.Compose(\n","        [transforms.Resize(224),\n","         transforms.ToTensor(),\n","         normalize])\n",")"],"metadata":{"id":"Ep3g2fjaVB07","executionInfo":{"status":"ok","timestamp":1651086157617,"user_tz":420,"elapsed":27,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["backbone.eval()\n","linear.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25e8fnGS-ER6","executionInfo":{"status":"ok","timestamp":1651086157620,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"8156dc32-5c58-487a-fb7c-9fdba2322bbf"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=2048, out_features=2048, bias=True)\n","  (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU(inplace=True)\n","  (5): Linear(in_features=2048, out_features=4, bias=True)\n","  (6): Softmax(dim=None)\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["with torch.no_grad():\n","    results = {}\n","    for i in range(len(test_dataset)):\n","        img_name = test_dataset.samples[i].split('/')[-1]\n","        results[img_name] = {} \n","        results[img_name]['target'] = test_dataset.targets[i]\n","        results[img_name]['pred'] = linear(backbone(test_dataset[i][1].expand(1, 3, 224, 224))).cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8tMVLC8fLGY","executionInfo":{"status":"ok","timestamp":1651086158987,"user_tz":420,"elapsed":1383,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"5c1bdb6f-d3cd-41a0-fb60-94aff662b138"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(results).T\n","props = df.index.map(lambda x: re.match('^Day (\\d+)_(Y|A)8-(\\d)-(L|R)', x).groups())\n","df['Day'] = props.map(lambda x: int(x[0]))\n","df['Age'] = props.map(lambda x: x[1])\n","df['Mouse'] = props.map(lambda x: int(x[2]))\n","df['Side'] = props.map(lambda x: x[3])\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"nhlvlmmh8xPN","executionInfo":{"status":"ok","timestamp":1651086158988,"user_tz":420,"elapsed":69,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"04b7842d-0ab0-48f3-ccb5-d05fa7b984a7"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.9090909090909...   \n","Day 7_Y8-4-L.png   [0.0, 0.0, 0.4545454545454545, 0.5454545454545...   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.4545454545454545, 0.454...   \n","Day 4_A8-1-R.png   [0.3636363636363636, 0.6363636363636364, 0.0, ...   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","\n","                                                                pred  Day Age  \\\n","Day 14_Y8-4-L.png  [[0.00077371113, 0.0022693924, 0.98832035, 0.0...   14   Y   \n","Day 7_Y8-4-L.png   [[0.00076753687, 0.0022484525, 0.9883583, 0.00...    7   Y   \n","Day 9_A8-1-R.png   [[0.0007661236, 0.002261453, 0.98830634, 0.008...    9   A   \n","Day 4_A8-1-R.png   [[0.0007682852, 0.0022748422, 0.9882572, 0.008...    4   A   \n","Day 12_A8-1-R.png  [[0.0007665131, 0.002246504, 0.98840904, 0.008...   12   A   \n","\n","                   Mouse Side  \n","Day 14_Y8-4-L.png      4    L  \n","Day 7_Y8-4-L.png       4    L  \n","Day 9_A8-1-R.png       1    R  \n","Day 4_A8-1-R.png       1    R  \n","Day 12_A8-1-R.png      1    R  "],"text/html":["\n","  <div id=\"df-db810047-4403-4299-89b3-efd2b9f1c332\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>Day</th>\n","      <th>Age</th>\n","      <th>Mouse</th>\n","      <th>Side</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.9090909090909...</td>\n","      <td>[[0.00077371113, 0.0022693924, 0.98832035, 0.0...</td>\n","      <td>14</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.4545454545454545, 0.5454545454545...</td>\n","      <td>[[0.00076753687, 0.0022484525, 0.9883583, 0.00...</td>\n","      <td>7</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.4545454545454545, 0.454...</td>\n","      <td>[[0.0007661236, 0.002261453, 0.98830634, 0.008...</td>\n","      <td>9</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.3636363636363636, 0.6363636363636364, 0.0, ...</td>\n","      <td>[[0.0007682852, 0.0022748422, 0.9882572, 0.008...</td>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[[0.0007665131, 0.002246504, 0.98840904, 0.008...</td>\n","      <td>12</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db810047-4403-4299-89b3-efd2b9f1c332')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-db810047-4403-4299-89b3-efd2b9f1c332 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-db810047-4403-4299-89b3-efd2b9f1c332');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["young_df = df[df.Age == 'Y']\n","young_df.sort_values('Day')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"id":"t7gfkMTdFq19","executionInfo":{"status":"ok","timestamp":1651086158989,"user_tz":420,"elapsed":59,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"769045f2-4807-446a-ff1d-bed36cb7534e"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_Y8-4-L.png                                [1.0, 0.0, 0.0, 0.0]   \n","Day 1_Y8-4-L.png                                [0.3, 0.4, 0.3, 0.0]   \n","Day 2_Y8-4-L.png                                [0.8, 0.2, 0.0, 0.0]   \n","Day 3_Y8-4-L.png                                [0.2, 0.8, 0.0, 0.0]   \n","Day 4_Y8-4-L.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 5_Y8-4-L.png                                [0.3, 0.5, 0.2, 0.0]   \n","Day 6_Y8-4-L.png                                [0.1, 0.3, 0.6, 0.0]   \n","Day 7_Y8-4-L.png   [0.0, 0.0, 0.4545454545454545, 0.5454545454545...   \n","Day 8_Y8-4-L.png                                [0.0, 0.0, 0.5, 0.5]   \n","Day 9_Y8-4-L.png                                [0.0, 0.0, 0.6, 0.4]   \n","Day 10_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 11_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 12_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 13_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.9090909090909...   \n","Day 15_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","\n","                                                                pred  Day Age  \\\n","Day 0_Y8-4-L.png   [[0.00077199383, 0.0023037447, 0.9880725, 0.00...    0   Y   \n","Day 1_Y8-4-L.png   [[0.0007662006, 0.0022762865, 0.988245, 0.0087...    1   Y   \n","Day 2_Y8-4-L.png   [[0.00076841813, 0.0022748837, 0.9882653, 0.00...    2   Y   \n","Day 3_Y8-4-L.png   [[0.00076816865, 0.0022626803, 0.98832417, 0.0...    3   Y   \n","Day 4_Y8-4-L.png   [[0.0007702087, 0.0022798984, 0.9881912, 0.008...    4   Y   \n","Day 5_Y8-4-L.png   [[0.0007680087, 0.0022626277, 0.98828226, 0.00...    5   Y   \n","Day 6_Y8-4-L.png   [[0.00076703215, 0.002252201, 0.9883349, 0.008...    6   Y   \n","Day 7_Y8-4-L.png   [[0.00076753687, 0.0022484525, 0.9883583, 0.00...    7   Y   \n","Day 8_Y8-4-L.png   [[0.0007683486, 0.0022554114, 0.9883284, 0.008...    8   Y   \n","Day 9_Y8-4-L.png   [[0.000767051, 0.0022412816, 0.9884106, 0.0085...    9   Y   \n","Day 10_Y8-4-L.png  [[0.0007663311, 0.002228032, 0.98846984, 0.008...   10   Y   \n","Day 11_Y8-4-L.png  [[0.0007663602, 0.002235587, 0.98844945, 0.008...   11   Y   \n","Day 12_Y8-4-L.png  [[0.0007754223, 0.0022995553, 0.9881116, 0.008...   12   Y   \n","Day 13_Y8-4-L.png  [[0.00076671375, 0.00224775, 0.98836946, 0.008...   13   Y   \n","Day 14_Y8-4-L.png  [[0.00077371113, 0.0022693924, 0.98832035, 0.0...   14   Y   \n","Day 15_Y8-4-L.png  [[0.0007665722, 0.0022391821, 0.9884184, 0.008...   15   Y   \n","\n","                   Mouse Side  \n","Day 0_Y8-4-L.png       4    L  \n","Day 1_Y8-4-L.png       4    L  \n","Day 2_Y8-4-L.png       4    L  \n","Day 3_Y8-4-L.png       4    L  \n","Day 4_Y8-4-L.png       4    L  \n","Day 5_Y8-4-L.png       4    L  \n","Day 6_Y8-4-L.png       4    L  \n","Day 7_Y8-4-L.png       4    L  \n","Day 8_Y8-4-L.png       4    L  \n","Day 9_Y8-4-L.png       4    L  \n","Day 10_Y8-4-L.png      4    L  \n","Day 11_Y8-4-L.png      4    L  \n","Day 12_Y8-4-L.png      4    L  \n","Day 13_Y8-4-L.png      4    L  \n","Day 14_Y8-4-L.png      4    L  \n","Day 15_Y8-4-L.png      4    L  "],"text/html":["\n","  <div id=\"df-732cf9f7-0617-40f0-a116-eb0daefbbe32\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>Day</th>\n","      <th>Age</th>\n","      <th>Mouse</th>\n","      <th>Side</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_Y8-4-L.png</th>\n","      <td>[1.0, 0.0, 0.0, 0.0]</td>\n","      <td>[[0.00077199383, 0.0023037447, 0.9880725, 0.00...</td>\n","      <td>0</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_Y8-4-L.png</th>\n","      <td>[0.3, 0.4, 0.3, 0.0]</td>\n","      <td>[[0.0007662006, 0.0022762865, 0.988245, 0.0087...</td>\n","      <td>1</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_Y8-4-L.png</th>\n","      <td>[0.8, 0.2, 0.0, 0.0]</td>\n","      <td>[[0.00076841813, 0.0022748837, 0.9882653, 0.00...</td>\n","      <td>2</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_Y8-4-L.png</th>\n","      <td>[0.2, 0.8, 0.0, 0.0]</td>\n","      <td>[[0.00076816865, 0.0022626803, 0.98832417, 0.0...</td>\n","      <td>3</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_Y8-4-L.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[[0.0007702087, 0.0022798984, 0.9881912, 0.008...</td>\n","      <td>4</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_Y8-4-L.png</th>\n","      <td>[0.3, 0.5, 0.2, 0.0]</td>\n","      <td>[[0.0007680087, 0.0022626277, 0.98828226, 0.00...</td>\n","      <td>5</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_Y8-4-L.png</th>\n","      <td>[0.1, 0.3, 0.6, 0.0]</td>\n","      <td>[[0.00076703215, 0.002252201, 0.9883349, 0.008...</td>\n","      <td>6</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.4545454545454545, 0.5454545454545...</td>\n","      <td>[[0.00076753687, 0.0022484525, 0.9883583, 0.00...</td>\n","      <td>7</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.5, 0.5]</td>\n","      <td>[[0.0007683486, 0.0022554114, 0.9883284, 0.008...</td>\n","      <td>8</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.6, 0.4]</td>\n","      <td>[[0.000767051, 0.0022412816, 0.9884106, 0.0085...</td>\n","      <td>9</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[[0.0007663311, 0.002228032, 0.98846984, 0.008...</td>\n","      <td>10</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[[0.0007663602, 0.002235587, 0.98844945, 0.008...</td>\n","      <td>11</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[[0.0007754223, 0.0022995553, 0.9881116, 0.008...</td>\n","      <td>12</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[[0.00076671375, 0.00224775, 0.98836946, 0.008...</td>\n","      <td>13</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.9090909090909...</td>\n","      <td>[[0.00077371113, 0.0022693924, 0.98832035, 0.0...</td>\n","      <td>14</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[[0.0007665722, 0.0022391821, 0.9884184, 0.008...</td>\n","      <td>15</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-732cf9f7-0617-40f0-a116-eb0daefbbe32')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-732cf9f7-0617-40f0-a116-eb0daefbbe32 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-732cf9f7-0617-40f0-a116-eb0daefbbe32');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["aged_df = df[df.Age == 'A']\n","aged_df.sort_values('Day')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"id":"R9VQDT9nHDUj","executionInfo":{"status":"ok","timestamp":1651086158996,"user_tz":420,"elapsed":63,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"905fae48-4edf-459b-e481-a33ce6e3c848"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_A8-1-R.png                                [0.9, 0.1, 0.0, 0.0]   \n","Day 1_A8-1-R.png                                [0.1, 0.8, 0.1, 0.0]   \n","Day 2_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 3_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 4_A8-1-R.png   [0.3636363636363636, 0.6363636363636364, 0.0, ...   \n","Day 5_A8-1-R.png                                [0.2, 0.5, 0.3, 0.0]   \n","Day 6_A8-1-R.png                                [0.2, 0.7, 0.1, 0.0]   \n","Day 7_A8-1-R.png                                [0.1, 0.7, 0.1, 0.1]   \n","Day 8_A8-1-R.png                                [0.2, 0.6, 0.2, 0.0]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.4545454545454545, 0.454...   \n","Day 10_A8-1-R.png                               [0.1, 0.4, 0.5, 0.0]   \n","Day 11_A8-1-R.png                               [0.0, 0.1, 0.8, 0.1]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","Day 13_A8-1-R.png                               [0.0, 0.1, 0.5, 0.4]   \n","Day 14_A8-1-R.png                               [0.0, 0.1, 0.3, 0.6]   \n","Day 15_A8-1-R.png                               [0.0, 0.1, 0.6, 0.3]   \n","\n","                                                                pred  Day Age  \\\n","Day 0_A8-1-R.png   [[0.0007662976, 0.002264746, 0.9882834, 0.0086...    0   A   \n","Day 1_A8-1-R.png   [[0.0007634308, 0.0022500332, 0.988376, 0.0086...    1   A   \n","Day 2_A8-1-R.png   [[0.0007654989, 0.0022612421, 0.9883159, 0.008...    2   A   \n","Day 3_A8-1-R.png   [[0.0007688016, 0.002287011, 0.9882036, 0.0087...    3   A   \n","Day 4_A8-1-R.png   [[0.0007682852, 0.0022748422, 0.9882572, 0.008...    4   A   \n","Day 5_A8-1-R.png   [[0.0007663971, 0.0022515245, 0.98835796, 0.00...    5   A   \n","Day 6_A8-1-R.png   [[0.0007645951, 0.002251848, 0.9883652, 0.0086...    6   A   \n","Day 7_A8-1-R.png   [[0.00076561735, 0.0022552274, 0.9883435, 0.00...    7   A   \n","Day 8_A8-1-R.png   [[0.0007667092, 0.0022641725, 0.98829377, 0.00...    8   A   \n","Day 9_A8-1-R.png   [[0.0007661236, 0.002261453, 0.98830634, 0.008...    9   A   \n","Day 10_A8-1-R.png  [[0.0007669503, 0.0022568833, 0.9883336, 0.008...   10   A   \n","Day 11_A8-1-R.png  [[0.0007687209, 0.0022586198, 0.98830867, 0.00...   11   A   \n","Day 12_A8-1-R.png  [[0.0007665131, 0.002246504, 0.98840904, 0.008...   12   A   \n","Day 13_A8-1-R.png  [[0.00076724775, 0.0022522574, 0.9883554, 0.00...   13   A   \n","Day 14_A8-1-R.png  [[0.0007706092, 0.0022496565, 0.98835343, 0.00...   14   A   \n","Day 15_A8-1-R.png  [[0.00076415454, 0.0022305283, 0.98848456, 0.0...   15   A   \n","\n","                   Mouse Side  \n","Day 0_A8-1-R.png       1    R  \n","Day 1_A8-1-R.png       1    R  \n","Day 2_A8-1-R.png       1    R  \n","Day 3_A8-1-R.png       1    R  \n","Day 4_A8-1-R.png       1    R  \n","Day 5_A8-1-R.png       1    R  \n","Day 6_A8-1-R.png       1    R  \n","Day 7_A8-1-R.png       1    R  \n","Day 8_A8-1-R.png       1    R  \n","Day 9_A8-1-R.png       1    R  \n","Day 10_A8-1-R.png      1    R  \n","Day 11_A8-1-R.png      1    R  \n","Day 12_A8-1-R.png      1    R  \n","Day 13_A8-1-R.png      1    R  \n","Day 14_A8-1-R.png      1    R  \n","Day 15_A8-1-R.png      1    R  "],"text/html":["\n","  <div id=\"df-fac45848-c5be-4647-a966-ac2809317669\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>Day</th>\n","      <th>Age</th>\n","      <th>Mouse</th>\n","      <th>Side</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_A8-1-R.png</th>\n","      <td>[0.9, 0.1, 0.0, 0.0]</td>\n","      <td>[[0.0007662976, 0.002264746, 0.9882834, 0.0086...</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_A8-1-R.png</th>\n","      <td>[0.1, 0.8, 0.1, 0.0]</td>\n","      <td>[[0.0007634308, 0.0022500332, 0.988376, 0.0086...</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[[0.0007654989, 0.0022612421, 0.9883159, 0.008...</td>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[[0.0007688016, 0.002287011, 0.9882036, 0.0087...</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.3636363636363636, 0.6363636363636364, 0.0, ...</td>\n","      <td>[[0.0007682852, 0.0022748422, 0.9882572, 0.008...</td>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_A8-1-R.png</th>\n","      <td>[0.2, 0.5, 0.3, 0.0]</td>\n","      <td>[[0.0007663971, 0.0022515245, 0.98835796, 0.00...</td>\n","      <td>5</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_A8-1-R.png</th>\n","      <td>[0.2, 0.7, 0.1, 0.0]</td>\n","      <td>[[0.0007645951, 0.002251848, 0.9883652, 0.0086...</td>\n","      <td>6</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_A8-1-R.png</th>\n","      <td>[0.1, 0.7, 0.1, 0.1]</td>\n","      <td>[[0.00076561735, 0.0022552274, 0.9883435, 0.00...</td>\n","      <td>7</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_A8-1-R.png</th>\n","      <td>[0.2, 0.6, 0.2, 0.0]</td>\n","      <td>[[0.0007667092, 0.0022641725, 0.98829377, 0.00...</td>\n","      <td>8</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.4545454545454545, 0.454...</td>\n","      <td>[[0.0007661236, 0.002261453, 0.98830634, 0.008...</td>\n","      <td>9</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_A8-1-R.png</th>\n","      <td>[0.1, 0.4, 0.5, 0.0]</td>\n","      <td>[[0.0007669503, 0.0022568833, 0.9883336, 0.008...</td>\n","      <td>10</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.8, 0.1]</td>\n","      <td>[[0.0007687209, 0.0022586198, 0.98830867, 0.00...</td>\n","      <td>11</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[[0.0007665131, 0.002246504, 0.98840904, 0.008...</td>\n","      <td>12</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.5, 0.4]</td>\n","      <td>[[0.00076724775, 0.0022522574, 0.9883554, 0.00...</td>\n","      <td>13</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.3, 0.6]</td>\n","      <td>[[0.0007706092, 0.0022496565, 0.98835343, 0.00...</td>\n","      <td>14</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.6, 0.3]</td>\n","      <td>[[0.00076415454, 0.0022305283, 0.98848456, 0.0...</td>\n","      <td>15</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fac45848-c5be-4647-a966-ac2809317669')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fac45848-c5be-4647-a966-ac2809317669 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fac45848-c5be-4647-a966-ac2809317669');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[""],"metadata":{"id":"1vlydbcZHgRL","executionInfo":{"status":"ok","timestamp":1651086158998,"user_tz":420,"elapsed":63,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":36,"outputs":[]}]}