{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CMSF-KM tests.ipynb","provenance":[],"collapsed_sections":["2Kf8dwhPqGxx","_UM2GHuMpLbF","h0rrgRKnpUr6","q9gXb5tmpnzD","5yp7qblbkJ9J","VzeXb2y52ktA","uYvYec8y2n8g","cw-FQg2fHl9Z"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2c823cfd3f9248049d65e9a50745801b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8021a56824ec48f6b7962e97beeec5c4","IPY_MODEL_304daea1cced4ede9cc011f19bbee717","IPY_MODEL_40b0e2e97eea4b018fba6e50ea51c386"],"layout":"IPY_MODEL_7c1f9a0d9ac74016aa59106d8f5c25bd"}},"8021a56824ec48f6b7962e97beeec5c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bcef4dab5ee44288a25841b2c3e2893","placeholder":"​","style":"IPY_MODEL_de9d735284b34967860a06de5e885470","value":"100%"}},"304daea1cced4ede9cc011f19bbee717":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8c2c7814c704d07959e94ec6479c801","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9daabdab71541a29bde103a1cca4968","value":46830571}},"40b0e2e97eea4b018fba6e50ea51c386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9efa7d01a62547beb41adca5ccb8d5a4","placeholder":"​","style":"IPY_MODEL_ff25c54a147b4ed983b94cf673e98df0","value":" 44.7M/44.7M [00:00&lt;00:00, 111MB/s]"}},"7c1f9a0d9ac74016aa59106d8f5c25bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bcef4dab5ee44288a25841b2c3e2893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de9d735284b34967860a06de5e885470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8c2c7814c704d07959e94ec6479c801":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9daabdab71541a29bde103a1cca4968":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9efa7d01a62547beb41adca5ccb8d5a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff25c54a147b4ed983b94cf673e98df0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"2Kf8dwhPqGxx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyikNXbYxhq6","executionInfo":{"status":"ok","timestamp":1651654658430,"user_tz":420,"elapsed":315,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"6f6b98ae-23a5-4464-e358-fb1fb4fb3672"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}],"source":["#GPU runtime required, should give CUDA version\n","!nvcc --version"]},{"cell_type":"code","source":["!pip install faiss-gpu\n","!pip install fuzzy-c-means"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFauSYcBymkd","executionInfo":{"status":"ok","timestamp":1651654675703,"user_tz":420,"elapsed":17092,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"26f9f7d7-48c0-4edc-8e60-e0a7134a1565"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 118 kB/s \n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n","Collecting fuzzy-c-means\n","  Downloading fuzzy_c_means-1.6.3-py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n","Requirement already satisfied: numpy<2.0.0,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (1.21.6)\n","Collecting pydantic<2.0.0,>=1.8.2\n","  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n","\u001b[K     |████████████████████████████████| 10.9 MB 5.2 MB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.2\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (4.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n","Installing collected packages: typer, pydantic, fuzzy-c-means\n","Successfully installed fuzzy-c-means-1.6.3 pydantic-1.9.0 typer-0.3.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SA5CzMz1tAp","executionInfo":{"status":"ok","timestamp":1651654697676,"user_tz":420,"elapsed":21984,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"c4ad72cd-1a25-4466-f764-936a337580ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!cp -r /content/gdrive/MyDrive/Explainable_Wound_Classification/CMSF/self_supervised/* /content\n","root_path = 'gdrive/MyDrive/Explainable_Wound_Classification/'"],"metadata":{"id":"lu1Z3VWPP2fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import builtins\n","import os\n","import sys\n","import time\n","import argparse\n","import random\n","import copy\n","from collections import Counter, OrderedDict\n","from random import shuffle\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torchvision import transforms, datasets, models\n","\n","from PIL import ImageFilter, Image\n","from util import adjust_learning_rate, AverageMeter as AvgMeter, subset_classes\n","\n","import pdb\n","import faiss\n","from fcmeans import FCM\n","\n","import numpy as np\n","from scipy import stats\n","import pandas as pd\n","import re\n","from collections import namedtuple\n","\n","import shutil\n","import warnings\n","\n","import torch.nn.parallel\n","import torch.optim\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","from tools import *"],"metadata":{"id":"sbLSB0x9ypbr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#CMSF-KM"],"metadata":{"id":"eDcwok-ko9t1"}},{"cell_type":"markdown","source":["### Misc Functions"],"metadata":{"id":"_UM2GHuMpLbF"}},{"cell_type":"code","source":["def get_mlp(inp_dim, hidden_dim, out_dim):\n","    mlp = nn.Sequential(\n","        nn.Linear(inp_dim, hidden_dim),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.ReLU(inplace=True),\n","        nn.Linear(hidden_dim, out_dim),\n","    )\n","    return mlp"],"metadata":{"id":"UOMD8VPsPCir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_parameter_requires_grad(model):\n","    for param in model.parameters():\n","        param.requires_grad = False"],"metadata":{"id":"_kesUL1R3Aey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def faiss_kmeans(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    d = feats.shape[-1]\n","    clus = faiss.Clustering(d, nmb_clusters)\n","    clus.niter = 20\n","    clus.max_points_per_centroid = 10000000\n","\n","    index = faiss.IndexFlatL2(d)\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    index = faiss.index_cpu_to_all_gpus(index, co)\n","\n","    # perform the training\n","    clus.train(feats, index)\n","    _, train_a = index.search(feats, 1)\n","\n","    return list(train_a[:, 0])"],"metadata":{"id":"UQ0DsdOY3ghX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fuzzy_c_means(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    \n","    fcm = FCM(n_clusters=nmb_clusters)\n","    fcm.fit(feats)\n","\n","    return fcm.predict(feats), fcm"],"metadata":{"id":"c3V34JDdO1Ql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_shuffle_ids(bsz):\n","    \"\"\"generate shuffle ids for ShuffleBN\"\"\"\n","    forward_inds = torch.randperm(bsz).long().cuda()\n","    backward_inds = torch.zeros(bsz).long().cuda()\n","    value = torch.arange(bsz).long().cuda()\n","    backward_inds.index_copy_(0, forward_inds, value)\n","    return forward_inds, backward_inds\n"],"metadata":{"id":"K2ZY6QzB7OrS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Architecture"],"metadata":{"id":"h0rrgRKnpUr6"}},{"cell_type":"code","source":["def initialize_encoder(model_name, output_dim, use_pretrained=True):\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, output_dim)\n","        input_size = 224\n","\n","    elif model_name == \"alexnet\":\n","        \"\"\" Alexnet\n","        \"\"\"\n","        model_ft = models.alexnet(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,output_dim)\n","        input_size = 224\n","\n","    elif model_name == \"vgg\":\n","        \"\"\" VGG11_bn\n","        \"\"\"\n","        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,output_dim)\n","        input_size = 224\n","\n","    elif model_name == \"squeezenet\":\n","        \"\"\" Squeezenet\n","        \"\"\"\n","        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        model_ft.classifier[1] = nn.Conv2d(512, output_dim, kernel_size=(1,1), stride=(1,1))\n","        model_ft.num_classes = output_dim\n","        input_size = 224\n","\n","    elif model_name == \"densenet\":\n","        \"\"\" Densenet\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, output_dim)\n","        input_size = 224\n","\n","    elif model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        # Handle the auxilary net\n","        num_ftrs = model_ft.AuxLogits.fc.in_features\n","        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, output_dim)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs,output_dim)\n","        input_size = 299\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size"],"metadata":{"id":"dnaWq6-JMO2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConstrainedMeanShiftKM(nn.Module):\n","    def __init__(self, arch, m=0.99, mem_bank_size=128000, topk=5, dataset_size=100, num_clusters=4, output_dim=16):\n","        super(ConstrainedMeanShiftKM, self).__init__()\n","\n","        # save parameters\n","        self.m = m\n","        self.mem_bank_size = mem_bank_size\n","        self.topk = topk\n","        self.dataset_size = dataset_size\n","        self.num_clusters = num_clusters\n","\n","        # create encoders and projection layers\n","        # both encoders should have same arch\n","        self.encoder_q = initialize_encoder(arch, output_dim)[0]\n","        self.encoder_t = initialize_encoder(arch, output_dim)[0]\n","\n","        # prediction layer\n","        self.predict_q = get_mlp(output_dim, output_dim * 2, output_dim)\n","\n","        # copy query encoder weights to target encoder\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data.copy_(param_q.data)\n","            param_t.requires_grad = False\n","\n","        print(\"using mem-bank size {}\".format(self.mem_bank_size))\n","        # setup queue (For Storing Random Targets)\n","        self.register_buffer('queue', torch.randn(self.mem_bank_size, output_dim))\n","        self.register_buffer('pool', torch.randn(self.dataset_size, output_dim))\n","        self.register_buffer('pseudo_labels', 0*torch.ones(self.dataset_size).long())\n","        # normalize the queue embeddings\n","        self.queue = nn.functional.normalize(self.queue, dim=1)\n","        # initialize the labels queue (For Purity measurement)\n","        self.register_buffer('labels', -1*torch.ones(self.mem_bank_size).long())\n","        self.register_buffer('index_queue', -1 * torch.ones(self.mem_bank_size).long())\n","        # setup the queue pointer\n","        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n","\n","    @torch.no_grad()\n","    def _momentum_update_target_encoder(self):\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data = param_t.data * self.m + param_q.data * (1. - self.m)\n","\n","    @torch.no_grad()\n","    def data_parallel(self):\n","        self.encoder_q = torch.nn.DataParallel(self.encoder_q)\n","        self.encoder_t = torch.nn.DataParallel(self.encoder_t)\n","        self.predict_q = torch.nn.DataParallel(self.predict_q)\n","\n","    @torch.no_grad()\n","    def cluster(self):\n","        print('start clustering ... num clusters: {}'.format(self.num_clusters))\n","        cluster_assignment, cluster_model = fuzzy_c_means(self.pool.clone().cpu(), self.num_clusters)\n","        self.pseudo_labels = torch.tensor(cluster_assignment).cuda()\n","        return cluster_model\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue(self, targets, labels, indices):\n","        batch_size = targets.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","        assert self.mem_bank_size % batch_size == 0 \n","\n","        # replace the targets at ptr (dequeue and enqueue)\n","        self.pool[indices, :] = targets\n","        self.queue[ptr:ptr + batch_size] = targets\n","        self.labels[ptr:ptr + batch_size] = labels\n","        self.index_queue[ptr:ptr + batch_size] = indices\n","        ptr = (ptr + batch_size) % self.mem_bank_size  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","    def forward(self, im_q, im_t, labels, indices):\n","        # compute query features\n","        feat_q = self.encoder_q(im_q)\n","        # compute predictions for instance level regression loss\n","        query = self.predict_q(feat_q)\n","        query = nn.functional.normalize(query, dim=1)\n","\n","        # compute target features\n","        with torch.no_grad():\n","            # update the target encoder\n","            self._momentum_update_target_encoder()\n","\n","            # shuffle targets\n","            shuffle_ids, reverse_ids = get_shuffle_ids(im_t.shape[0])\n","            im_t = im_t[shuffle_ids]\n","\n","            # forward through the target encoder\n","            current_target = self.encoder_t(im_t)\n","            current_target = nn.functional.normalize(current_target, dim=1)\n","\n","            # undo shuffle\n","            current_target = current_target[reverse_ids].detach()\n","\n","            # update the memory-bank\n","            self._dequeue_and_enqueue(current_target, labels, indices)\n","\n","        targets = self.queue.clone().detach()\n","\n","        # get pseudo of target and memory bank samples\n","        current_target_pseudo_labels = self.pseudo_labels[indices]\n","        targets_pseudo_labels = self.pseudo_labels[self.index_queue]\n","\n","        # create a mask to constrain the search space\n","        b = current_target_pseudo_labels.shape[0]\n","        m = targets_pseudo_labels.shape[0]\n","        lx = current_target_pseudo_labels.unsqueeze(1).expand((b, m))\n","        lm = targets_pseudo_labels.unsqueeze(0).expand((b, m))\n","        msk = lx != lm\n","\n","        # calculate distances between vectors\n","        dist_t = 2 - 2 * torch.einsum('bc,kc->bk', [current_target, targets])\n","        dist_q = 2 - 2 * torch.einsum('bc,kc->bk', [query, targets])\n","\n","        # select the k nearest neighbors [with smallest distance (largest=False)] based on current target\n","        _, unconstrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # select the k nearest neighbors based on constrained memory bank\n","        dist_t[torch.where(msk)] = 5.0\n","        _, constrained_nn_index = dist_t.topk(self.topk, dim=1, largest=False)\n","\n","        # calculate mean shift regression loss\n","        nn_dist_q_constrained = torch.gather(dist_q, 1, constrained_nn_index)\n","        nn_dist_q_unconstrained = torch.gather(dist_q, 1, unconstrained_nn_index)\n","\n","        # purity based on memory bank\n","        labels = labels.unsqueeze(1).expand(nn_dist_q_unconstrained.shape[0], nn_dist_q_unconstrained.shape[1])\n","        labels_queue = self.labels.clone().detach()\n","        labels_queue = labels_queue.unsqueeze(0).expand((nn_dist_q_unconstrained.shape[0], self.mem_bank_size))\n","        labels_queue = torch.gather(labels_queue, dim=1, index=unconstrained_nn_index)\n","# TODO: Change matches here\n","        matches = (labels_queue == labels).float()\n","        purity = (matches.sum(dim=1) / self.topk).mean()\n","\n","        loss = ((nn_dist_q_constrained.sum(dim=1) / self.topk).mean()\n","                + (nn_dist_q_unconstrained.sum(dim=1) / self.topk).mean()) / 2.0\n","\n","        return loss, purity"],"metadata":{"id":"9WrVPdUa3m1Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformations/Data Loading"],"metadata":{"id":"q9gXb5tmpnzD"}},{"cell_type":"code","source":["class TwoCropsTransform:\n","    \"\"\"Take two random crops of one image as the query and target.\"\"\"\n","    def __init__(self, weak_transform, strong_transform):\n","        self.weak_transform = weak_transform\n","        self.strong_transform = strong_transform\n","        print(self.weak_transform)\n","        print(self.strong_transform)\n","\n","    def __call__(self, x):\n","        q = self.strong_transform(x)\n","        t = self.weak_transform(x)\n","        return [q, t]\n","\n","\n","class GaussianBlur(object):\n","    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n","\n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","\n","    def __call__(self, x):\n","        sigma = random.uniform(self.sigma[0], self.sigma[1])\n","        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n","        return x"],"metadata":{"id":"8lqpv_uE7Dsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Image_Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, root_dir, label_fn, transform=None):\n","        \"\"\"\n","        Image dataset. Returns tensorized images and labels with index\n","        Args:\n","            root_dir: path to a cropped mouse image dataset.\n","            label_fn: function that returns the correct label given an image name\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.label_fn = label_fn\n","        self.transform = transform\n","\n","        samples = []\n","        targets = []\n","        for f in os.listdir(root_dir):\n","            samples.append(os.path.join(root_dir, f))\n","            targets.append(label_fn(f))\n","        \n","        self.samples = samples\n","        self.targets = targets\n","\n","    def pil_loader(self, path):\n","        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n","        with open(path, 'rb') as f:\n","            img = Image.open(f)\n","            return img.convert('RGB')\n","\n","    def __getitem__(self, index: int):\n","            \"\"\"\n","            Returns index, tensor data, and tensorized label.\n","            \"\"\"\n","            img = self.pil_loader(self.samples[index])\n","            target = self.targets[index]\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return index, img, torch.tensor(target)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __str__(self):\n","        return \"Image_Dataset:\\n\" + \"Found \" + str(len(self)) + \" images in \" + self.root_dir + \"\\n\""],"metadata":{"id":"S7XGxXyYA87o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create train loader\n","def get_train_loader(datapath, label_fn, batch_size, num_workers, weak_strong=True):\n","    traindir = os.path.join(datapath, 'train')\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","\n","    augmentation_strong = [\n","        #transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.Resize(224),\n","        #transforms.RandomApply([\n","        #    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n","        #], p=0.8),\n","        #transforms.RandomGrayscale(p=0.2),\n","        #transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n","        #transforms.RandomHorizontalFlip(),\n","        transforms.ColorJitter(saturation=(0,1)),\n","        transforms.RandomRotation((0, 360)),\n","        transforms.RandomAffine((0,0), translate=(0.3, 0.3)),\n","        transforms.ToTensor(),\n","        normalize\n","    ]\n","\n","    augmentation_weak = [\n","        #transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n","        transforms.Resize(224),\n","        #transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation((0, 360)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]\n","\n","    if weak_strong:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_strong))\n","        )\n","    else:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_weak))\n","        )\n","\n","    print('==> train dataset')\n","    print(train_dataset)\n","\n","    # NOTE: remove drop_last\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, shuffle=True,\n","        num_workers=num_workers, pin_memory=True, drop_last=True)\n","\n","    return train_loader"],"metadata":{"id":"5MMumuTc7qmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_val_loader(datapath, label_fn, num_workers, batch_size=-1, test=False, train=False):\n","    if test:\n","        valdir = os.path.join(datapath, 'test')\n","    elif train:\n","        valdir = os.path.join(datapath, 'train')\n","    else:\n","        valdir = os.path.join(datapath, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    val_transform = transforms.Compose([\n","        #transforms.Resize(256),\n","        #transforms.CenterCrop(224),\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    dataset = Image_Dataset(valdir, label_fn, val_transform)\n","\n","    if batch_size == -1:\n","        batch_size = len(dataset)\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False,\n","        num_workers=num_workers, pin_memory=True,\n","    )\n","    return val_loader, dataset.samples"],"metadata":{"id":"IRWu3Hk6ZS5U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"6JT3uvt0pym_"}},{"cell_type":"code","source":["def train(epoch, train_loader, mean_shift, optimizer, print_freq):\n","    \"\"\"\n","    one epoch training\n","    \"\"\"\n","    mean_shift.train()\n","\n","    batch_time = AvgMeter()\n","    data_time = AvgMeter()\n","    loss_meter = AvgMeter()\n","    purity_meter = AvgMeter()\n","\n","    end = time.time()\n","    for idx, (indices, (im_q, im_t), labels) in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","        im_q = im_q.cuda(non_blocking=True)\n","        im_t = im_t.cuda(non_blocking=True)\n","        labels = labels.cuda(non_blocking=True)\n","\n","        # ===================forward=====================\n","        loss, purity = mean_shift(im_q=im_q, im_t=im_t, labels=labels, indices=indices)\n","\n","        # ===================backward=====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ===================meters=====================\n","        loss_meter.update(loss.item(), im_q.size(0))\n","        purity_meter.update(purity.item(), im_q.size(0))\n","\n","        torch.cuda.synchronize()\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        # print info\n","        if (idx + 1) % print_freq == 0:\n","            print('Train: [{0}][{1}/{2}]\\t'\n","                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'purity {purity.val:.3f} ({purity.avg:.3f})\\t'\n","                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'.format(\n","                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                   data_time=data_time,\n","                   purity=purity_meter,\n","                   loss=loss_meter))\n","            sys.stdout.flush()\n","            sys.stdout.flush()\n","\n","    \n","\n","    return loss_meter.avg, purity_meter.avg"],"metadata":{"id":"kbeHAYjbVSaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#workaround struct to pass args to util script\n","LRArgs = namedtuple('LRArgs', ['cos', 'learning_rate', 'epochs', 'lr_decay_rate'])"],"metadata":{"id":"rXCJ1Q94dBEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cmsf_km_main(data_path, checkpoint_path, label_fn, batch_size=16, num_workers=2, \n","                 epochs=200, print_freq=10, save_freq=10, weak_strong=True, \n","                 debug=False, arch='resnet50', momentum=0.99, mem_bank_size=128000, \n","                 topk=5, num_clusters=4, learning_rate=0.05, sgd_momentum=0.9, \n","                 weight_decay=1e-4, weights=None, resume=None, cos=True, \n","                 lr_decay_rate=0.2, output_dim=16):\n","    \"\"\"\n","    todo: docstring\n","    \"\"\"\n","    opt = locals()\n","    del opt['label_fn']\n","\n","    os.makedirs(checkpoint_path, exist_ok=True)\n","\n","    train_loader = get_train_loader(data_path, label_fn, batch_size, num_workers, weak_strong)\n","\n","    mean_shift = ConstrainedMeanShiftKM(\n","        arch,\n","        m=momentum,\n","        mem_bank_size=mem_bank_size,\n","        topk=topk,\n","        dataset_size=len(train_loader.dataset),\n","        num_clusters=num_clusters,\n","        output_dim=output_dim\n","    )\n","\n","    mean_shift.data_parallel()\n","    mean_shift = mean_shift.cuda()\n","    print(mean_shift)\n","\n","\n","    print(\"Params to learn:\")\n","    for name,param in mean_shift.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","    params = [p for p in mean_shift.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params,\n","                                lr=learning_rate,\n","                                momentum=sgd_momentum,\n","                                weight_decay=weight_decay)\n","\n","    cudnn.benchmark = True\n","    start_epoch = 1\n","\n","    history_df = pd.DataFrame(index=range(start_epoch, epochs + 1))\n","\n","    if weights:\n","        print('==> load weights from checkpoint: {}'.format(weights))\n","        ckpt = torch.load(weights)\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        if 'model' in ckpt:\n","            sd = ckpt['model']\n","        else:\n","            sd = ckpt['state_dict']\n","        msg = mean_shift.load_state_dict(sd, strict=False)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        start_epoch = ckpt['epoch'] + 1\n","        print(msg)\n","    \n","\n","    if resume:\n","        print('==> resume from checkpoint: {}'.format(resume))\n","        ckpt = torch.load(resume, map_location='cpu')\n","        # sd = ckpt['state_dict']\n","        # sd = {k.replace('module.', ''): v for k, v in sd.items()}\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        mean_shift.load_state_dict(ckpt['state_dict'], strict=True)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        start_epoch = ckpt['epoch'] + 1\n","        history_df = ckpt['history_df']\n","\n","    lr_args = LRArgs(cos, learning_rate, epochs, lr_decay_rate)\n","\n","    for epoch in range(start_epoch, epochs + 1):\n","\n","        adjust_learning_rate(epoch, lr_args, optimizer)\n","        print(\"==> training...\")\n","\n","        time1 = time.time()\n","\n","        loss, purity = train(epoch, train_loader, mean_shift, optimizer, print_freq)\n","        cluster_model = mean_shift.cluster()\n","\n","        time2 = time.time()\n","        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n","\n","        history_df.loc[epoch, 'loss'] = loss\n","        history_df.loc[epoch, 'purity'] = purity\n","\n","        # saving the model\n","        if epoch % save_freq == 0:\n","            print('==> Saving...')\n","            state = {\n","                'opt': opt,\n","                'state_dict': mean_shift.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epoch,\n","                'history_df': history_df\n","            }\n","\n","            save_file = os.path.join(checkpoint_path, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n","            torch.save(state, save_file)\n","\n","            # help release GPU memory\n","            del state\n","            torch.cuda.empty_cache()"],"metadata":{"id":"nbS9piVdV8T_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Getting Label Assignments"],"metadata":{"id":"5yp7qblbkJ9J"}},{"cell_type":"code","source":["labels_df = pd.read_csv(root_path + 'Updated_Cropped_Images_Wound_Stage_Probabilities.csv', index_col='Image')\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"4pQa0ql3kI6v","executionInfo":{"status":"ok","timestamp":1651654708103,"user_tz":420,"elapsed":207,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"aa0207b2-51cb-4897-90f0-47d2278a8346"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation\n","Image                                                                 \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000"],"text/html":["\n","  <div id=\"df-9a3795b9-a31e-4361-81ca-96318d7943a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3795b9-a31e-4361-81ca-96318d7943a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9a3795b9-a31e-4361-81ca-96318d7943a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9a3795b9-a31e-4361-81ca-96318d7943a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["labels_df['label'] = labels_df.index.map(lambda x: labels_df.loc[x].argmax())\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"hvuzz2tgktSO","executionInfo":{"status":"ok","timestamp":1651654708307,"user_tz":420,"elapsed":211,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"e57d9f99-8619-467e-e14f-027391924c4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation  label\n","Image                                                                        \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818      2\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000      1\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091      3\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455      3\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000      1"],"text/html":["\n","  <div id=\"df-5aaedad8-d64c-4459-b618-1fa35c435c57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aaedad8-d64c-4459-b618-1fa35c435c57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5aaedad8-d64c-4459-b618-1fa35c435c57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5aaedad8-d64c-4459-b618-1fa35c435c57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["labels_map = labels_df['label']\n","labels_map.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UZrhjs_l7Bz","executionInfo":{"status":"ok","timestamp":1651654708966,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"6a3fd2c5-559a-4d51-c121-d3241bc0913c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Image\n","Day 8_A8-4-L.png     2\n","Day 4_A8-3-R.png     1\n","Day 14_Y8-4-L.png    3\n","Day 7_Y8-4-L.png     3\n","Day 2_A8-1-L.png     1\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["### Folder to store outputs and number of epochs to run"],"metadata":{"id":"ChoSMs3wRIHO"}},{"cell_type":"code","source":["train_folder_name = 'transforms_1/'\n","epochs = 200"],"metadata":{"id":"22JGUWI8QWej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CMSF-KM Training"],"metadata":{"id":"55w0V6ivp5AT"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"4om4mdoQrErk"}},{"cell_type":"code","source":["cmsf_km_main(\n","    data_path=root_path + 'Split_images', \n","    checkpoint_path=root_path + 'outputs/' + train_folder_name, \n","    label_fn=lambda x: labels_map[x],\n","    batch_size=8,\n","    num_workers=2,\n","    epochs=epochs,\n","    arch='resnet',\n","    topk=5,\n","    num_clusters=4,\n","    learning_rate=0.05,\n","    mem_bank_size=128000,\n","    weak_strong=True,\n","    output_dim=16,\n","    debug=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2c823cfd3f9248049d65e9a50745801b","8021a56824ec48f6b7962e97beeec5c4","304daea1cced4ede9cc011f19bbee717","40b0e2e97eea4b018fba6e50ea51c386","7c1f9a0d9ac74016aa59106d8f5c25bd","0bcef4dab5ee44288a25841b2c3e2893","de9d735284b34967860a06de5e885470","a8c2c7814c704d07959e94ec6479c801","c9daabdab71541a29bde103a1cca4968","9efa7d01a62547beb41adca5ccb8d5a4","ff25c54a147b4ed983b94cf673e98df0"]},"id":"udb2Oop0jJ7y","outputId":"56c49cf2-b1c0-4e6d-f4f5-dc249b6da141","executionInfo":{"status":"ok","timestamp":1651636579822,"user_tz":420,"elapsed":475879,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    RandomRotation(degrees=[0.0, 360.0], interpolation=nearest, expand=False, fill=0)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    ColorJitter(brightness=None, contrast=None, saturation=(0, 1), hue=None)\n","    RandomRotation(degrees=[0.0, 360.0], interpolation=nearest, expand=False, fill=0)\n","    RandomAffine(degrees=[0.0, 0.0], translate=(0.3, 0.3))\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","==> train dataset\n","Image_Dataset:\n","Found 191 images in gdrive/MyDrive/Explainable_Wound_Classification/Split_images/train\n","\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c823cfd3f9248049d65e9a50745801b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["using mem-bank size 128000\n","ConstrainedMeanShiftKM(\n","  (encoder_q): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=16, bias=True)\n","    )\n","  )\n","  (encoder_t): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=16, bias=True)\n","    )\n","  )\n","  (predict_q): DataParallel(\n","    (module): Sequential(\n","      (0): Linear(in_features=16, out_features=32, bias=True)\n","      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=32, out_features=16, bias=True)\n","    )\n","  )\n",")\n","Params to learn:\n","\t encoder_q.module.fc.weight\n","\t encoder_q.module.fc.bias\n","\t predict_q.module.0.weight\n","\t predict_q.module.0.bias\n","\t predict_q.module.1.weight\n","\t predict_q.module.1.bias\n","\t predict_q.module.3.weight\n","\t predict_q.module.3.bias\n","LR: 0.05\n","==> training...\n","Train: [1][10/23]\tBT 0.076 (0.439)\tDT 0.000 (0.286)\tpurity 0.350 (0.333)\tloss 0.393 (0.730)\t\n","Train: [1][20/23]\tBT 0.071 (0.262)\tDT 0.001 (0.144)\tpurity 0.500 (0.383)\tloss 0.499 (0.573)\t\n","start clustering ... num clusters: 4\n","epoch 1, total time 5.52\n","LR: 0.04999691581204152\n","==> training...\n","Train: [2][10/23]\tBT 0.081 (0.109)\tDT 0.007 (0.024)\tpurity 0.600 (0.540)\tloss 0.396 (0.400)\t\n","Train: [2][20/23]\tBT 0.071 (0.098)\tDT 0.000 (0.013)\tpurity 0.575 (0.571)\tloss 0.312 (0.376)\t\n","start clustering ... num clusters: 4\n","epoch 2, total time 2.26\n","LR: 0.04998766400914329\n","==> training...\n","Train: [3][10/23]\tBT 0.094 (0.121)\tDT 0.007 (0.038)\tpurity 0.575 (0.640)\tloss 0.217 (0.244)\t\n","Train: [3][20/23]\tBT 0.084 (0.105)\tDT 0.000 (0.021)\tpurity 0.475 (0.636)\tloss 0.199 (0.220)\t\n","start clustering ... num clusters: 4\n","epoch 3, total time 2.37\n","LR: 0.049972246874049255\n","==> training...\n","Train: [4][10/23]\tBT 0.090 (0.112)\tDT 0.012 (0.026)\tpurity 0.600 (0.625)\tloss 0.134 (0.160)\t\n","Train: [4][20/23]\tBT 0.071 (0.099)\tDT 0.000 (0.014)\tpurity 0.475 (0.608)\tloss 0.174 (0.163)\t\n","start clustering ... num clusters: 4\n","epoch 4, total time 2.26\n","LR: 0.04995066821070679\n","==> training...\n","Train: [5][10/23]\tBT 0.084 (0.103)\tDT 0.000 (0.023)\tpurity 0.650 (0.638)\tloss 0.144 (0.151)\t\n","Train: [5][20/23]\tBT 0.073 (0.093)\tDT 0.000 (0.012)\tpurity 0.625 (0.643)\tloss 0.130 (0.147)\t\n","start clustering ... num clusters: 4\n","epoch 5, total time 2.16\n","LR: 0.0499229333433282\n","==> training...\n","Train: [6][10/23]\tBT 0.082 (0.106)\tDT 0.000 (0.023)\tpurity 0.600 (0.665)\tloss 0.178 (0.142)\t\n","Train: [6][20/23]\tBT 0.071 (0.097)\tDT 0.000 (0.012)\tpurity 0.675 (0.663)\tloss 0.177 (0.144)\t\n","start clustering ... num clusters: 4\n","epoch 6, total time 2.21\n","LR: 0.049889049115077\n","==> training...\n","Train: [7][10/23]\tBT 0.077 (0.108)\tDT 0.000 (0.027)\tpurity 0.625 (0.628)\tloss 0.116 (0.125)\t\n","Train: [7][20/23]\tBT 0.080 (0.096)\tDT 0.000 (0.015)\tpurity 0.775 (0.678)\tloss 0.126 (0.130)\t\n","start clustering ... num clusters: 4\n","epoch 7, total time 2.19\n","LR: 0.0498490238863795\n","==> training...\n","Train: [8][10/23]\tBT 0.075 (0.158)\tDT 0.000 (0.041)\tpurity 0.550 (0.690)\tloss 0.124 (0.121)\t\n","Train: [8][20/23]\tBT 0.071 (0.149)\tDT 0.000 (0.023)\tpurity 0.775 (0.685)\tloss 0.145 (0.129)\t\n","start clustering ... num clusters: 4\n","epoch 8, total time 3.47\n","LR: 0.04980286753286195\n","==> training...\n","Train: [9][10/23]\tBT 0.078 (0.143)\tDT 0.000 (0.062)\tpurity 0.725 (0.713)\tloss 0.132 (0.120)\t\n","Train: [9][20/23]\tBT 0.080 (0.116)\tDT 0.000 (0.035)\tpurity 0.675 (0.691)\tloss 0.158 (0.125)\t\n","start clustering ... num clusters: 4\n","epoch 9, total time 2.59\n","LR: 0.04975059144291394\n","==> training...\n","Train: [10][10/23]\tBT 0.089 (0.112)\tDT 0.000 (0.028)\tpurity 0.775 (0.682)\tloss 0.140 (0.132)\t\n","Train: [10][20/23]\tBT 0.083 (0.098)\tDT 0.000 (0.015)\tpurity 0.675 (0.675)\tloss 0.101 (0.131)\t\n","start clustering ... num clusters: 4\n","epoch 10, total time 2.24\n","==> Saving...\n","LR: 0.04969220851487845\n","==> training...\n","Train: [11][10/23]\tBT 0.086 (0.112)\tDT 0.000 (0.025)\tpurity 0.675 (0.683)\tloss 0.117 (0.137)\t\n","Train: [11][20/23]\tBT 0.078 (0.099)\tDT 0.000 (0.014)\tpurity 0.675 (0.688)\tloss 0.180 (0.139)\t\n","start clustering ... num clusters: 4\n","epoch 11, total time 2.25\n","LR: 0.04962773315386935\n","==> training...\n","Train: [12][10/23]\tBT 0.099 (0.111)\tDT 0.000 (0.029)\tpurity 0.600 (0.705)\tloss 0.141 (0.123)\t\n","Train: [12][20/23]\tBT 0.086 (0.097)\tDT 0.000 (0.016)\tpurity 0.675 (0.693)\tloss 0.137 (0.122)\t\n","start clustering ... num clusters: 4\n","epoch 12, total time 2.22\n","LR: 0.049557181268217225\n","==> training...\n","Train: [13][10/23]\tBT 0.092 (0.108)\tDT 0.000 (0.031)\tpurity 0.550 (0.715)\tloss 0.133 (0.153)\t\n","Train: [13][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.017)\tpurity 0.875 (0.699)\tloss 0.078 (0.143)\t\n","start clustering ... num clusters: 4\n","epoch 13, total time 2.19\n","LR: 0.049480570265544144\n","==> training...\n","Train: [14][10/23]\tBT 0.100 (0.115)\tDT 0.001 (0.024)\tpurity 0.750 (0.718)\tloss 0.115 (0.127)\t\n","Train: [14][20/23]\tBT 0.077 (0.098)\tDT 0.000 (0.013)\tpurity 0.625 (0.703)\tloss 0.121 (0.125)\t\n","start clustering ... num clusters: 4\n","epoch 14, total time 2.28\n","LR: 0.049397919048468686\n","==> training...\n","Train: [15][10/23]\tBT 0.090 (0.111)\tDT 0.001 (0.025)\tpurity 0.700 (0.700)\tloss 0.139 (0.136)\t\n","Train: [15][20/23]\tBT 0.093 (0.105)\tDT 0.014 (0.018)\tpurity 0.675 (0.709)\tloss 0.124 (0.133)\t\n","start clustering ... num clusters: 4\n","epoch 15, total time 2.46\n","LR: 0.049309248009941915\n","==> training...\n","Train: [16][10/23]\tBT 0.108 (0.120)\tDT 0.002 (0.033)\tpurity 0.575 (0.770)\tloss 0.100 (0.136)\t\n","Train: [16][20/23]\tBT 0.070 (0.102)\tDT 0.000 (0.017)\tpurity 0.700 (0.740)\tloss 0.143 (0.133)\t\n","start clustering ... num clusters: 4\n","epoch 16, total time 2.31\n","LR: 0.04921457902821578\n","==> training...\n","Train: [17][10/23]\tBT 0.084 (0.107)\tDT 0.000 (0.025)\tpurity 0.825 (0.743)\tloss 0.129 (0.136)\t\n","Train: [17][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.014)\tpurity 0.650 (0.759)\tloss 0.099 (0.129)\t\n","start clustering ... num clusters: 4\n","epoch 17, total time 2.22\n","LR: 0.049113935461444956\n","==> training...\n","Train: [18][10/23]\tBT 0.111 (0.109)\tDT 0.000 (0.024)\tpurity 0.750 (0.705)\tloss 0.155 (0.157)\t\n","Train: [18][20/23]\tBT 0.068 (0.098)\tDT 0.000 (0.013)\tpurity 0.675 (0.706)\tloss 0.111 (0.144)\t\n","start clustering ... num clusters: 4\n","epoch 18, total time 2.23\n","LR: 0.04900734214192358\n","==> training...\n","Train: [19][10/23]\tBT 0.081 (0.112)\tDT 0.000 (0.024)\tpurity 0.650 (0.778)\tloss 0.183 (0.136)\t\n","Train: [19][20/23]\tBT 0.077 (0.097)\tDT 0.000 (0.013)\tpurity 0.775 (0.755)\tloss 0.153 (0.133)\t\n","start clustering ... num clusters: 4\n","epoch 19, total time 2.21\n","LR: 0.048894825369958254\n","==> training...\n","Train: [20][10/23]\tBT 0.100 (0.111)\tDT 0.000 (0.028)\tpurity 0.875 (0.765)\tloss 0.132 (0.138)\t\n","Train: [20][20/23]\tBT 0.067 (0.098)\tDT 0.000 (0.015)\tpurity 0.925 (0.745)\tloss 0.121 (0.139)\t\n","start clustering ... num clusters: 4\n","epoch 20, total time 2.25\n","==> Saving...\n","LR: 0.048776412907378844\n","==> training...\n","Train: [21][10/23]\tBT 0.097 (0.112)\tDT 0.000 (0.023)\tpurity 0.800 (0.805)\tloss 0.132 (0.141)\t\n","Train: [21][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.012)\tpurity 0.650 (0.776)\tloss 0.152 (0.135)\t\n","start clustering ... num clusters: 4\n","epoch 21, total time 2.25\n","LR: 0.048652133970688634\n","==> training...\n","Train: [22][10/23]\tBT 0.078 (0.106)\tDT 0.000 (0.023)\tpurity 0.825 (0.740)\tloss 0.086 (0.141)\t\n","Train: [22][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.012)\tpurity 0.700 (0.739)\tloss 0.120 (0.137)\t\n","start clustering ... num clusters: 4\n","epoch 22, total time 2.20\n","LR: 0.04852201922385564\n","==> training...\n","Train: [23][10/23]\tBT 0.071 (0.116)\tDT 0.000 (0.024)\tpurity 0.725 (0.753)\tloss 0.127 (0.134)\t\n","Train: [23][20/23]\tBT 0.094 (0.108)\tDT 0.000 (0.013)\tpurity 0.800 (0.728)\tloss 0.168 (0.137)\t\n","start clustering ... num clusters: 4\n","epoch 23, total time 2.43\n","LR: 0.04838610077074669\n","==> training...\n","Train: [24][10/23]\tBT 0.103 (0.117)\tDT 0.000 (0.033)\tpurity 0.675 (0.770)\tloss 0.100 (0.129)\t\n","Train: [24][20/23]\tBT 0.071 (0.101)\tDT 0.000 (0.017)\tpurity 0.775 (0.726)\tloss 0.141 (0.137)\t\n","start clustering ... num clusters: 4\n","epoch 24, total time 2.29\n","LR: 0.04824441214720629\n","==> training...\n","Train: [25][10/23]\tBT 0.078 (0.106)\tDT 0.000 (0.022)\tpurity 0.825 (0.775)\tloss 0.130 (0.148)\t\n","Train: [25][20/23]\tBT 0.082 (0.097)\tDT 0.000 (0.012)\tpurity 0.725 (0.761)\tloss 0.115 (0.140)\t\n","start clustering ... num clusters: 4\n","epoch 25, total time 2.20\n","LR: 0.04809698831278217\n","==> training...\n","Train: [26][10/23]\tBT 0.072 (0.105)\tDT 0.000 (0.025)\tpurity 0.625 (0.743)\tloss 0.170 (0.145)\t\n","Train: [26][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.019)\tpurity 0.775 (0.755)\tloss 0.149 (0.146)\t\n","start clustering ... num clusters: 4\n","epoch 26, total time 2.19\n","LR: 0.04794386564209953\n","==> training...\n","Train: [27][10/23]\tBT 0.076 (0.106)\tDT 0.000 (0.024)\tpurity 0.600 (0.723)\tloss 0.168 (0.126)\t\n","Train: [27][20/23]\tBT 0.073 (0.095)\tDT 0.000 (0.014)\tpurity 0.875 (0.730)\tloss 0.175 (0.137)\t\n","start clustering ... num clusters: 4\n","epoch 27, total time 2.17\n","LR: 0.04778508191588613\n","==> training...\n","Train: [28][10/23]\tBT 0.119 (0.111)\tDT 0.000 (0.025)\tpurity 0.775 (0.757)\tloss 0.132 (0.126)\t\n","Train: [28][20/23]\tBT 0.087 (0.097)\tDT 0.000 (0.013)\tpurity 0.725 (0.733)\tloss 0.116 (0.129)\t\n","start clustering ... num clusters: 4\n","epoch 28, total time 2.22\n","LR: 0.04762067631165049\n","==> training...\n","Train: [29][10/23]\tBT 0.086 (0.106)\tDT 0.000 (0.023)\tpurity 0.825 (0.745)\tloss 0.189 (0.135)\t\n","Train: [29][20/23]\tBT 0.069 (0.092)\tDT 0.000 (0.012)\tpurity 0.650 (0.742)\tloss 0.107 (0.132)\t\n","start clustering ... num clusters: 4\n","epoch 29, total time 2.16\n","LR: 0.047450689394015394\n","==> training...\n","Train: [30][10/23]\tBT 0.093 (0.106)\tDT 0.000 (0.024)\tpurity 0.875 (0.790)\tloss 0.136 (0.133)\t\n","Train: [30][20/23]\tBT 0.078 (0.094)\tDT 0.000 (0.013)\tpurity 0.775 (0.739)\tloss 0.238 (0.143)\t\n","start clustering ... num clusters: 4\n","epoch 30, total time 2.17\n","==> Saving...\n","LR: 0.047275163104709195\n","==> training...\n","Train: [31][10/23]\tBT 0.086 (0.112)\tDT 0.000 (0.026)\tpurity 0.750 (0.798)\tloss 0.161 (0.136)\t\n","Train: [31][20/23]\tBT 0.080 (0.097)\tDT 0.000 (0.014)\tpurity 0.675 (0.775)\tloss 0.166 (0.143)\t\n","start clustering ... num clusters: 4\n","epoch 31, total time 2.24\n","LR: 0.047094140752217344\n","==> training...\n","Train: [32][10/23]\tBT 0.091 (0.109)\tDT 0.000 (0.028)\tpurity 0.600 (0.720)\tloss 0.177 (0.137)\t\n","Train: [32][20/23]\tBT 0.081 (0.097)\tDT 0.000 (0.015)\tpurity 0.825 (0.731)\tloss 0.078 (0.137)\t\n","start clustering ... num clusters: 4\n","epoch 32, total time 2.23\n","LR: 0.04690766700109659\n","==> training...\n","Train: [33][10/23]\tBT 0.074 (0.111)\tDT 0.000 (0.024)\tpurity 0.775 (0.785)\tloss 0.113 (0.138)\t\n","Train: [33][20/23]\tBT 0.080 (0.096)\tDT 0.000 (0.013)\tpurity 0.625 (0.758)\tloss 0.125 (0.150)\t\n","start clustering ... num clusters: 4\n","epoch 33, total time 2.20\n","LR: 0.04671578786095479\n","==> training...\n","Train: [34][10/23]\tBT 0.094 (0.107)\tDT 0.000 (0.025)\tpurity 0.975 (0.780)\tloss 0.134 (0.131)\t\n","Train: [34][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.016)\tpurity 0.800 (0.761)\tloss 0.123 (0.149)\t\n","start clustering ... num clusters: 4\n","epoch 34, total time 2.19\n","LR: 0.046518550675098594\n","==> training...\n","Train: [35][10/23]\tBT 0.086 (0.118)\tDT 0.000 (0.024)\tpurity 0.900 (0.767)\tloss 0.139 (0.147)\t\n","Train: [35][20/23]\tBT 0.069 (0.109)\tDT 0.000 (0.013)\tpurity 0.825 (0.771)\tloss 0.140 (0.152)\t\n","start clustering ... num clusters: 4\n","epoch 35, total time 2.47\n","LR: 0.04631600410885231\n","==> training...\n","Train: [36][10/23]\tBT 0.081 (0.113)\tDT 0.000 (0.035)\tpurity 0.750 (0.758)\tloss 0.134 (0.158)\t\n","Train: [36][20/23]\tBT 0.083 (0.099)\tDT 0.000 (0.020)\tpurity 0.725 (0.741)\tloss 0.161 (0.158)\t\n","start clustering ... num clusters: 4\n","epoch 36, total time 2.28\n","LR: 0.04610819813755038\n","==> training...\n","Train: [37][10/23]\tBT 0.073 (0.107)\tDT 0.000 (0.024)\tpurity 0.850 (0.765)\tloss 0.163 (0.149)\t\n","Train: [37][20/23]\tBT 0.072 (0.096)\tDT 0.000 (0.014)\tpurity 0.800 (0.771)\tloss 0.181 (0.156)\t\n","start clustering ... num clusters: 4\n","epoch 37, total time 2.18\n","LR: 0.04589518403420676\n","==> training...\n","Train: [38][10/23]\tBT 0.096 (0.111)\tDT 0.000 (0.023)\tpurity 0.700 (0.738)\tloss 0.151 (0.165)\t\n","Train: [38][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.012)\tpurity 0.600 (0.735)\tloss 0.163 (0.159)\t\n","start clustering ... num clusters: 4\n","epoch 38, total time 2.22\n","LR: 0.04567701435686405\n","==> training...\n","Train: [39][10/23]\tBT 0.091 (0.106)\tDT 0.002 (0.026)\tpurity 0.650 (0.822)\tloss 0.141 (0.136)\t\n","Train: [39][20/23]\tBT 0.092 (0.094)\tDT 0.000 (0.014)\tpurity 0.650 (0.783)\tloss 0.132 (0.143)\t\n","start clustering ... num clusters: 4\n","epoch 39, total time 2.16\n","LR: 0.04545374293562559\n","==> training...\n","Train: [40][10/23]\tBT 0.079 (0.109)\tDT 0.002 (0.024)\tpurity 0.875 (0.738)\tloss 0.121 (0.157)\t\n","Train: [40][20/23]\tBT 0.068 (0.097)\tDT 0.000 (0.013)\tpurity 0.775 (0.773)\tloss 0.113 (0.152)\t\n","start clustering ... num clusters: 4\n","epoch 40, total time 2.23\n","==> Saving...\n","LR: 0.04522542485937369\n","==> training...\n","Train: [41][10/23]\tBT 0.090 (0.104)\tDT 0.000 (0.022)\tpurity 0.725 (0.700)\tloss 0.173 (0.147)\t\n","Train: [41][20/23]\tBT 0.099 (0.095)\tDT 0.000 (0.015)\tpurity 0.600 (0.736)\tloss 0.204 (0.153)\t\n","start clustering ... num clusters: 4\n","epoch 41, total time 2.20\n","LR: 0.04499211646217727\n","==> training...\n","Train: [42][10/23]\tBT 0.074 (0.105)\tDT 0.000 (0.024)\tpurity 0.850 (0.747)\tloss 0.170 (0.152)\t\n","Train: [42][20/23]\tBT 0.078 (0.095)\tDT 0.001 (0.013)\tpurity 0.850 (0.736)\tloss 0.225 (0.162)\t\n","start clustering ... num clusters: 4\n","epoch 42, total time 2.18\n","LR: 0.04475387530939226\n","==> training...\n","Train: [43][10/23]\tBT 0.076 (0.115)\tDT 0.000 (0.026)\tpurity 0.850 (0.795)\tloss 0.136 (0.135)\t\n","Train: [43][20/23]\tBT 0.072 (0.097)\tDT 0.000 (0.013)\tpurity 0.675 (0.749)\tloss 0.179 (0.146)\t\n","start clustering ... num clusters: 4\n","epoch 43, total time 2.23\n","LR: 0.044510760183458245\n","==> training...\n","Train: [44][10/23]\tBT 0.113 (0.111)\tDT 0.001 (0.024)\tpurity 0.700 (0.688)\tloss 0.160 (0.164)\t\n","Train: [44][20/23]\tBT 0.075 (0.095)\tDT 0.000 (0.013)\tpurity 0.725 (0.725)\tloss 0.136 (0.162)\t\n","start clustering ... num clusters: 4\n","epoch 44, total time 2.20\n","LR: 0.044262831069394735\n","==> training...\n","Train: [45][10/23]\tBT 0.074 (0.113)\tDT 0.000 (0.031)\tpurity 0.750 (0.758)\tloss 0.129 (0.156)\t\n","Train: [45][20/23]\tBT 0.068 (0.107)\tDT 0.000 (0.020)\tpurity 0.600 (0.735)\tloss 0.168 (0.151)\t\n","start clustering ... num clusters: 4\n","epoch 45, total time 2.44\n","LR: 0.04401014914000078\n","==> training...\n","Train: [46][10/23]\tBT 0.089 (0.113)\tDT 0.000 (0.033)\tpurity 0.650 (0.762)\tloss 0.149 (0.140)\t\n","Train: [46][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.017)\tpurity 0.750 (0.752)\tloss 0.124 (0.153)\t\n","start clustering ... num clusters: 4\n","epoch 46, total time 2.25\n","LR: 0.043752776740761494\n","==> training...\n","Train: [47][10/23]\tBT 0.086 (0.106)\tDT 0.000 (0.025)\tpurity 0.650 (0.718)\tloss 0.143 (0.161)\t\n","Train: [47][20/23]\tBT 0.079 (0.097)\tDT 0.000 (0.014)\tpurity 0.800 (0.700)\tloss 0.148 (0.167)\t\n","start clustering ... num clusters: 4\n","epoch 47, total time 2.24\n","LR: 0.043490777374465245\n","==> training...\n","Train: [48][10/23]\tBT 0.074 (0.103)\tDT 0.000 (0.022)\tpurity 0.700 (0.775)\tloss 0.167 (0.162)\t\n","Train: [48][20/23]\tBT 0.074 (0.092)\tDT 0.003 (0.013)\tpurity 0.550 (0.729)\tloss 0.203 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 48, total time 2.14\n","LR: 0.04322421568553529\n","==> training...\n","Train: [49][10/23]\tBT 0.084 (0.106)\tDT 0.000 (0.023)\tpurity 0.850 (0.748)\tloss 0.150 (0.152)\t\n","Train: [49][20/23]\tBT 0.077 (0.095)\tDT 0.000 (0.012)\tpurity 0.800 (0.723)\tloss 0.151 (0.168)\t\n","start clustering ... num clusters: 4\n","epoch 49, total time 2.18\n","LR: 0.04295315744407972\n","==> training...\n","Train: [50][10/23]\tBT 0.074 (0.108)\tDT 0.000 (0.022)\tpurity 0.525 (0.750)\tloss 0.225 (0.168)\t\n","Train: [50][20/23]\tBT 0.068 (0.097)\tDT 0.000 (0.013)\tpurity 0.750 (0.747)\tloss 0.144 (0.161)\t\n","start clustering ... num clusters: 4\n","epoch 50, total time 2.23\n","==> Saving...\n","LR: 0.04267766952966369\n","==> training...\n","Train: [51][10/23]\tBT 0.095 (0.110)\tDT 0.006 (0.026)\tpurity 0.725 (0.775)\tloss 0.136 (0.147)\t\n","Train: [51][20/23]\tBT 0.080 (0.095)\tDT 0.000 (0.014)\tpurity 0.725 (0.766)\tloss 0.134 (0.163)\t\n","start clustering ... num clusters: 4\n","epoch 51, total time 2.20\n","LR: 0.04239781991480786\n","==> training...\n","Train: [52][10/23]\tBT 0.085 (0.109)\tDT 0.000 (0.025)\tpurity 0.750 (0.780)\tloss 0.154 (0.159)\t\n","Train: [52][20/23]\tBT 0.088 (0.096)\tDT 0.000 (0.014)\tpurity 0.850 (0.770)\tloss 0.113 (0.166)\t\n","start clustering ... num clusters: 4\n","epoch 52, total time 2.19\n","LR: 0.04211367764821722\n","==> training...\n","Train: [53][10/23]\tBT 0.078 (0.106)\tDT 0.005 (0.023)\tpurity 0.900 (0.777)\tloss 0.150 (0.174)\t\n","Train: [53][20/23]\tBT 0.074 (0.095)\tDT 0.000 (0.016)\tpurity 0.825 (0.774)\tloss 0.130 (0.161)\t\n","start clustering ... num clusters: 4\n","epoch 53, total time 2.20\n","LR: 0.041825312837744336\n","==> training...\n","Train: [54][10/23]\tBT 0.070 (0.106)\tDT 0.000 (0.024)\tpurity 0.775 (0.777)\tloss 0.131 (0.194)\t\n","Train: [54][20/23]\tBT 0.069 (0.097)\tDT 0.000 (0.013)\tpurity 0.875 (0.790)\tloss 0.168 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 54, total time 2.23\n","LR: 0.0415327966330913\n","==> training...\n","Train: [55][10/23]\tBT 0.098 (0.117)\tDT 0.000 (0.024)\tpurity 0.825 (0.760)\tloss 0.128 (0.165)\t\n","Train: [55][20/23]\tBT 0.112 (0.110)\tDT 0.000 (0.019)\tpurity 0.475 (0.765)\tloss 0.154 (0.158)\t\n","start clustering ... num clusters: 4\n","epoch 55, total time 2.50\n","LR: 0.041236201208254594\n","==> training...\n","Train: [56][10/23]\tBT 0.089 (0.108)\tDT 0.000 (0.026)\tpurity 0.675 (0.748)\tloss 0.158 (0.152)\t\n","Train: [56][20/23]\tBT 0.083 (0.096)\tDT 0.000 (0.018)\tpurity 0.800 (0.760)\tloss 0.136 (0.156)\t\n","start clustering ... num clusters: 4\n","epoch 56, total time 2.21\n","LR: 0.040935599743717244\n","==> training...\n","Train: [57][10/23]\tBT 0.076 (0.104)\tDT 0.000 (0.025)\tpurity 0.750 (0.733)\tloss 0.206 (0.164)\t\n","Train: [57][20/23]\tBT 0.091 (0.095)\tDT 0.000 (0.015)\tpurity 0.850 (0.737)\tloss 0.142 (0.163)\t\n","start clustering ... num clusters: 4\n","epoch 57, total time 2.18\n","LR: 0.04063106640839264\n","==> training...\n","Train: [58][10/23]\tBT 0.086 (0.109)\tDT 0.000 (0.024)\tpurity 0.750 (0.790)\tloss 0.154 (0.166)\t\n","Train: [58][20/23]\tBT 0.071 (0.096)\tDT 0.000 (0.013)\tpurity 0.600 (0.760)\tloss 0.244 (0.176)\t\n","start clustering ... num clusters: 4\n","epoch 58, total time 2.21\n","LR: 0.040322676341324415\n","==> training...\n","Train: [59][10/23]\tBT 0.087 (0.110)\tDT 0.002 (0.024)\tpurity 0.825 (0.745)\tloss 0.148 (0.181)\t\n","Train: [59][20/23]\tBT 0.076 (0.096)\tDT 0.000 (0.013)\tpurity 0.800 (0.763)\tloss 0.112 (0.170)\t\n","start clustering ... num clusters: 4\n","epoch 59, total time 2.22\n","LR: 0.040010505633147106\n","==> training...\n","Train: [60][10/23]\tBT 0.085 (0.108)\tDT 0.001 (0.023)\tpurity 0.775 (0.745)\tloss 0.135 (0.177)\t\n","Train: [60][20/23]\tBT 0.071 (0.097)\tDT 0.000 (0.012)\tpurity 0.775 (0.756)\tloss 0.207 (0.178)\t\n","start clustering ... num clusters: 4\n","epoch 60, total time 2.23\n","==> Saving...\n","LR: 0.03969463130731184\n","==> training...\n","Train: [61][10/23]\tBT 0.087 (0.110)\tDT 0.000 (0.025)\tpurity 0.875 (0.805)\tloss 0.179 (0.172)\t\n","Train: [61][20/23]\tBT 0.079 (0.096)\tDT 0.000 (0.013)\tpurity 0.925 (0.786)\tloss 0.150 (0.176)\t\n","start clustering ... num clusters: 4\n","epoch 61, total time 2.20\n","LR: 0.03937513130108197\n","==> training...\n","Train: [62][10/23]\tBT 0.093 (0.109)\tDT 0.000 (0.026)\tpurity 0.825 (0.817)\tloss 0.139 (0.181)\t\n","Train: [62][20/23]\tBT 0.078 (0.098)\tDT 0.000 (0.014)\tpurity 0.700 (0.811)\tloss 0.135 (0.169)\t\n","start clustering ... num clusters: 4\n","epoch 62, total time 2.27\n","LR: 0.03905208444630327\n","==> training...\n","Train: [63][10/23]\tBT 0.078 (0.108)\tDT 0.000 (0.022)\tpurity 0.825 (0.810)\tloss 0.146 (0.168)\t\n","Train: [63][20/23]\tBT 0.078 (0.097)\tDT 0.000 (0.012)\tpurity 0.725 (0.796)\tloss 0.195 (0.174)\t\n","start clustering ... num clusters: 4\n","epoch 63, total time 2.21\n","LR: 0.0387255704499533\n","==> training...\n","Train: [64][10/23]\tBT 0.102 (0.111)\tDT 0.005 (0.023)\tpurity 0.700 (0.727)\tloss 0.162 (0.170)\t\n","Train: [64][20/23]\tBT 0.084 (0.099)\tDT 0.000 (0.015)\tpurity 0.725 (0.772)\tloss 0.245 (0.174)\t\n","start clustering ... num clusters: 4\n","epoch 64, total time 2.26\n","LR: 0.038395669874474916\n","==> training...\n","Train: [65][10/23]\tBT 0.138 (0.121)\tDT 0.000 (0.027)\tpurity 0.675 (0.775)\tloss 0.266 (0.199)\t\n","Train: [65][20/23]\tBT 0.100 (0.112)\tDT 0.001 (0.014)\tpurity 0.800 (0.765)\tloss 0.164 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 65, total time 2.54\n","LR: 0.03806246411789872\n","==> training...\n","Train: [66][10/23]\tBT 0.090 (0.116)\tDT 0.000 (0.028)\tpurity 0.850 (0.768)\tloss 0.232 (0.164)\t\n","Train: [66][20/23]\tBT 0.074 (0.099)\tDT 0.000 (0.014)\tpurity 0.800 (0.769)\tloss 0.176 (0.161)\t\n","start clustering ... num clusters: 4\n","epoch 66, total time 2.27\n","LR: 0.03772603539375929\n","==> training...\n","Train: [67][10/23]\tBT 0.087 (0.107)\tDT 0.000 (0.024)\tpurity 0.825 (0.773)\tloss 0.223 (0.182)\t\n","Train: [67][20/23]\tBT 0.078 (0.095)\tDT 0.000 (0.015)\tpurity 0.675 (0.760)\tloss 0.257 (0.177)\t\n","start clustering ... num clusters: 4\n","epoch 67, total time 2.20\n","LR: 0.03738646671081019\n","==> training...\n","Train: [68][10/23]\tBT 0.077 (0.104)\tDT 0.000 (0.025)\tpurity 0.750 (0.770)\tloss 0.211 (0.189)\t\n","Train: [68][20/23]\tBT 0.084 (0.096)\tDT 0.000 (0.017)\tpurity 0.900 (0.774)\tloss 0.139 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 68, total time 2.23\n","LR: 0.037043841852542884\n","==> training...\n","Train: [69][10/23]\tBT 0.094 (0.108)\tDT 0.000 (0.027)\tpurity 0.825 (0.793)\tloss 0.167 (0.173)\t\n","Train: [69][20/23]\tBT 0.092 (0.096)\tDT 0.000 (0.014)\tpurity 0.925 (0.804)\tloss 0.104 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 69, total time 2.19\n","LR: 0.036698245356514336\n","==> training...\n","Train: [70][10/23]\tBT 0.085 (0.105)\tDT 0.000 (0.024)\tpurity 0.500 (0.798)\tloss 0.150 (0.192)\t\n","Train: [70][20/23]\tBT 0.077 (0.094)\tDT 0.000 (0.013)\tpurity 0.750 (0.794)\tloss 0.154 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 70, total time 2.18\n","==> Saving...\n","LR: 0.03634976249348867\n","==> training...\n","Train: [71][10/23]\tBT 0.086 (0.105)\tDT 0.000 (0.028)\tpurity 0.800 (0.800)\tloss 0.126 (0.177)\t\n","Train: [71][20/23]\tBT 0.086 (0.096)\tDT 0.000 (0.016)\tpurity 0.750 (0.801)\tloss 0.121 (0.178)\t\n","start clustering ... num clusters: 4\n","epoch 71, total time 2.19\n","LR: 0.035998479246397874\n","==> training...\n","Train: [72][10/23]\tBT 0.071 (0.107)\tDT 0.000 (0.023)\tpurity 0.900 (0.770)\tloss 0.204 (0.167)\t\n","Train: [72][20/23]\tBT 0.084 (0.094)\tDT 0.000 (0.012)\tpurity 0.650 (0.804)\tloss 0.167 (0.165)\t\n","start clustering ... num clusters: 4\n","epoch 72, total time 2.16\n","LR: 0.03564448228912682\n","==> training...\n","Train: [73][10/23]\tBT 0.095 (0.113)\tDT 0.000 (0.030)\tpurity 0.750 (0.750)\tloss 0.259 (0.188)\t\n","Train: [73][20/23]\tBT 0.081 (0.099)\tDT 0.000 (0.018)\tpurity 0.675 (0.764)\tloss 0.263 (0.188)\t\n","start clustering ... num clusters: 4\n","epoch 73, total time 2.27\n","LR: 0.035287858965127726\n","==> training...\n","Train: [74][10/23]\tBT 0.070 (0.112)\tDT 0.000 (0.026)\tpurity 0.675 (0.733)\tloss 0.208 (0.194)\t\n","Train: [74][20/23]\tBT 0.078 (0.097)\tDT 0.000 (0.014)\tpurity 0.550 (0.734)\tloss 0.154 (0.187)\t\n","start clustering ... num clusters: 4\n","epoch 74, total time 2.22\n","LR: 0.034928697265869516\n","==> training...\n","Train: [75][10/23]\tBT 0.084 (0.116)\tDT 0.001 (0.031)\tpurity 0.825 (0.810)\tloss 0.195 (0.178)\t\n","Train: [75][20/23]\tBT 0.089 (0.107)\tDT 0.000 (0.021)\tpurity 0.800 (0.803)\tloss 0.140 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 75, total time 2.42\n","LR: 0.03456708580912725\n","==> training...\n","Train: [76][10/23]\tBT 0.099 (0.115)\tDT 0.000 (0.034)\tpurity 0.750 (0.743)\tloss 0.141 (0.195)\t\n","Train: [76][20/23]\tBT 0.093 (0.101)\tDT 0.001 (0.018)\tpurity 0.775 (0.753)\tloss 0.142 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 76, total time 2.30\n","LR: 0.03420311381711696\n","==> training...\n","Train: [77][10/23]\tBT 0.092 (0.109)\tDT 0.000 (0.024)\tpurity 0.825 (0.838)\tloss 0.117 (0.162)\t\n","Train: [77][20/23]\tBT 0.092 (0.098)\tDT 0.000 (0.013)\tpurity 0.450 (0.793)\tloss 0.353 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 77, total time 2.24\n","LR: 0.033836871094481434\n","==> training...\n","Train: [78][10/23]\tBT 0.088 (0.112)\tDT 0.004 (0.024)\tpurity 0.725 (0.757)\tloss 0.178 (0.168)\t\n","Train: [78][20/23]\tBT 0.071 (0.098)\tDT 0.000 (0.014)\tpurity 0.775 (0.765)\tloss 0.159 (0.164)\t\n","start clustering ... num clusters: 4\n","epoch 78, total time 2.24\n","LR: 0.033468448006132294\n","==> training...\n","Train: [79][10/23]\tBT 0.075 (0.107)\tDT 0.000 (0.024)\tpurity 0.850 (0.760)\tloss 0.165 (0.152)\t\n","Train: [79][20/23]\tBT 0.079 (0.096)\tDT 0.000 (0.015)\tpurity 0.825 (0.766)\tloss 0.154 (0.161)\t\n","start clustering ... num clusters: 4\n","epoch 79, total time 2.20\n","LR: 0.033097935454953736\n","==> training...\n","Train: [80][10/23]\tBT 0.091 (0.109)\tDT 0.000 (0.025)\tpurity 0.650 (0.758)\tloss 0.177 (0.170)\t\n","Train: [80][20/23]\tBT 0.081 (0.095)\tDT 0.000 (0.013)\tpurity 0.675 (0.760)\tloss 0.189 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 80, total time 2.20\n","==> Saving...\n","LR: 0.032725424859373686\n","==> training...\n","Train: [81][10/23]\tBT 0.086 (0.106)\tDT 0.002 (0.023)\tpurity 0.725 (0.808)\tloss 0.118 (0.148)\t\n","Train: [81][20/23]\tBT 0.071 (0.094)\tDT 0.000 (0.013)\tpurity 0.800 (0.805)\tloss 0.164 (0.168)\t\n","start clustering ... num clusters: 4\n","epoch 81, total time 2.18\n","LR: 0.0323510081308076\n","==> training...\n","Train: [82][10/23]\tBT 0.090 (0.109)\tDT 0.000 (0.027)\tpurity 0.800 (0.785)\tloss 0.136 (0.166)\t\n","Train: [82][20/23]\tBT 0.100 (0.096)\tDT 0.000 (0.016)\tpurity 0.800 (0.752)\tloss 0.214 (0.168)\t\n","start clustering ... num clusters: 4\n","epoch 82, total time 2.23\n","LR: 0.03197477765098074\n","==> training...\n","Train: [83][10/23]\tBT 0.087 (0.112)\tDT 0.000 (0.025)\tpurity 0.800 (0.793)\tloss 0.170 (0.193)\t\n","Train: [83][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.013)\tpurity 0.775 (0.780)\tloss 0.131 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 83, total time 2.24\n","LR: 0.03159682624913432\n","==> training...\n","Train: [84][10/23]\tBT 0.083 (0.108)\tDT 0.000 (0.025)\tpurity 0.900 (0.823)\tloss 0.117 (0.163)\t\n","Train: [84][20/23]\tBT 0.083 (0.097)\tDT 0.000 (0.017)\tpurity 0.750 (0.818)\tloss 0.147 (0.161)\t\n","start clustering ... num clusters: 4\n","epoch 84, total time 2.22\n","LR: 0.031217247179121367\n","==> training...\n","Train: [85][10/23]\tBT 0.069 (0.112)\tDT 0.000 (0.026)\tpurity 0.925 (0.805)\tloss 0.203 (0.182)\t\n","Train: [85][20/23]\tBT 0.075 (0.111)\tDT 0.001 (0.020)\tpurity 0.800 (0.759)\tloss 0.160 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 85, total time 2.53\n","LR: 0.03083613409639764\n","==> training...\n","Train: [86][10/23]\tBT 0.093 (0.111)\tDT 0.000 (0.024)\tpurity 0.750 (0.743)\tloss 0.151 (0.149)\t\n","Train: [86][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.013)\tpurity 0.875 (0.765)\tloss 0.242 (0.172)\t\n","start clustering ... num clusters: 4\n","epoch 86, total time 2.22\n","LR: 0.03045358103491357\n","==> training...\n","Train: [87][10/23]\tBT 0.089 (0.108)\tDT 0.001 (0.022)\tpurity 0.925 (0.852)\tloss 0.172 (0.160)\t\n","Train: [87][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.012)\tpurity 0.825 (0.821)\tloss 0.286 (0.172)\t\n","start clustering ... num clusters: 4\n","epoch 87, total time 2.23\n","LR: 0.03006968238391282\n","==> training...\n","Train: [88][10/23]\tBT 0.077 (0.104)\tDT 0.000 (0.024)\tpurity 0.725 (0.775)\tloss 0.183 (0.185)\t\n","Train: [88][20/23]\tBT 0.110 (0.097)\tDT 0.032 (0.016)\tpurity 0.900 (0.796)\tloss 0.116 (0.165)\t\n","start clustering ... num clusters: 4\n","epoch 88, total time 2.22\n","LR: 0.02968453286464312\n","==> training...\n","Train: [89][10/23]\tBT 0.103 (0.105)\tDT 0.000 (0.023)\tpurity 0.775 (0.805)\tloss 0.268 (0.176)\t\n","Train: [89][20/23]\tBT 0.084 (0.095)\tDT 0.000 (0.013)\tpurity 0.725 (0.773)\tloss 0.194 (0.185)\t\n","start clustering ... num clusters: 4\n","epoch 89, total time 2.19\n","LR: 0.029298227506985238\n","==> training...\n","Train: [90][10/23]\tBT 0.121 (0.112)\tDT 0.000 (0.024)\tpurity 0.925 (0.810)\tloss 0.124 (0.172)\t\n","Train: [90][20/23]\tBT 0.080 (0.098)\tDT 0.000 (0.013)\tpurity 0.800 (0.814)\tloss 0.179 (0.169)\t\n","start clustering ... num clusters: 4\n","epoch 90, total time 2.26\n","==> Saving...\n","LR: 0.028910861626005774\n","==> training...\n","Train: [91][10/23]\tBT 0.085 (0.109)\tDT 0.000 (0.024)\tpurity 0.700 (0.768)\tloss 0.251 (0.182)\t\n","Train: [91][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.013)\tpurity 0.825 (0.780)\tloss 0.129 (0.174)\t\n","start clustering ... num clusters: 4\n","epoch 91, total time 2.22\n","LR: 0.028522530798439572\n","==> training...\n","Train: [92][10/23]\tBT 0.094 (0.109)\tDT 0.000 (0.025)\tpurity 0.725 (0.768)\tloss 0.198 (0.171)\t\n","Train: [92][20/23]\tBT 0.091 (0.097)\tDT 0.000 (0.013)\tpurity 0.875 (0.794)\tloss 0.165 (0.164)\t\n","start clustering ... num clusters: 4\n","epoch 92, total time 2.23\n","LR: 0.028133330839107615\n","==> training...\n","Train: [93][10/23]\tBT 0.112 (0.113)\tDT 0.002 (0.030)\tpurity 0.775 (0.783)\tloss 0.212 (0.179)\t\n","Train: [93][20/23]\tBT 0.068 (0.103)\tDT 0.000 (0.016)\tpurity 0.700 (0.778)\tloss 0.121 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 93, total time 2.35\n","LR: 0.027743357777276136\n","==> training...\n","Train: [94][10/23]\tBT 0.109 (0.108)\tDT 0.003 (0.023)\tpurity 0.850 (0.785)\tloss 0.220 (0.195)\t\n","Train: [94][20/23]\tBT 0.096 (0.095)\tDT 0.000 (0.012)\tpurity 0.650 (0.799)\tloss 0.248 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 94, total time 2.16\n","LR: 0.02735270783296286\n","==> training...\n","Train: [95][10/23]\tBT 0.091 (0.115)\tDT 0.001 (0.022)\tpurity 0.875 (0.762)\tloss 0.194 (0.184)\t\n","Train: [95][20/23]\tBT 0.080 (0.109)\tDT 0.000 (0.018)\tpurity 0.825 (0.776)\tloss 0.184 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 95, total time 2.48\n","LR: 0.026961477393196126\n","==> training...\n","Train: [96][10/23]\tBT 0.084 (0.114)\tDT 0.000 (0.031)\tpurity 0.625 (0.770)\tloss 0.245 (0.178)\t\n","Train: [96][20/23]\tBT 0.073 (0.100)\tDT 0.000 (0.017)\tpurity 0.875 (0.783)\tloss 0.222 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 96, total time 2.27\n","LR: 0.02656976298823284\n","==> training...\n","Train: [97][10/23]\tBT 0.109 (0.110)\tDT 0.000 (0.025)\tpurity 0.775 (0.763)\tloss 0.149 (0.182)\t\n","Train: [97][20/23]\tBT 0.088 (0.095)\tDT 0.003 (0.013)\tpurity 0.875 (0.764)\tloss 0.144 (0.171)\t\n","start clustering ... num clusters: 4\n","epoch 97, total time 2.19\n","LR: 0.026177661267741067\n","==> training...\n","Train: [98][10/23]\tBT 0.099 (0.109)\tDT 0.000 (0.022)\tpurity 0.600 (0.760)\tloss 0.272 (0.176)\t\n","Train: [98][20/23]\tBT 0.074 (0.096)\tDT 0.000 (0.012)\tpurity 0.825 (0.782)\tloss 0.270 (0.188)\t\n","start clustering ... num clusters: 4\n","epoch 98, total time 2.21\n","LR: 0.02578526897695321\n","==> training...\n","Train: [99][10/23]\tBT 0.086 (0.112)\tDT 0.001 (0.023)\tpurity 0.850 (0.822)\tloss 0.196 (0.189)\t\n","Train: [99][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.013)\tpurity 0.675 (0.786)\tloss 0.220 (0.196)\t\n","start clustering ... num clusters: 4\n","epoch 99, total time 2.24\n","LR: 0.02539268293279552\n","==> training...\n","Train: [100][10/23]\tBT 0.087 (0.109)\tDT 0.000 (0.027)\tpurity 0.675 (0.798)\tloss 0.114 (0.178)\t\n","Train: [100][20/23]\tBT 0.086 (0.097)\tDT 0.000 (0.015)\tpurity 0.825 (0.808)\tloss 0.147 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 100, total time 2.22\n","==> Saving...\n","LR: 0.025\n","==> training...\n","Train: [101][10/23]\tBT 0.077 (0.109)\tDT 0.000 (0.023)\tpurity 0.700 (0.815)\tloss 0.273 (0.182)\t\n","Train: [101][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.017)\tpurity 0.725 (0.789)\tloss 0.259 (0.183)\t\n","start clustering ... num clusters: 4\n","epoch 101, total time 2.21\n","LR: 0.02460731706720449\n","==> training...\n","Train: [102][10/23]\tBT 0.075 (0.115)\tDT 0.000 (0.022)\tpurity 0.950 (0.805)\tloss 0.242 (0.176)\t\n","Train: [102][20/23]\tBT 0.102 (0.099)\tDT 0.000 (0.012)\tpurity 0.575 (0.796)\tloss 0.216 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 102, total time 2.26\n","LR: 0.024214731023046793\n","==> training...\n","Train: [103][10/23]\tBT 0.090 (0.110)\tDT 0.001 (0.029)\tpurity 0.850 (0.770)\tloss 0.190 (0.182)\t\n","Train: [103][20/23]\tBT 0.086 (0.098)\tDT 0.000 (0.016)\tpurity 0.950 (0.786)\tloss 0.117 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 103, total time 2.24\n","LR: 0.023822338732258936\n","==> training...\n","Train: [104][10/23]\tBT 0.106 (0.109)\tDT 0.002 (0.028)\tpurity 0.850 (0.785)\tloss 0.183 (0.183)\t\n","Train: [104][20/23]\tBT 0.068 (0.099)\tDT 0.000 (0.016)\tpurity 0.850 (0.794)\tloss 0.223 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 104, total time 2.27\n","LR: 0.023430237011767167\n","==> training...\n","Train: [105][10/23]\tBT 0.092 (0.118)\tDT 0.000 (0.033)\tpurity 0.900 (0.780)\tloss 0.172 (0.179)\t\n","Train: [105][20/23]\tBT 0.077 (0.112)\tDT 0.000 (0.020)\tpurity 0.875 (0.787)\tloss 0.114 (0.178)\t\n","start clustering ... num clusters: 4\n","epoch 105, total time 2.53\n","LR: 0.02303852260680388\n","==> training...\n","Train: [106][10/23]\tBT 0.079 (0.111)\tDT 0.000 (0.028)\tpurity 0.650 (0.785)\tloss 0.209 (0.188)\t\n","Train: [106][20/23]\tBT 0.083 (0.097)\tDT 0.000 (0.015)\tpurity 0.850 (0.800)\tloss 0.152 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 106, total time 2.24\n","LR: 0.022647292167037144\n","==> training...\n","Train: [107][10/23]\tBT 0.082 (0.107)\tDT 0.000 (0.024)\tpurity 0.900 (0.815)\tloss 0.147 (0.169)\t\n","Train: [107][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.013)\tpurity 0.700 (0.775)\tloss 0.173 (0.176)\t\n","start clustering ... num clusters: 4\n","epoch 107, total time 2.24\n","LR: 0.02225664222272387\n","==> training...\n","Train: [108][10/23]\tBT 0.081 (0.104)\tDT 0.000 (0.023)\tpurity 0.675 (0.770)\tloss 0.225 (0.176)\t\n","Train: [108][20/23]\tBT 0.081 (0.097)\tDT 0.000 (0.013)\tpurity 0.775 (0.779)\tloss 0.216 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 108, total time 2.23\n","LR: 0.0218666691608924\n","==> training...\n","Train: [109][10/23]\tBT 0.096 (0.107)\tDT 0.002 (0.023)\tpurity 0.775 (0.803)\tloss 0.196 (0.195)\t\n","Train: [109][20/23]\tBT 0.071 (0.094)\tDT 0.000 (0.012)\tpurity 0.775 (0.811)\tloss 0.166 (0.185)\t\n","start clustering ... num clusters: 4\n","epoch 109, total time 2.18\n","LR: 0.02147746920156044\n","==> training...\n","Train: [110][10/23]\tBT 0.104 (0.107)\tDT 0.000 (0.022)\tpurity 0.800 (0.838)\tloss 0.129 (0.176)\t\n","Train: [110][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.012)\tpurity 0.825 (0.829)\tloss 0.139 (0.177)\t\n","start clustering ... num clusters: 4\n","epoch 110, total time 2.19\n","==> Saving...\n","LR: 0.021089138373994232\n","==> training...\n","Train: [111][10/23]\tBT 0.091 (0.113)\tDT 0.000 (0.024)\tpurity 0.850 (0.800)\tloss 0.126 (0.190)\t\n","Train: [111][20/23]\tBT 0.072 (0.095)\tDT 0.000 (0.013)\tpurity 0.775 (0.789)\tloss 0.212 (0.193)\t\n","start clustering ... num clusters: 4\n","epoch 111, total time 2.22\n","LR: 0.02070177249301476\n","==> training...\n","Train: [112][10/23]\tBT 0.072 (0.103)\tDT 0.000 (0.028)\tpurity 0.800 (0.813)\tloss 0.187 (0.197)\t\n","Train: [112][20/23]\tBT 0.094 (0.096)\tDT 0.000 (0.015)\tpurity 1.000 (0.778)\tloss 0.157 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 112, total time 2.20\n","LR: 0.020315467135356886\n","==> training...\n","Train: [113][10/23]\tBT 0.099 (0.109)\tDT 0.001 (0.023)\tpurity 0.825 (0.745)\tloss 0.173 (0.191)\t\n","Train: [113][20/23]\tBT 0.068 (0.100)\tDT 0.000 (0.013)\tpurity 0.850 (0.728)\tloss 0.158 (0.190)\t\n","start clustering ... num clusters: 4\n","epoch 113, total time 2.30\n","LR: 0.01993031761608719\n","==> training...\n","Train: [114][10/23]\tBT 0.096 (0.108)\tDT 0.000 (0.027)\tpurity 0.925 (0.790)\tloss 0.137 (0.174)\t\n","Train: [114][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.014)\tpurity 0.900 (0.820)\tloss 0.149 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 114, total time 2.21\n","LR: 0.019546418965086444\n","==> training...\n","Train: [115][10/23]\tBT 0.078 (0.119)\tDT 0.000 (0.024)\tpurity 0.750 (0.720)\tloss 0.121 (0.187)\t\n","Train: [115][20/23]\tBT 0.094 (0.110)\tDT 0.000 (0.013)\tpurity 0.775 (0.771)\tloss 0.167 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 115, total time 2.50\n","LR: 0.019163865903602362\n","==> training...\n","Train: [116][10/23]\tBT 0.094 (0.114)\tDT 0.000 (0.027)\tpurity 0.800 (0.785)\tloss 0.280 (0.221)\t\n","Train: [116][20/23]\tBT 0.071 (0.099)\tDT 0.000 (0.015)\tpurity 0.850 (0.813)\tloss 0.166 (0.211)\t\n","start clustering ... num clusters: 4\n","epoch 116, total time 2.26\n","LR: 0.01878275282087863\n","==> training...\n","Train: [117][10/23]\tBT 0.073 (0.112)\tDT 0.000 (0.025)\tpurity 0.625 (0.795)\tloss 0.174 (0.179)\t\n","Train: [117][20/23]\tBT 0.071 (0.099)\tDT 0.000 (0.014)\tpurity 0.825 (0.810)\tloss 0.146 (0.174)\t\n","start clustering ... num clusters: 4\n","epoch 117, total time 2.27\n","LR: 0.01840317375086568\n","==> training...\n","Train: [118][10/23]\tBT 0.087 (0.109)\tDT 0.000 (0.024)\tpurity 0.650 (0.733)\tloss 0.176 (0.206)\t\n","Train: [118][20/23]\tBT 0.075 (0.095)\tDT 0.000 (0.013)\tpurity 0.850 (0.760)\tloss 0.182 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 118, total time 2.19\n","LR: 0.018025222349019272\n","==> training...\n","Train: [119][10/23]\tBT 0.089 (0.109)\tDT 0.000 (0.023)\tpurity 0.825 (0.777)\tloss 0.206 (0.174)\t\n","Train: [119][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.013)\tpurity 0.600 (0.812)\tloss 0.282 (0.185)\t\n","start clustering ... num clusters: 4\n","epoch 119, total time 2.24\n","LR: 0.017648991869192405\n","==> training...\n","Train: [120][10/23]\tBT 0.113 (0.113)\tDT 0.000 (0.023)\tpurity 0.675 (0.793)\tloss 0.176 (0.188)\t\n","Train: [120][20/23]\tBT 0.069 (0.099)\tDT 0.000 (0.012)\tpurity 0.775 (0.789)\tloss 0.159 (0.182)\t\n","start clustering ... num clusters: 4\n","epoch 120, total time 2.28\n","==> Saving...\n","LR: 0.017274575140626323\n","==> training...\n","Train: [121][10/23]\tBT 0.080 (0.112)\tDT 0.001 (0.024)\tpurity 0.850 (0.797)\tloss 0.206 (0.200)\t\n","Train: [121][20/23]\tBT 0.076 (0.097)\tDT 0.000 (0.013)\tpurity 0.650 (0.789)\tloss 0.240 (0.190)\t\n","start clustering ... num clusters: 4\n","epoch 121, total time 2.23\n","LR: 0.016902064545046263\n","==> training...\n","Train: [122][10/23]\tBT 0.103 (0.109)\tDT 0.003 (0.028)\tpurity 0.625 (0.742)\tloss 0.169 (0.197)\t\n","Train: [122][20/23]\tBT 0.070 (0.098)\tDT 0.000 (0.018)\tpurity 0.850 (0.794)\tloss 0.195 (0.199)\t\n","start clustering ... num clusters: 4\n","epoch 122, total time 2.26\n","LR: 0.016531551993867716\n","==> training...\n","Train: [123][10/23]\tBT 0.092 (0.105)\tDT 0.001 (0.027)\tpurity 0.900 (0.835)\tloss 0.127 (0.175)\t\n","Train: [123][20/23]\tBT 0.071 (0.095)\tDT 0.000 (0.014)\tpurity 0.675 (0.795)\tloss 0.223 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 123, total time 2.20\n","LR: 0.016163128905518576\n","==> training...\n","Train: [124][10/23]\tBT 0.086 (0.110)\tDT 0.000 (0.025)\tpurity 0.925 (0.852)\tloss 0.137 (0.176)\t\n","Train: [124][20/23]\tBT 0.089 (0.098)\tDT 0.002 (0.013)\tpurity 0.750 (0.826)\tloss 0.197 (0.199)\t\n","start clustering ... num clusters: 4\n","epoch 124, total time 2.25\n","LR: 0.01579688618288306\n","==> training...\n","Train: [125][10/23]\tBT 0.095 (0.114)\tDT 0.000 (0.025)\tpurity 0.875 (0.770)\tloss 0.149 (0.189)\t\n","Train: [125][20/23]\tBT 0.075 (0.108)\tDT 0.000 (0.016)\tpurity 0.725 (0.799)\tloss 0.200 (0.186)\t\n","start clustering ... num clusters: 4\n","epoch 125, total time 2.48\n","LR: 0.015432914190872763\n","==> training...\n","Train: [126][10/23]\tBT 0.084 (0.115)\tDT 0.000 (0.031)\tpurity 0.800 (0.750)\tloss 0.155 (0.194)\t\n","Train: [126][20/23]\tBT 0.079 (0.100)\tDT 0.001 (0.017)\tpurity 0.775 (0.796)\tloss 0.190 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 126, total time 2.29\n","LR: 0.015071302734130482\n","==> training...\n","Train: [127][10/23]\tBT 0.078 (0.108)\tDT 0.000 (0.027)\tpurity 0.775 (0.792)\tloss 0.157 (0.189)\t\n","Train: [127][20/23]\tBT 0.069 (0.095)\tDT 0.000 (0.014)\tpurity 0.775 (0.811)\tloss 0.213 (0.185)\t\n","start clustering ... num clusters: 4\n","epoch 127, total time 2.20\n","LR: 0.014712141034872282\n","==> training...\n","Train: [128][10/23]\tBT 0.084 (0.107)\tDT 0.000 (0.024)\tpurity 0.975 (0.853)\tloss 0.151 (0.181)\t\n","Train: [128][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.013)\tpurity 0.775 (0.815)\tloss 0.160 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 128, total time 2.21\n","LR: 0.014355517710873185\n","==> training...\n","Train: [129][10/23]\tBT 0.088 (0.110)\tDT 0.000 (0.024)\tpurity 1.000 (0.802)\tloss 0.151 (0.168)\t\n","Train: [129][20/23]\tBT 0.069 (0.097)\tDT 0.000 (0.013)\tpurity 0.825 (0.812)\tloss 0.124 (0.177)\t\n","start clustering ... num clusters: 4\n","epoch 129, total time 2.21\n","LR: 0.014001520753602122\n","==> training...\n","Train: [130][10/23]\tBT 0.081 (0.105)\tDT 0.000 (0.024)\tpurity 0.675 (0.780)\tloss 0.256 (0.173)\t\n","Train: [130][20/23]\tBT 0.069 (0.094)\tDT 0.000 (0.014)\tpurity 0.800 (0.803)\tloss 0.139 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 130, total time 2.17\n","==> Saving...\n","LR: 0.013650237506511332\n","==> training...\n","Train: [131][10/23]\tBT 0.091 (0.109)\tDT 0.011 (0.025)\tpurity 0.775 (0.817)\tloss 0.342 (0.195)\t\n","Train: [131][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.014)\tpurity 0.825 (0.815)\tloss 0.266 (0.188)\t\n","start clustering ... num clusters: 4\n","epoch 131, total time 2.25\n","LR: 0.01330175464348567\n","==> training...\n","Train: [132][10/23]\tBT 0.073 (0.108)\tDT 0.000 (0.025)\tpurity 0.900 (0.820)\tloss 0.122 (0.164)\t\n","Train: [132][20/23]\tBT 0.078 (0.095)\tDT 0.000 (0.014)\tpurity 0.750 (0.825)\tloss 0.204 (0.167)\t\n","start clustering ... num clusters: 4\n","epoch 132, total time 2.19\n","LR: 0.012956158147457115\n","==> training...\n","Train: [133][10/23]\tBT 0.100 (0.111)\tDT 0.003 (0.025)\tpurity 0.800 (0.830)\tloss 0.137 (0.199)\t\n","Train: [133][20/23]\tBT 0.076 (0.100)\tDT 0.000 (0.013)\tpurity 0.850 (0.809)\tloss 0.139 (0.187)\t\n","start clustering ... num clusters: 4\n","epoch 133, total time 2.28\n","LR: 0.01261353328918981\n","==> training...\n","Train: [134][10/23]\tBT 0.075 (0.110)\tDT 0.000 (0.025)\tpurity 0.700 (0.838)\tloss 0.173 (0.182)\t\n","Train: [134][20/23]\tBT 0.083 (0.097)\tDT 0.000 (0.013)\tpurity 0.925 (0.826)\tloss 0.177 (0.186)\t\n","start clustering ... num clusters: 4\n","epoch 134, total time 2.23\n","LR: 0.012273964606240717\n","==> training...\n","Train: [135][10/23]\tBT 0.080 (0.110)\tDT 0.001 (0.028)\tpurity 0.825 (0.825)\tloss 0.172 (0.162)\t\n","Train: [135][20/23]\tBT 0.082 (0.107)\tDT 0.000 (0.023)\tpurity 0.925 (0.837)\tloss 0.186 (0.165)\t\n","start clustering ... num clusters: 4\n","epoch 135, total time 2.47\n","LR: 0.01193753588210128\n","==> training...\n","Train: [136][10/23]\tBT 0.073 (0.105)\tDT 0.000 (0.023)\tpurity 0.775 (0.823)\tloss 0.147 (0.160)\t\n","Train: [136][20/23]\tBT 0.079 (0.095)\tDT 0.000 (0.012)\tpurity 0.875 (0.804)\tloss 0.154 (0.170)\t\n","start clustering ... num clusters: 4\n","epoch 136, total time 2.19\n","LR: 0.01160433012552508\n","==> training...\n","Train: [137][10/23]\tBT 0.097 (0.108)\tDT 0.000 (0.023)\tpurity 0.775 (0.790)\tloss 0.134 (0.173)\t\n","Train: [137][20/23]\tBT 0.077 (0.095)\tDT 0.000 (0.012)\tpurity 0.900 (0.799)\tloss 0.202 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 137, total time 2.20\n","LR: 0.011274429550046703\n","==> training...\n","Train: [138][10/23]\tBT 0.070 (0.106)\tDT 0.000 (0.024)\tpurity 0.725 (0.815)\tloss 0.161 (0.200)\t\n","Train: [138][20/23]\tBT 0.090 (0.096)\tDT 0.000 (0.013)\tpurity 0.700 (0.803)\tloss 0.271 (0.197)\t\n","start clustering ... num clusters: 4\n","epoch 138, total time 2.22\n","LR: 0.010947915553696733\n","==> training...\n","Train: [139][10/23]\tBT 0.099 (0.109)\tDT 0.000 (0.027)\tpurity 0.875 (0.800)\tloss 0.136 (0.190)\t\n","Train: [139][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.015)\tpurity 0.925 (0.822)\tloss 0.138 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 139, total time 2.24\n","LR: 0.010624868698918037\n","==> training...\n","Train: [140][10/23]\tBT 0.094 (0.106)\tDT 0.003 (0.023)\tpurity 0.925 (0.845)\tloss 0.150 (0.168)\t\n","Train: [140][20/23]\tBT 0.087 (0.094)\tDT 0.000 (0.013)\tpurity 0.825 (0.829)\tloss 0.129 (0.185)\t\n","start clustering ... num clusters: 4\n","epoch 140, total time 2.18\n","==> Saving...\n","LR: 0.010305368692688175\n","==> training...\n","Train: [141][10/23]\tBT 0.069 (0.107)\tDT 0.000 (0.026)\tpurity 0.900 (0.855)\tloss 0.165 (0.182)\t\n","Train: [141][20/23]\tBT 0.085 (0.094)\tDT 0.000 (0.014)\tpurity 0.850 (0.853)\tloss 0.191 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 141, total time 2.18\n","LR: 0.009989494366852904\n","==> training...\n","Train: [142][10/23]\tBT 0.084 (0.106)\tDT 0.000 (0.022)\tpurity 0.750 (0.775)\tloss 0.144 (0.162)\t\n","Train: [142][20/23]\tBT 0.091 (0.097)\tDT 0.000 (0.012)\tpurity 0.925 (0.797)\tloss 0.181 (0.172)\t\n","start clustering ... num clusters: 4\n","epoch 142, total time 2.22\n","LR: 0.009677323658675586\n","==> training...\n","Train: [143][10/23]\tBT 0.074 (0.105)\tDT 0.000 (0.023)\tpurity 0.800 (0.817)\tloss 0.185 (0.185)\t\n","Train: [143][20/23]\tBT 0.090 (0.096)\tDT 0.000 (0.013)\tpurity 0.850 (0.794)\tloss 0.233 (0.195)\t\n","start clustering ... num clusters: 4\n","epoch 143, total time 2.21\n","LR: 0.00936893359160737\n","==> training...\n","Train: [144][10/23]\tBT 0.079 (0.110)\tDT 0.003 (0.026)\tpurity 0.800 (0.813)\tloss 0.149 (0.181)\t\n","Train: [144][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.014)\tpurity 0.850 (0.816)\tloss 0.282 (0.183)\t\n","start clustering ... num clusters: 4\n","epoch 144, total time 2.30\n","LR: 0.009064400256282757\n","==> training...\n","Train: [145][10/23]\tBT 0.092 (0.109)\tDT 0.000 (0.024)\tpurity 0.725 (0.778)\tloss 0.138 (0.175)\t\n","Train: [145][20/23]\tBT 0.081 (0.109)\tDT 0.000 (0.019)\tpurity 0.825 (0.780)\tloss 0.192 (0.186)\t\n","start clustering ... num clusters: 4\n","epoch 145, total time 2.50\n","LR: 0.008763798791745412\n","==> training...\n","Train: [146][10/23]\tBT 0.074 (0.109)\tDT 0.000 (0.024)\tpurity 0.800 (0.795)\tloss 0.147 (0.216)\t\n","Train: [146][20/23]\tBT 0.082 (0.095)\tDT 0.000 (0.013)\tpurity 0.875 (0.824)\tloss 0.134 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 146, total time 2.19\n","LR: 0.008467203366908708\n","==> training...\n","Train: [147][10/23]\tBT 0.084 (0.106)\tDT 0.000 (0.023)\tpurity 0.850 (0.877)\tloss 0.153 (0.190)\t\n","Train: [147][20/23]\tBT 0.075 (0.094)\tDT 0.000 (0.013)\tpurity 0.850 (0.855)\tloss 0.160 (0.196)\t\n","start clustering ... num clusters: 4\n","epoch 147, total time 2.17\n","LR: 0.008174687162255665\n","==> training...\n","Train: [148][10/23]\tBT 0.083 (0.107)\tDT 0.000 (0.024)\tpurity 0.725 (0.813)\tloss 0.162 (0.200)\t\n","Train: [148][20/23]\tBT 0.071 (0.096)\tDT 0.000 (0.013)\tpurity 0.725 (0.829)\tloss 0.172 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 148, total time 2.21\n","LR: 0.007886322351782783\n","==> training...\n","Train: [149][10/23]\tBT 0.086 (0.107)\tDT 0.000 (0.023)\tpurity 0.875 (0.817)\tloss 0.119 (0.167)\t\n","Train: [149][20/23]\tBT 0.074 (0.096)\tDT 0.000 (0.012)\tpurity 0.825 (0.811)\tloss 0.191 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 149, total time 2.20\n","LR: 0.0076021800851921425\n","==> training...\n","Train: [150][10/23]\tBT 0.078 (0.112)\tDT 0.002 (0.026)\tpurity 0.650 (0.760)\tloss 0.186 (0.200)\t\n","Train: [150][20/23]\tBT 0.077 (0.098)\tDT 0.000 (0.013)\tpurity 0.775 (0.798)\tloss 0.154 (0.191)\t\n","start clustering ... num clusters: 4\n","epoch 150, total time 2.24\n","==> Saving...\n","LR: 0.0073223304703363135\n","==> training...\n","Train: [151][10/23]\tBT 0.090 (0.107)\tDT 0.000 (0.026)\tpurity 0.775 (0.853)\tloss 0.180 (0.180)\t\n","Train: [151][20/23]\tBT 0.069 (0.095)\tDT 0.000 (0.015)\tpurity 0.950 (0.854)\tloss 0.129 (0.178)\t\n","start clustering ... num clusters: 4\n","epoch 151, total time 2.20\n","LR: 0.007046842555920283\n","==> training...\n","Train: [152][10/23]\tBT 0.087 (0.110)\tDT 0.001 (0.023)\tpurity 0.900 (0.830)\tloss 0.139 (0.163)\t\n","Train: [152][20/23]\tBT 0.081 (0.097)\tDT 0.000 (0.013)\tpurity 0.775 (0.817)\tloss 0.251 (0.177)\t\n","start clustering ... num clusters: 4\n","epoch 152, total time 2.24\n","LR: 0.006775784314464717\n","==> training...\n","Train: [153][10/23]\tBT 0.086 (0.109)\tDT 0.000 (0.026)\tpurity 0.775 (0.843)\tloss 0.173 (0.183)\t\n","Train: [153][20/23]\tBT 0.077 (0.098)\tDT 0.000 (0.014)\tpurity 0.950 (0.846)\tloss 0.165 (0.182)\t\n","start clustering ... num clusters: 4\n","epoch 153, total time 2.26\n","LR: 0.006509222625534755\n","==> training...\n","Train: [154][10/23]\tBT 0.078 (0.110)\tDT 0.001 (0.025)\tpurity 0.850 (0.760)\tloss 0.212 (0.187)\t\n","Train: [154][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.013)\tpurity 0.725 (0.809)\tloss 0.307 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 154, total time 2.23\n","LR: 0.0062472232592385105\n","==> training...\n","Train: [155][10/23]\tBT 0.146 (0.130)\tDT 0.000 (0.037)\tpurity 0.875 (0.807)\tloss 0.208 (0.194)\t\n","Train: [155][20/23]\tBT 0.090 (0.112)\tDT 0.001 (0.019)\tpurity 0.850 (0.799)\tloss 0.178 (0.197)\t\n","start clustering ... num clusters: 4\n","epoch 155, total time 2.51\n","LR: 0.005989850859999227\n","==> training...\n","Train: [156][10/23]\tBT 0.070 (0.107)\tDT 0.000 (0.022)\tpurity 0.750 (0.775)\tloss 0.210 (0.192)\t\n","Train: [156][20/23]\tBT 0.072 (0.097)\tDT 0.000 (0.012)\tpurity 0.975 (0.801)\tloss 0.138 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 156, total time 2.22\n","LR: 0.005737168930605272\n","==> training...\n","Train: [157][10/23]\tBT 0.076 (0.106)\tDT 0.000 (0.025)\tpurity 0.775 (0.845)\tloss 0.211 (0.178)\t\n","Train: [157][20/23]\tBT 0.068 (0.098)\tDT 0.000 (0.016)\tpurity 0.600 (0.812)\tloss 0.280 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 157, total time 2.25\n","LR: 0.005489239816541761\n","==> training...\n","Train: [158][10/23]\tBT 0.082 (0.113)\tDT 0.000 (0.028)\tpurity 0.750 (0.863)\tloss 0.157 (0.163)\t\n","Train: [158][20/23]\tBT 0.079 (0.099)\tDT 0.000 (0.014)\tpurity 0.875 (0.844)\tloss 0.190 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 158, total time 2.26\n","LR: 0.00524612469060774\n","==> training...\n","Train: [159][10/23]\tBT 0.085 (0.108)\tDT 0.000 (0.025)\tpurity 0.850 (0.825)\tloss 0.195 (0.189)\t\n","Train: [159][20/23]\tBT 0.073 (0.096)\tDT 0.000 (0.014)\tpurity 0.875 (0.825)\tloss 0.175 (0.191)\t\n","start clustering ... num clusters: 4\n","epoch 159, total time 2.22\n","LR: 0.005007883537822735\n","==> training...\n","Train: [160][10/23]\tBT 0.101 (0.109)\tDT 0.001 (0.025)\tpurity 0.850 (0.860)\tloss 0.162 (0.182)\t\n","Train: [160][20/23]\tBT 0.071 (0.095)\tDT 0.000 (0.013)\tpurity 0.900 (0.834)\tloss 0.156 (0.186)\t\n","start clustering ... num clusters: 4\n","epoch 160, total time 2.18\n","==> Saving...\n","LR: 0.004774575140626317\n","==> training...\n","Train: [161][10/23]\tBT 0.086 (0.106)\tDT 0.001 (0.026)\tpurity 0.875 (0.868)\tloss 0.170 (0.164)\t\n","Train: [161][20/23]\tBT 0.073 (0.096)\tDT 0.000 (0.014)\tpurity 0.900 (0.832)\tloss 0.221 (0.191)\t\n","start clustering ... num clusters: 4\n","epoch 161, total time 2.22\n","LR: 0.004546257064374418\n","==> training...\n","Train: [162][10/23]\tBT 0.077 (0.108)\tDT 0.000 (0.029)\tpurity 0.875 (0.823)\tloss 0.128 (0.182)\t\n","Train: [162][20/23]\tBT 0.077 (0.096)\tDT 0.000 (0.016)\tpurity 0.850 (0.816)\tloss 0.221 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 162, total time 2.21\n","LR: 0.004322985643135957\n","==> training...\n","Train: [163][10/23]\tBT 0.092 (0.108)\tDT 0.002 (0.023)\tpurity 0.975 (0.778)\tloss 0.157 (0.185)\t\n","Train: [163][20/23]\tBT 0.071 (0.097)\tDT 0.000 (0.012)\tpurity 0.825 (0.804)\tloss 0.152 (0.190)\t\n","start clustering ... num clusters: 4\n","epoch 163, total time 2.22\n","LR: 0.004104815965793249\n","==> training...\n","Train: [164][10/23]\tBT 0.081 (0.107)\tDT 0.000 (0.025)\tpurity 0.825 (0.830)\tloss 0.193 (0.160)\t\n","Train: [164][20/23]\tBT 0.082 (0.093)\tDT 0.011 (0.014)\tpurity 0.775 (0.821)\tloss 0.232 (0.183)\t\n","start clustering ... num clusters: 4\n","epoch 164, total time 2.19\n","LR: 0.003891801862449629\n","==> training...\n","Train: [165][10/23]\tBT 0.087 (0.108)\tDT 0.000 (0.028)\tpurity 0.900 (0.890)\tloss 0.130 (0.175)\t\n","Train: [165][20/23]\tBT 0.073 (0.108)\tDT 0.000 (0.017)\tpurity 0.950 (0.866)\tloss 0.219 (0.181)\t\n","start clustering ... num clusters: 4\n","epoch 165, total time 2.48\n","LR: 0.0036839958911477014\n","==> training...\n","Train: [166][10/23]\tBT 0.089 (0.115)\tDT 0.000 (0.030)\tpurity 0.825 (0.808)\tloss 0.135 (0.197)\t\n","Train: [166][20/23]\tBT 0.088 (0.099)\tDT 0.000 (0.016)\tpurity 0.950 (0.809)\tloss 0.182 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 166, total time 2.28\n","LR: 0.0034814493249014063\n","==> training...\n","Train: [167][10/23]\tBT 0.088 (0.105)\tDT 0.000 (0.026)\tpurity 0.975 (0.795)\tloss 0.220 (0.195)\t\n","Train: [167][20/23]\tBT 0.075 (0.095)\tDT 0.000 (0.015)\tpurity 0.925 (0.831)\tloss 0.134 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 167, total time 2.20\n","LR: 0.0032842121390452175\n","==> training...\n","Train: [168][10/23]\tBT 0.086 (0.106)\tDT 0.002 (0.028)\tpurity 0.850 (0.847)\tloss 0.202 (0.182)\t\n","Train: [168][20/23]\tBT 0.071 (0.096)\tDT 0.000 (0.017)\tpurity 0.825 (0.841)\tloss 0.223 (0.179)\t\n","start clustering ... num clusters: 4\n","epoch 168, total time 2.20\n","LR: 0.0030923329989034107\n","==> training...\n","Train: [169][10/23]\tBT 0.071 (0.106)\tDT 0.000 (0.029)\tpurity 0.750 (0.877)\tloss 0.108 (0.197)\t\n","Train: [169][20/23]\tBT 0.072 (0.097)\tDT 0.000 (0.018)\tpurity 0.925 (0.860)\tloss 0.165 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 169, total time 2.24\n","LR: 0.0029058592477826635\n","==> training...\n","Train: [170][10/23]\tBT 0.078 (0.109)\tDT 0.000 (0.023)\tpurity 0.775 (0.840)\tloss 0.144 (0.173)\t\n","Train: [170][20/23]\tBT 0.073 (0.097)\tDT 0.000 (0.013)\tpurity 0.850 (0.836)\tloss 0.248 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 170, total time 2.23\n","==> Saving...\n","LR: 0.0027248368952908055\n","==> training...\n","Train: [171][10/23]\tBT 0.086 (0.110)\tDT 0.000 (0.024)\tpurity 0.875 (0.857)\tloss 0.142 (0.187)\t\n","Train: [171][20/23]\tBT 0.095 (0.099)\tDT 0.000 (0.016)\tpurity 0.925 (0.860)\tloss 0.148 (0.189)\t\n","start clustering ... num clusters: 4\n","epoch 171, total time 2.27\n","LR: 0.002549310605984612\n","==> training...\n","Train: [172][10/23]\tBT 0.078 (0.112)\tDT 0.002 (0.024)\tpurity 0.900 (0.850)\tloss 0.200 (0.197)\t\n","Train: [172][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.013)\tpurity 0.875 (0.849)\tloss 0.191 (0.195)\t\n","start clustering ... num clusters: 4\n","epoch 172, total time 2.22\n","LR: 0.0023793236883495163\n","==> training...\n","Train: [173][10/23]\tBT 0.101 (0.111)\tDT 0.000 (0.025)\tpurity 0.775 (0.803)\tloss 0.171 (0.208)\t\n","Train: [173][20/23]\tBT 0.068 (0.096)\tDT 0.000 (0.013)\tpurity 0.800 (0.814)\tloss 0.155 (0.187)\t\n","start clustering ... num clusters: 4\n","epoch 173, total time 2.22\n","LR: 0.002214918084113873\n","==> training...\n","Train: [174][10/23]\tBT 0.089 (0.113)\tDT 0.000 (0.035)\tpurity 0.800 (0.838)\tloss 0.188 (0.171)\t\n","Train: [174][20/23]\tBT 0.068 (0.100)\tDT 0.000 (0.019)\tpurity 0.925 (0.818)\tloss 0.155 (0.170)\t\n","start clustering ... num clusters: 4\n","epoch 174, total time 2.29\n","LR: 0.0020561343579004773\n","==> training...\n","Train: [175][10/23]\tBT 0.102 (0.118)\tDT 0.000 (0.022)\tpurity 0.700 (0.808)\tloss 0.180 (0.220)\t\n","Train: [175][20/23]\tBT 0.105 (0.111)\tDT 0.027 (0.017)\tpurity 0.750 (0.821)\tloss 0.159 (0.192)\t\n","start clustering ... num clusters: 4\n","epoch 175, total time 2.57\n","LR: 0.0019030116872178371\n","==> training...\n","Train: [176][10/23]\tBT 0.086 (0.108)\tDT 0.000 (0.025)\tpurity 0.875 (0.830)\tloss 0.178 (0.172)\t\n","Train: [176][20/23]\tBT 0.098 (0.096)\tDT 0.000 (0.014)\tpurity 0.750 (0.809)\tloss 0.175 (0.177)\t\n","start clustering ... num clusters: 4\n","epoch 176, total time 2.22\n","LR: 0.0017555878527937164\n","==> training...\n","Train: [177][10/23]\tBT 0.099 (0.107)\tDT 0.000 (0.024)\tpurity 0.925 (0.818)\tloss 0.299 (0.210)\t\n","Train: [177][20/23]\tBT 0.071 (0.095)\tDT 0.000 (0.013)\tpurity 0.700 (0.814)\tloss 0.265 (0.196)\t\n","start clustering ... num clusters: 4\n","epoch 177, total time 2.18\n","LR: 0.0016138992292533156\n","==> training...\n","Train: [178][10/23]\tBT 0.087 (0.103)\tDT 0.000 (0.026)\tpurity 0.800 (0.833)\tloss 0.210 (0.171)\t\n","Train: [178][20/23]\tBT 0.082 (0.096)\tDT 0.000 (0.017)\tpurity 0.825 (0.819)\tloss 0.288 (0.188)\t\n","start clustering ... num clusters: 4\n","epoch 178, total time 2.21\n","LR: 0.0014779807761443637\n","==> training...\n","Train: [179][10/23]\tBT 0.082 (0.111)\tDT 0.000 (0.023)\tpurity 0.950 (0.825)\tloss 0.200 (0.177)\t\n","Train: [179][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.013)\tpurity 0.850 (0.821)\tloss 0.312 (0.183)\t\n","start clustering ... num clusters: 4\n","epoch 179, total time 2.22\n","LR: 0.0013478660293113677\n","==> training...\n","Train: [180][10/23]\tBT 0.100 (0.112)\tDT 0.000 (0.025)\tpurity 0.775 (0.835)\tloss 0.176 (0.182)\t\n","Train: [180][20/23]\tBT 0.074 (0.098)\tDT 0.000 (0.013)\tpurity 0.725 (0.820)\tloss 0.331 (0.192)\t\n","start clustering ... num clusters: 4\n","epoch 180, total time 2.25\n","==> Saving...\n","LR: 0.0012235870926211618\n","==> training...\n","Train: [181][10/23]\tBT 0.117 (0.110)\tDT 0.001 (0.024)\tpurity 0.975 (0.805)\tloss 0.125 (0.184)\t\n","Train: [181][20/23]\tBT 0.091 (0.095)\tDT 0.000 (0.013)\tpurity 0.775 (0.805)\tloss 0.201 (0.180)\t\n","start clustering ... num clusters: 4\n","epoch 181, total time 2.19\n","LR: 0.001105174630041747\n","==> training...\n","Train: [182][10/23]\tBT 0.087 (0.109)\tDT 0.000 (0.024)\tpurity 0.775 (0.800)\tloss 0.188 (0.200)\t\n","Train: [182][20/23]\tBT 0.098 (0.096)\tDT 0.000 (0.014)\tpurity 0.600 (0.815)\tloss 0.233 (0.201)\t\n","start clustering ... num clusters: 4\n","epoch 182, total time 2.23\n","LR: 0.0009926578580764262\n","==> training...\n","Train: [183][10/23]\tBT 0.082 (0.114)\tDT 0.001 (0.027)\tpurity 0.850 (0.783)\tloss 0.216 (0.201)\t\n","Train: [183][20/23]\tBT 0.086 (0.096)\tDT 0.001 (0.014)\tpurity 0.775 (0.815)\tloss 0.184 (0.198)\t\n","start clustering ... num clusters: 4\n","epoch 183, total time 2.22\n","LR: 0.0008860645385550509\n","==> training...\n","Train: [184][10/23]\tBT 0.079 (0.110)\tDT 0.000 (0.024)\tpurity 0.850 (0.843)\tloss 0.170 (0.178)\t\n","Train: [184][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.012)\tpurity 0.850 (0.828)\tloss 0.175 (0.186)\t\n","start clustering ... num clusters: 4\n","epoch 184, total time 2.21\n","LR: 0.0007854209717842259\n","==> training...\n","Train: [185][10/23]\tBT 0.160 (0.119)\tDT 0.001 (0.027)\tpurity 0.875 (0.848)\tloss 0.265 (0.166)\t\n","Train: [185][20/23]\tBT 0.085 (0.106)\tDT 0.000 (0.014)\tpurity 0.725 (0.828)\tloss 0.386 (0.196)\t\n","start clustering ... num clusters: 4\n","epoch 185, total time 2.48\n","LR: 0.0006907519900580862\n","==> training...\n","Train: [186][10/23]\tBT 0.099 (0.116)\tDT 0.006 (0.035)\tpurity 0.850 (0.845)\tloss 0.104 (0.166)\t\n","Train: [186][20/23]\tBT 0.080 (0.100)\tDT 0.000 (0.018)\tpurity 0.675 (0.836)\tloss 0.186 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 186, total time 2.30\n","LR: 0.0006020809515313169\n","==> training...\n","Train: [187][10/23]\tBT 0.075 (0.108)\tDT 0.000 (0.025)\tpurity 0.850 (0.793)\tloss 0.167 (0.194)\t\n","Train: [187][20/23]\tBT 0.076 (0.094)\tDT 0.000 (0.013)\tpurity 0.825 (0.802)\tloss 0.223 (0.194)\t\n","start clustering ... num clusters: 4\n","epoch 187, total time 2.17\n","LR: 0.0005194297344558535\n","==> training...\n","Train: [188][10/23]\tBT 0.100 (0.113)\tDT 0.001 (0.026)\tpurity 0.750 (0.822)\tloss 0.202 (0.167)\t\n","Train: [188][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.014)\tpurity 1.000 (0.842)\tloss 0.114 (0.176)\t\n","start clustering ... num clusters: 4\n","epoch 188, total time 2.24\n","LR: 0.000442818731782782\n","==> training...\n","Train: [189][10/23]\tBT 0.071 (0.107)\tDT 0.000 (0.025)\tpurity 0.475 (0.802)\tloss 0.329 (0.220)\t\n","Train: [189][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.017)\tpurity 0.900 (0.806)\tloss 0.176 (0.202)\t\n","start clustering ... num clusters: 4\n","epoch 189, total time 2.22\n","LR: 0.00037226684613065334\n","==> training...\n","Train: [190][10/23]\tBT 0.082 (0.107)\tDT 0.005 (0.024)\tpurity 0.875 (0.845)\tloss 0.149 (0.187)\t\n","Train: [190][20/23]\tBT 0.108 (0.098)\tDT 0.000 (0.013)\tpurity 0.825 (0.814)\tloss 0.140 (0.190)\t\n","start clustering ... num clusters: 4\n","epoch 190, total time 2.25\n","==> Saving...\n","LR: 0.00030779148512155856\n","==> training...\n","Train: [191][10/23]\tBT 0.072 (0.106)\tDT 0.000 (0.023)\tpurity 0.600 (0.808)\tloss 0.234 (0.215)\t\n","Train: [191][20/23]\tBT 0.078 (0.097)\tDT 0.000 (0.013)\tpurity 0.775 (0.814)\tloss 0.161 (0.200)\t\n","start clustering ... num clusters: 4\n","epoch 191, total time 2.22\n","LR: 0.0002494085570860616\n","==> training...\n","Train: [192][10/23]\tBT 0.094 (0.110)\tDT 0.000 (0.026)\tpurity 1.000 (0.842)\tloss 0.124 (0.160)\t\n","Train: [192][20/23]\tBT 0.070 (0.097)\tDT 0.000 (0.016)\tpurity 0.825 (0.854)\tloss 0.172 (0.170)\t\n","start clustering ... num clusters: 4\n","epoch 192, total time 2.23\n","LR: 0.0001971324671380559\n","==> training...\n","Train: [193][10/23]\tBT 0.085 (0.108)\tDT 0.000 (0.027)\tpurity 0.850 (0.850)\tloss 0.140 (0.163)\t\n","Train: [193][20/23]\tBT 0.081 (0.097)\tDT 0.000 (0.017)\tpurity 0.825 (0.822)\tloss 0.206 (0.192)\t\n","start clustering ... num clusters: 4\n","epoch 193, total time 2.23\n","LR: 0.00015097611362051012\n","==> training...\n","Train: [194][10/23]\tBT 0.093 (0.129)\tDT 0.001 (0.040)\tpurity 0.850 (0.835)\tloss 0.129 (0.172)\t\n","Train: [194][20/23]\tBT 0.074 (0.115)\tDT 0.000 (0.023)\tpurity 0.725 (0.819)\tloss 0.149 (0.173)\t\n","start clustering ... num clusters: 4\n","epoch 194, total time 2.60\n","LR: 0.0001109508849230001\n","==> training...\n","Train: [195][10/23]\tBT 0.115 (0.113)\tDT 0.001 (0.029)\tpurity 0.925 (0.840)\tloss 0.135 (0.166)\t\n","Train: [195][20/23]\tBT 0.072 (0.100)\tDT 0.000 (0.015)\tpurity 0.950 (0.845)\tloss 0.153 (0.174)\t\n","start clustering ... num clusters: 4\n","epoch 195, total time 2.29\n","LR: 7.70666566718009e-05\n","==> training...\n","Train: [196][10/23]\tBT 0.077 (0.112)\tDT 0.000 (0.026)\tpurity 0.825 (0.843)\tloss 0.133 (0.190)\t\n","Train: [196][20/23]\tBT 0.068 (0.099)\tDT 0.000 (0.014)\tpurity 0.850 (0.851)\tloss 0.213 (0.192)\t\n","start clustering ... num clusters: 4\n","epoch 196, total time 2.27\n","LR: 4.933178929321103e-05\n","==> training...\n","Train: [197][10/23]\tBT 0.090 (0.112)\tDT 0.001 (0.024)\tpurity 0.875 (0.830)\tloss 0.229 (0.179)\t\n","Train: [197][20/23]\tBT 0.084 (0.099)\tDT 0.000 (0.013)\tpurity 0.725 (0.814)\tloss 0.127 (0.175)\t\n","start clustering ... num clusters: 4\n","epoch 197, total time 2.27\n","LR: 2.775312595075241e-05\n","==> training...\n","Train: [198][10/23]\tBT 0.075 (0.108)\tDT 0.000 (0.028)\tpurity 0.700 (0.825)\tloss 0.230 (0.191)\t\n","Train: [198][20/23]\tBT 0.076 (0.099)\tDT 0.000 (0.018)\tpurity 0.725 (0.830)\tloss 0.273 (0.196)\t\n","start clustering ... num clusters: 4\n","epoch 198, total time 2.27\n","LR: 1.233599085671e-05\n","==> training...\n","Train: [199][10/23]\tBT 0.079 (0.112)\tDT 0.000 (0.024)\tpurity 1.000 (0.838)\tloss 0.201 (0.187)\t\n","Train: [199][20/23]\tBT 0.073 (0.098)\tDT 0.000 (0.013)\tpurity 0.825 (0.830)\tloss 0.180 (0.184)\t\n","start clustering ... num clusters: 4\n","epoch 199, total time 2.24\n","LR: 3.0841879584853073e-06\n","==> training...\n","Train: [200][10/23]\tBT 0.083 (0.108)\tDT 0.000 (0.029)\tpurity 0.925 (0.850)\tloss 0.221 (0.177)\t\n","Train: [200][20/23]\tBT 0.084 (0.099)\tDT 0.001 (0.017)\tpurity 0.975 (0.871)\tloss 0.169 (0.176)\t\n","start clustering ... num clusters: 4\n","epoch 200, total time 2.26\n","==> Saving...\n"]}]},{"cell_type":"markdown","source":["### Graphs"],"metadata":{"id":"tISDTul2rLhi"}},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + str(epochs) + '.pth')\n","history_df = cpkt['history_df']"],"metadata":{"id":"mxJcEVaHrOa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_ = history_df['loss'].plot.line(xlabel='epochs', ylabel='loss', color='orange')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"7y3ii5bUsr25","executionInfo":{"status":"ok","timestamp":1651636593415,"user_tz":420,"elapsed":1095,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"6ca38863-f559-4746-b9e2-c098f4a4cbff"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df['purity'].plot.line(xlabel='epochs', ylabel='purity')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"oGM9Ul3IwpL9","executionInfo":{"status":"ok","timestamp":1651636597825,"user_tz":420,"elapsed":825,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"d9c0fa6c-e839-4746-df99-3a2e1882d56b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# Linear Evaluation"],"metadata":{"id":"rWpGZ0dmqWqI"}},{"cell_type":"markdown","source":["### Misc Setup"],"metadata":{"id":"VzeXb2y52ktA"}},{"cell_type":"code","source":["def load_weights(model, wts_path):\n","    wts = torch.load(wts_path)\n","    # pdb.set_trace()\n","    if 'state_dict' in wts:\n","        ckpt = wts['state_dict']\n","    elif 'model' in wts:\n","        ckpt = wts['model']\n","    else:\n","        ckpt = wts\n","\n","    ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n","    ckpt = {k: v for k, v in ckpt.items() if 'encoder_q' not in k}\n","    ckpt = {k.replace('encoder_t.', ''): v for k, v in ckpt.items()}\n","    state_dict = {}\n","\n","    for m_key, m_val in model.state_dict().items():\n","        if m_key in ckpt:\n","            state_dict[m_key] = ckpt[m_key]\n","        else:\n","            state_dict[m_key] = m_val\n","            print('not copied => ' + m_key)\n","\n","    model.load_state_dict(state_dict)"],"metadata":{"id":"6Edp6TK5qbKw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model(arch, output_dim, wts_path):\n","    model, _ = initialize_encoder(arch, output_dim)\n","    load_weights(model, wts_path)\n","\n","    # if arch == 'alexnet':\n","    #     model = AlexNet()\n","    #     model.fc = nn.Sequential()\n","    #     load_weights(model, wts_path)\n","    # elif arch == 'pt_alexnet':\n","    #     model = models.alexnet()\n","    #     classif = list(model.classifier.children())[:5]\n","    #     model.classifier = nn.Sequential(*classif)\n","    #     load_weights(model, wts_path)\n","    # elif arch == 'mobilenet':\n","    #     model = MobileNetV2()\n","    #     model.fc = nn.Sequential()\n","    #     load_weights(model, wts_path)\n","    # elif 'sup_resnet' in arch:\n","    #     model = models.__dict__[arch.replace('sup_', '')](pretrained=True)\n","    #     model.fc = nn.Sequential()\n","    # elif 'resnet' in arch:\n","    #     model = models.__dict__[arch]()\n","    #     model.fc = nn.Sequential()\n","    #     load_weights(model, wts_path)\n","    # else:\n","    #     raise ValueError('arch not found: ' + arch)\n","\n","    for p in model.parameters():\n","        p.requires_grad = False\n","\n","    return model"],"metadata":{"id":"llr6zKaHv_Mw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Normalize(nn.Module):\n","    def forward(self, x):\n","        return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","class FullBatchNorm(nn.Module):\n","    def __init__(self, var, mean):\n","        super(FullBatchNorm, self).__init__()\n","        self.register_buffer('inv_std', (1.0 / torch.sqrt(var + 1e-5)))\n","        self.register_buffer('mean', mean)\n","\n","    def forward(self, x):\n","        return (x - self.mean) * self.inv_std"],"metadata":{"id":"L35H3XpAwAPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_channels(arch):\n","    if arch == 'alexnet':\n","        c = 4096\n","    elif arch == 'pt_alexnet':\n","        c = 4096\n","    elif 'resnet50' in arch:\n","        c = 2048\n","    elif arch == 'resnet18':\n","        c = 512\n","    elif arch == 'mobilenet':\n","        c = 1280\n","    else:\n","        raise ValueError('arch not found: ' + arch)\n","    return c"],"metadata":{"id":"EJrHmVbWwOuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)"],"metadata":{"id":"_G27DtRTwbnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_feats(loader, model, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, ptr = None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = normalize(model(images)).cpu()\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets.argmax(axis=1))\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","    return feats, labels"],"metadata":{"id":"ue02EocuyLgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"uYvYec8y2n8g"}},{"cell_type":"code","source":["def train(train_loader, backbone, linear, optimizer, epoch, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(train_loader),\n","        [batch_time, data_time, losses, top1, top2],\n","        prefix=\"Epoch: [{}]\".format(epoch))\n","\n","    # switch to train mode\n","    backbone.eval()\n","    linear.train()\n","\n","    end = time.time()\n","    for i, (indices, images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # compute output\n","        with torch.no_grad():\n","            output = backbone(images)\n","        output = linear(output)\n","        loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","        # measure accuracy and record loss\n","        acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","        losses.update(loss.item(), images.size(0))\n","        top1.update(acc1[0], images.size(0))\n","        top2.update(acc2[0], images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            print(progress.display(i))\n","\n","    return losses.avg, top1.avg.item(), top2.avg.item()"],"metadata":{"id":"1gWHh9br2g-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(val_loader, backbone, linear, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(val_loader),\n","        [batch_time, losses, top1, top2],\n","        prefix='Test: ')\n","\n","    backbone.eval()\n","    linear.eval()\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(val_loader):\n","            images = images.cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = backbone(images)\n","            output = linear(output)\n","            loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","            # measure accuracy and record loss\n","            \n","            acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","            losses.update(loss.item(), images.size(0))\n","            top1.update(acc1[0], images.size(0))\n","            top2.update(acc2[0], images.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","        # TODO: this should also be done with the ProgressMeter\n","        print(' * Acc@1 {top1.avg:.3f} Acc@2 {top2.avg:.3f}'\n","              .format(top1=top1, top2=top2))\n","\n","    return losses.avg, top1.avg.item(), top2.avg.item()"],"metadata":{"id":"tzM_L9xK3qP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main_worker(data, label_fn, weights, save, logger, batch_size=16, workers=2, \n","                epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                resume=None, evaluate=False, n_classes=4, output_dim=16):\n","    best_acc1 = 0\n","    best_loss = np.inf\n","\n","    # Data loading code\n","    traindir = os.path.join(data, 'train')\n","    valdir = os.path.join(data, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    train_transform = transforms.Compose([\n","        #transforms.RandomResizedCrop(224),\n","        transforms.Resize(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        #transforms.Resize(256),\n","        #transforms.CenterCrop(224),\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    train_dataset = Image_Dataset(traindir, label_fn, train_transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size, shuffle=True,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(valdir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    train_val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(traindir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    backbone = get_model(arch, output_dim, weights)\n","    backbone = nn.DataParallel(backbone).cuda()\n","    backbone.eval()\n","\n","\n","    cached_feats = '%s/var_mean.pth.tar' % save\n","    if not os.path.exists(cached_feats):\n","        train_feats, _ = get_feats(train_val_loader, backbone, print_freq, logger)\n","        train_var, train_mean = torch.var_mean(train_feats, dim=0)\n","        torch.save((train_var, train_mean), cached_feats)\n","    else:\n","        train_var, train_mean = torch.load(cached_feats)\n","    if mlp:\n","        c = output_dim\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(output_dim, c),\n","            nn.BatchNorm1d(c),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(c, n_classes),\n","        )\n","    else:\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(output_dim, n_classes)\n","        )\n","\n","    print(backbone)\n","    print(linear)\n","\n","    linear = linear.cuda()\n","\n","    optimizer = torch.optim.SGD(linear.parameters(),\n","                                lr,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay)\n","\n","    sched = [int(x) for x in lr_schedule.split(',')]\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer, milestones=sched\n","    )\n","\n","    start_epoch = 0\n","    history_df = pd.DataFrame(index=range(start_epoch + 1, epochs + 1))\n","\n","    # optionally resume from a checkpoint\n","    if resume:\n","        if os.path.isfile(resume):\n","            print(\"=> loading checkpoint '{}'\".format(resume))\n","            checkpoint = torch.load(resume)\n","            start_epoch = checkpoint['epoch']\n","            linear.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            history_df = checkpoint['history_df']\n","            print(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(resume, checkpoint['epoch']))\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(resume))\n","\n","    cudnn.benchmark = True\n","\n","    if evaluate:\n","        validate(val_loader, backbone, linear, print_freq, logger)\n","        return\n","\n","    for epoch in range(start_epoch, epochs):\n","        # train for one epoch\n","        loss, acc1, acc2 = train(\n","            train_loader, backbone, linear, optimizer, epoch, print_freq, logger)\n","\n","        # evaluate on validation set\n","        val_loss, val_acc1, val_acc2 = validate(\n","            val_loader, backbone, linear, print_freq, logger)\n","        \n","        history_df.loc[epoch + 1, 'train_loss'] = loss\n","        history_df.loc[epoch + 1, 'train_acc1'] = acc1\n","        history_df.loc[epoch + 1, 'train_acc2'] = acc2\n","        history_df.loc[epoch + 1, 'val_loss'] = val_loss\n","        history_df.loc[epoch + 1, 'val_acc1'] = val_acc1\n","        history_df.loc[epoch + 1, 'val_acc2'] = val_acc2\n","\n","        # modify lr\n","        lr_scheduler.step()\n","        # logger.info('LR: {:f}'.format(lr_scheduler.get_last_lr()[-1]))\n","\n","        # remember best acc@1 and save checkpoint\n","        #is_best = val_acc1 > best_acc1\n","        is_best = val_loss < best_loss\n","        if is_best:\n","            best_loss = val_loss\n","\n","\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': linear.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","            'backbone': backbone,\n","            'linear': linear,\n","            'history_df': history_df\n","        }, is_best, save)\n","\n","    return backbone, linear"],"metadata":{"id":"_44olm-z7fG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!touch logger_init\n","def main_linear_eval(data, label_fn, weights, save, batch_size=16, workers=2, \n","                     epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                     momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                     resume=None, evaluate=False, seed=None, n_classes=4, output_dim=16):\n","    args = locals()\n","    del args['label_fn']\n","\n","    makedirs(save)\n","    logger = get_logger(logpath=os.path.join(save, 'logs'), filepath='logger_init')\n","    print(args)\n","\n","    if seed is not None:\n","        random.seed(seed)\n","        torch.manual_seed(seed)\n","        cudnn.deterministic = True\n","        warnings.warn('You have chosen to seed training. '\n","                      'This will turn on the CUDNN deterministic setting, '\n","                      'which can slow down your training considerably! '\n","                      'You may see unexpected behavior when restarting '\n","                      'from checkpoints.')\n","\n","    return main_worker(data=data, label_fn=label_fn, weights=weights, save=save, \n","                       logger=logger, batch_size=batch_size, workers=workers, \n","                       epochs=epochs, arch=arch, print_freq=print_freq, mlp=mlp, \n","                       lr=lr, momentum=momentum, weight_decay=weight_decay, \n","                       lr_schedule=lr_schedule, resume=resume, evaluate=evaluate, \n","                       n_classes=n_classes, output_dim=output_dim)"],"metadata":{"id":"EJy6AFcZDlK8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Getting Labels"],"metadata":{"id":"cw-FQg2fHl9Z"}},{"cell_type":"code","source":["labels_df = pd.read_csv(root_path + 'Updated_Cropped_Images_Wound_Stage_Probabilities.csv', index_col='Image')\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"Q613sTN9OH9z","executionInfo":{"status":"ok","timestamp":1651654709387,"user_tz":420,"elapsed":123,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"c44759e1-b63c-413d-82bc-d41d044cbbfe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation\n","Image                                                                 \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000"],"text/html":["\n","  <div id=\"df-620fbafe-bdd7-423f-9b28-eecf4798017c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-620fbafe-bdd7-423f-9b28-eecf4798017c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-620fbafe-bdd7-423f-9b28-eecf4798017c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-620fbafe-bdd7-423f-9b28-eecf4798017c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["labels_df.loc['Day 8_A8-4-L.png'].to_numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpskZYsoPOrq","executionInfo":{"status":"ok","timestamp":1651654709658,"user_tz":420,"elapsed":389,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"7f6de820-953f-4909-d5e0-0ecba2f03e32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.18181818, 0.09090909, 0.54545455, 0.18181818])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["### Epoch number of CMSF to evaluate"],"metadata":{"id":"JpaVfWQTQ8XF"}},{"cell_type":"code","source":["epoch = '200'\n","eval_suffix = '_1_'"],"metadata":{"id":"N9Pe4XCJQO6T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Linear Evaluation Training"],"metadata":{"id":"AoS9kV5iOBUC"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"IrWc3kqD1pW3"}},{"cell_type":"code","source":["_, _ = main_linear_eval(\n","    data=root_path + 'Split_images', \n","    label_fn=lambda x: labels_df.loc[x].to_numpy(), \n","    weights=root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + epoch + '.pth',\n","    save=root_path + 'outputs/' + train_folder_name + 'eval' + eval_suffix + epoch + '/', \n","    batch_size=8, \n","    workers=2, \n","    epochs=40, \n","    arch='resnet', \n","    print_freq=10, \n","    mlp=False, \n","    lr=0.01,\n","    output_dim=16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqLRidzrRF3A","executionInfo":{"status":"ok","timestamp":1651642117307,"user_tz":420,"elapsed":94467,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"dd63883f-dca1-4f12-ee24-014166a55020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","logger_init\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'data': 'gdrive/MyDrive/Explainable_Wound_Classification/Split_images', 'weights': 'gdrive/MyDrive/Explainable_Wound_Classification/outputs/transforms_1/ckpt_epoch_100.pth', 'save': 'gdrive/MyDrive/Explainable_Wound_Classification/outputs/transforms_1/eval_1_100/', 'batch_size': 8, 'workers': 2, 'epochs': 40, 'arch': 'resnet', 'print_freq': 10, 'mlp': False, 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_schedule': '15,30,40', 'resume': None, 'evaluate': False, 'seed': None, 'n_classes': 4, 'output_dim': 16}\n","Parameter containing:\n","tensor([[ 0.1510,  0.0797, -0.1093,  ...,  0.0009, -0.1144,  0.0547],\n","        [-0.0408,  0.0161,  0.0411,  ...,  0.1106, -0.0437, -0.0296],\n","        [ 0.0459, -0.0097,  0.0417,  ...,  0.0151,  0.0007,  0.0154],\n","        ...,\n","        [ 0.1059, -0.0178, -0.0113,  ...,  0.2362,  0.0130,  0.0092],\n","        [ 0.0828,  0.0342, -0.0461,  ..., -0.0407, -0.0341, -0.0227],\n","        [ 0.0212, -0.0492, -0.0464,  ...,  0.0893, -0.1043,  0.0182]])\n","Parameter containing:\n","tensor([-0.0334,  0.0131,  0.0143, -0.0399,  0.0403, -0.0399,  0.0267,  0.0360,\n","        -0.0009, -0.0330,  0.0068,  0.0037, -0.0016, -0.0126,  0.0395,  0.0290])\n","DataParallel(\n","  (module): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=16, bias=True)\n","  )\n",")\n","Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=16, out_features=4, bias=True)\n",")\n","Epoch: [0][ 0/24]\tTime  0.590 ( 0.590)\tData  0.548 ( 0.548)\tLoss 7.9684e-01 (7.9684e-01)\tAcc@1  12.50 ( 12.50)\tAcc@2  50.00 ( 50.00)\n","Epoch: [0][10/24]\tTime  0.046 ( 0.107)\tData  0.000 ( 0.065)\tLoss 7.1667e-01 (7.5553e-01)\tAcc@1  25.00 ( 18.18)\tAcc@2  50.00 ( 46.59)\n","Epoch: [0][20/24]\tTime  0.046 ( 0.089)\tData  0.000 ( 0.046)\tLoss 6.9959e-01 (7.3092e-01)\tAcc@1  50.00 ( 25.60)\tAcc@2  87.50 ( 55.36)\n","Test: [0/4]\tTime  0.499 ( 0.499)\tLoss 6.5649e-01 (6.5649e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  50.00 ( 50.00)\n"," * Acc@1 37.500 Acc@2 65.625\n","Epoch: [1][ 0/24]\tTime  0.583 ( 0.583)\tData  0.543 ( 0.543)\tLoss 6.0654e-01 (6.0654e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [1][10/24]\tTime  0.071 ( 0.102)\tData  0.038 ( 0.065)\tLoss 6.6193e-01 (6.3480e-01)\tAcc@1  37.50 ( 56.82)\tAcc@2 100.00 ( 78.41)\n","Epoch: [1][20/24]\tTime  0.102 ( 0.087)\tData  0.064 ( 0.049)\tLoss 5.0714e-01 (6.0424e-01)\tAcc@1  87.50 ( 58.33)\tAcc@2 100.00 ( 83.33)\n","Test: [0/4]\tTime  0.337 ( 0.337)\tLoss 5.8307e-01 (5.8307e-01)\tAcc@1  25.00 ( 25.00)\tAcc@2  50.00 ( 50.00)\n"," * Acc@1 40.625 Acc@2 75.000\n","Epoch: [2][ 0/24]\tTime  0.667 ( 0.667)\tData  0.607 ( 0.607)\tLoss 5.7119e-01 (5.7119e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [2][10/24]\tTime  0.031 ( 0.110)\tData  0.000 ( 0.068)\tLoss 5.7919e-01 (5.6855e-01)\tAcc@1  75.00 ( 56.82)\tAcc@2 100.00 ( 87.50)\n","Epoch: [2][20/24]\tTime  0.039 ( 0.078)\tData  0.008 ( 0.041)\tLoss 5.0745e-01 (5.4306e-01)\tAcc@1  75.00 ( 61.90)\tAcc@2 100.00 ( 89.29)\n","Test: [0/4]\tTime  0.266 ( 0.266)\tLoss 5.4615e-01 (5.4615e-01)\tAcc@1  25.00 ( 25.00)\tAcc@2  50.00 ( 50.00)\n"," * Acc@1 50.000 Acc@2 81.250\n","Epoch: [3][ 0/24]\tTime  0.244 ( 0.244)\tData  0.212 ( 0.212)\tLoss 5.1089e-01 (5.1089e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [3][10/24]\tTime  0.055 ( 0.065)\tData  0.022 ( 0.035)\tLoss 5.2655e-01 (4.9570e-01)\tAcc@1  50.00 ( 71.59)\tAcc@2  87.50 ( 93.18)\n","Epoch: [3][20/24]\tTime  0.028 ( 0.054)\tData  0.000 ( 0.024)\tLoss 4.8648e-01 (5.0175e-01)\tAcc@1  50.00 ( 69.05)\tAcc@2 100.00 ( 94.05)\n","Test: [0/4]\tTime  0.258 ( 0.258)\tLoss 5.2802e-01 (5.2802e-01)\tAcc@1  25.00 ( 25.00)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 53.125 Acc@2 90.625\n","Epoch: [4][ 0/24]\tTime  0.272 ( 0.272)\tData  0.230 ( 0.230)\tLoss 5.4004e-01 (5.4004e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n","Epoch: [4][10/24]\tTime  0.040 ( 0.065)\tData  0.000 ( 0.032)\tLoss 5.2216e-01 (5.0277e-01)\tAcc@1  75.00 ( 70.45)\tAcc@2  87.50 ( 94.32)\n","Epoch: [4][20/24]\tTime  0.036 ( 0.054)\tData  0.000 ( 0.022)\tLoss 4.6180e-01 (4.8000e-01)\tAcc@1  62.50 ( 68.45)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.243 ( 0.243)\tLoss 5.1050e-01 (5.1050e-01)\tAcc@1  25.00 ( 25.00)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 53.125 Acc@2 90.625\n","Epoch: [5][ 0/24]\tTime  0.260 ( 0.260)\tData  0.223 ( 0.223)\tLoss 4.8860e-01 (4.8860e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [5][10/24]\tTime  0.033 ( 0.063)\tData  0.000 ( 0.031)\tLoss 4.7584e-01 (4.6695e-01)\tAcc@1 100.00 ( 76.14)\tAcc@2 100.00 ( 96.59)\n","Epoch: [5][20/24]\tTime  0.063 ( 0.056)\tData  0.032 ( 0.025)\tLoss 4.0386e-01 (4.6072e-01)\tAcc@1 100.00 ( 76.19)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.250 ( 0.250)\tLoss 4.9878e-01 (4.9878e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 59.375 Acc@2 90.625\n","Epoch: [6][ 0/24]\tTime  0.255 ( 0.255)\tData  0.218 ( 0.218)\tLoss 4.4498e-01 (4.4498e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [6][10/24]\tTime  0.055 ( 0.063)\tData  0.025 ( 0.033)\tLoss 4.5306e-01 (4.5053e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 ( 92.05)\n","Epoch: [6][20/24]\tTime  0.064 ( 0.054)\tData  0.035 ( 0.025)\tLoss 4.8904e-01 (4.5353e-01)\tAcc@1  37.50 ( 72.62)\tAcc@2  87.50 ( 92.86)\n","Test: [0/4]\tTime  0.359 ( 0.359)\tLoss 4.8857e-01 (4.8857e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 62.500 Acc@2 93.750\n","Epoch: [7][ 0/24]\tTime  0.283 ( 0.283)\tData  0.247 ( 0.247)\tLoss 4.7445e-01 (4.7445e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [7][10/24]\tTime  0.033 ( 0.061)\tData  0.000 ( 0.026)\tLoss 4.3140e-01 (4.4901e-01)\tAcc@1  75.00 ( 71.59)\tAcc@2 100.00 ( 94.32)\n","Epoch: [7][20/24]\tTime  0.030 ( 0.054)\tData  0.000 ( 0.022)\tLoss 3.6793e-01 (4.4155e-01)\tAcc@1  87.50 ( 72.62)\tAcc@2 100.00 ( 94.64)\n","Test: [0/4]\tTime  0.243 ( 0.243)\tLoss 4.8060e-01 (4.8060e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 65.625 Acc@2 93.750\n","Epoch: [8][ 0/24]\tTime  0.264 ( 0.264)\tData  0.232 ( 0.232)\tLoss 3.8330e-01 (3.8330e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [8][10/24]\tTime  0.028 ( 0.063)\tData  0.000 ( 0.031)\tLoss 4.8924e-01 (4.3291e-01)\tAcc@1  75.00 ( 71.59)\tAcc@2  87.50 ( 93.18)\n","Epoch: [8][20/24]\tTime  0.028 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.4994e-01 (4.2833e-01)\tAcc@1  62.50 ( 76.19)\tAcc@2 100.00 ( 94.64)\n","Test: [0/4]\tTime  0.246 ( 0.246)\tLoss 4.7420e-01 (4.7420e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 93.750\n","Epoch: [9][ 0/24]\tTime  0.259 ( 0.259)\tData  0.218 ( 0.218)\tLoss 3.9085e-01 (3.9085e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [9][10/24]\tTime  0.038 ( 0.062)\tData  0.001 ( 0.027)\tLoss 4.5884e-01 (4.2343e-01)\tAcc@1  50.00 ( 76.14)\tAcc@2 100.00 ( 94.32)\n","Epoch: [9][20/24]\tTime  0.029 ( 0.054)\tData  0.000 ( 0.022)\tLoss 3.5205e-01 (4.2392e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 ( 94.05)\n","Test: [0/4]\tTime  0.227 ( 0.227)\tLoss 4.6867e-01 (4.6867e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 93.750\n","Epoch: [10][ 0/24]\tTime  0.256 ( 0.256)\tData  0.224 ( 0.224)\tLoss 3.6824e-01 (3.6824e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [10][10/24]\tTime  0.028 ( 0.066)\tData  0.000 ( 0.036)\tLoss 4.4579e-01 (4.0304e-01)\tAcc@1  75.00 ( 79.55)\tAcc@2  75.00 ( 94.32)\n","Epoch: [10][20/24]\tTime  0.028 ( 0.057)\tData  0.000 ( 0.026)\tLoss 4.4067e-01 (4.1738e-01)\tAcc@1  75.00 ( 74.40)\tAcc@2 100.00 ( 94.64)\n","Test: [0/4]\tTime  0.252 ( 0.252)\tLoss 4.6586e-01 (4.6586e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 93.750\n","Epoch: [11][ 0/24]\tTime  0.229 ( 0.229)\tData  0.194 ( 0.194)\tLoss 4.8473e-01 (4.8473e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2 100.00 (100.00)\n","Epoch: [11][10/24]\tTime  0.030 ( 0.065)\tData  0.000 ( 0.034)\tLoss 4.2587e-01 (4.1448e-01)\tAcc@1  50.00 ( 70.45)\tAcc@2  87.50 ( 95.45)\n","Epoch: [11][20/24]\tTime  0.051 ( 0.057)\tData  0.000 ( 0.025)\tLoss 3.9246e-01 (4.2153e-01)\tAcc@1 100.00 ( 73.21)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.244 ( 0.244)\tLoss 4.6285e-01 (4.6285e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 90.625\n","Epoch: [12][ 0/24]\tTime  0.258 ( 0.258)\tData  0.227 ( 0.227)\tLoss 4.6143e-01 (4.6143e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [12][10/24]\tTime  0.029 ( 0.062)\tData  0.000 ( 0.032)\tLoss 4.0897e-01 (4.2325e-01)\tAcc@1  87.50 ( 65.91)\tAcc@2 100.00 ( 93.18)\n","Epoch: [12][20/24]\tTime  0.050 ( 0.055)\tData  0.016 ( 0.024)\tLoss 3.5100e-01 (4.0659e-01)\tAcc@1  87.50 ( 75.00)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.244 ( 0.244)\tLoss 4.6015e-01 (4.6015e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 90.625\n","Epoch: [13][ 0/24]\tTime  0.244 ( 0.244)\tData  0.210 ( 0.210)\tLoss 4.3277e-01 (4.3277e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [13][10/24]\tTime  0.038 ( 0.064)\tData  0.000 ( 0.032)\tLoss 3.6483e-01 (4.0121e-01)\tAcc@1  75.00 ( 78.41)\tAcc@2 100.00 ( 95.45)\n","Epoch: [13][20/24]\tTime  0.029 ( 0.054)\tData  0.000 ( 0.022)\tLoss 3.5796e-01 (4.0765e-01)\tAcc@1  87.50 ( 74.40)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.228 ( 0.228)\tLoss 4.5955e-01 (4.5955e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 90.625\n","Epoch: [14][ 0/24]\tTime  0.237 ( 0.237)\tData  0.207 ( 0.207)\tLoss 4.4768e-01 (4.4768e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [14][10/24]\tTime  0.031 ( 0.060)\tData  0.001 ( 0.031)\tLoss 3.8237e-01 (4.0995e-01)\tAcc@1  75.00 ( 71.59)\tAcc@2 100.00 ( 97.73)\n","Epoch: [14][20/24]\tTime  0.029 ( 0.053)\tData  0.000 ( 0.024)\tLoss 4.0843e-01 (4.1467e-01)\tAcc@1  62.50 ( 72.62)\tAcc@2 100.00 ( 94.64)\n","Test: [0/4]\tTime  0.235 ( 0.235)\tLoss 4.5530e-01 (4.5530e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [15][ 0/24]\tTime  0.258 ( 0.258)\tData  0.228 ( 0.228)\tLoss 3.0603e-01 (3.0603e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [15][10/24]\tTime  0.054 ( 0.063)\tData  0.025 ( 0.033)\tLoss 4.6750e-01 (3.8580e-01)\tAcc@1  75.00 ( 82.95)\tAcc@2  87.50 ( 97.73)\n","Epoch: [15][20/24]\tTime  0.055 ( 0.054)\tData  0.026 ( 0.025)\tLoss 3.7649e-01 (4.0501e-01)\tAcc@1  50.00 ( 75.60)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.238 ( 0.238)\tLoss 4.5508e-01 (4.5508e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [16][ 0/24]\tTime  0.270 ( 0.270)\tData  0.237 ( 0.237)\tLoss 4.2771e-01 (4.2771e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [16][10/24]\tTime  0.030 ( 0.063)\tData  0.000 ( 0.032)\tLoss 3.9962e-01 (3.9959e-01)\tAcc@1  75.00 ( 73.86)\tAcc@2 100.00 ( 97.73)\n","Epoch: [16][20/24]\tTime  0.029 ( 0.053)\tData  0.000 ( 0.023)\tLoss 3.8899e-01 (4.0217e-01)\tAcc@1  87.50 ( 76.79)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.258 ( 0.258)\tLoss 4.5503e-01 (4.5503e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [17][ 0/24]\tTime  0.262 ( 0.262)\tData  0.229 ( 0.229)\tLoss 4.0271e-01 (4.0271e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [17][10/24]\tTime  0.054 ( 0.064)\tData  0.024 ( 0.034)\tLoss 3.9247e-01 (3.9089e-01)\tAcc@1  75.00 ( 78.41)\tAcc@2 100.00 ( 96.59)\n","Epoch: [17][20/24]\tTime  0.056 ( 0.054)\tData  0.028 ( 0.024)\tLoss 4.4530e-01 (3.9737e-01)\tAcc@1  37.50 ( 76.79)\tAcc@2  87.50 ( 97.02)\n","Test: [0/4]\tTime  0.240 ( 0.240)\tLoss 4.5480e-01 (4.5480e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [18][ 0/24]\tTime  0.254 ( 0.254)\tData  0.222 ( 0.222)\tLoss 4.3776e-01 (4.3776e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2 100.00 (100.00)\n","Epoch: [18][10/24]\tTime  0.029 ( 0.066)\tData  0.000 ( 0.036)\tLoss 4.6918e-01 (3.8310e-01)\tAcc@1  62.50 ( 77.27)\tAcc@2 100.00 (100.00)\n","Epoch: [18][20/24]\tTime  0.028 ( 0.056)\tData  0.000 ( 0.025)\tLoss 4.0809e-01 (3.9790e-01)\tAcc@1  87.50 ( 75.00)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.228 ( 0.228)\tLoss 4.5445e-01 (4.5445e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [19][ 0/24]\tTime  0.306 ( 0.306)\tData  0.256 ( 0.256)\tLoss 4.4684e-01 (4.4684e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [19][10/24]\tTime  0.062 ( 0.067)\tData  0.029 ( 0.035)\tLoss 4.3959e-01 (3.9392e-01)\tAcc@1 100.00 ( 73.86)\tAcc@2 100.00 ( 95.45)\n","Epoch: [19][20/24]\tTime  0.034 ( 0.056)\tData  0.000 ( 0.024)\tLoss 4.1540e-01 (4.0323e-01)\tAcc@1  75.00 ( 76.19)\tAcc@2  87.50 ( 96.43)\n","Test: [0/4]\tTime  0.246 ( 0.246)\tLoss 4.5442e-01 (4.5442e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [20][ 0/24]\tTime  0.259 ( 0.259)\tData  0.224 ( 0.224)\tLoss 3.3065e-01 (3.3065e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [20][10/24]\tTime  0.029 ( 0.065)\tData  0.000 ( 0.034)\tLoss 4.1425e-01 (4.1178e-01)\tAcc@1  75.00 ( 69.32)\tAcc@2 100.00 ( 95.45)\n","Epoch: [20][20/24]\tTime  0.028 ( 0.057)\tData  0.000 ( 0.026)\tLoss 3.6346e-01 (4.0223e-01)\tAcc@1  87.50 ( 74.40)\tAcc@2  87.50 ( 95.83)\n","Test: [0/4]\tTime  0.246 ( 0.246)\tLoss 4.5429e-01 (4.5429e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [21][ 0/24]\tTime  0.268 ( 0.268)\tData  0.234 ( 0.234)\tLoss 3.9017e-01 (3.9017e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [21][10/24]\tTime  0.039 ( 0.063)\tData  0.010 ( 0.032)\tLoss 3.5278e-01 (4.0905e-01)\tAcc@1  87.50 ( 75.00)\tAcc@2 100.00 ( 94.32)\n","Epoch: [21][20/24]\tTime  0.035 ( 0.054)\tData  0.005 ( 0.024)\tLoss 3.3939e-01 (4.0067e-01)\tAcc@1  87.50 ( 75.00)\tAcc@2  87.50 ( 95.24)\n","Test: [0/4]\tTime  0.233 ( 0.233)\tLoss 4.5407e-01 (4.5407e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [22][ 0/24]\tTime  0.294 ( 0.294)\tData  0.260 ( 0.260)\tLoss 4.0659e-01 (4.0659e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [22][10/24]\tTime  0.045 ( 0.064)\tData  0.016 ( 0.033)\tLoss 4.2971e-01 (3.9667e-01)\tAcc@1  87.50 ( 75.00)\tAcc@2 100.00 ( 96.59)\n","Epoch: [22][20/24]\tTime  0.039 ( 0.055)\tData  0.009 ( 0.024)\tLoss 3.6487e-01 (4.0027e-01)\tAcc@1  75.00 ( 75.60)\tAcc@2 100.00 ( 97.02)\n","Test: [0/4]\tTime  0.266 ( 0.266)\tLoss 4.5394e-01 (4.5394e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [23][ 0/24]\tTime  0.254 ( 0.254)\tData  0.221 ( 0.221)\tLoss 3.7346e-01 (3.7346e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [23][10/24]\tTime  0.029 ( 0.063)\tData  0.000 ( 0.031)\tLoss 4.3502e-01 (3.8934e-01)\tAcc@1  87.50 ( 82.95)\tAcc@2 100.00 (100.00)\n","Epoch: [23][20/24]\tTime  0.031 ( 0.055)\tData  0.000 ( 0.023)\tLoss 4.0349e-01 (4.0554e-01)\tAcc@1  62.50 ( 74.40)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.236 ( 0.236)\tLoss 4.5386e-01 (4.5386e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [24][ 0/24]\tTime  0.315 ( 0.315)\tData  0.271 ( 0.271)\tLoss 3.6816e-01 (3.6816e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [24][10/24]\tTime  0.064 ( 0.066)\tData  0.035 ( 0.034)\tLoss 4.2164e-01 (4.1334e-01)\tAcc@1 100.00 ( 78.41)\tAcc@2 100.00 ( 95.45)\n","Epoch: [24][20/24]\tTime  0.060 ( 0.057)\tData  0.027 ( 0.026)\tLoss 4.5190e-01 (4.0124e-01)\tAcc@1  50.00 ( 76.79)\tAcc@2  87.50 ( 95.24)\n","Test: [0/4]\tTime  0.265 ( 0.265)\tLoss 4.5367e-01 (4.5367e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [25][ 0/24]\tTime  0.273 ( 0.273)\tData  0.242 ( 0.242)\tLoss 4.2605e-01 (4.2605e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [25][10/24]\tTime  0.028 ( 0.067)\tData  0.000 ( 0.035)\tLoss 3.6519e-01 (4.0846e-01)\tAcc@1  87.50 ( 77.27)\tAcc@2  87.50 ( 94.32)\n","Epoch: [25][20/24]\tTime  0.028 ( 0.056)\tData  0.000 ( 0.025)\tLoss 3.7824e-01 (4.0550e-01)\tAcc@1  87.50 ( 73.81)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.230 ( 0.230)\tLoss 4.5341e-01 (4.5341e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [26][ 0/24]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.8684e-01 (3.8684e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [26][10/24]\tTime  0.042 ( 0.066)\tData  0.009 ( 0.034)\tLoss 4.1307e-01 (3.9211e-01)\tAcc@1  75.00 ( 73.86)\tAcc@2  87.50 ( 94.32)\n","Epoch: [26][20/24]\tTime  0.061 ( 0.055)\tData  0.027 ( 0.024)\tLoss 4.4886e-01 (4.0023e-01)\tAcc@1  62.50 ( 73.81)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.262 ( 0.262)\tLoss 4.5333e-01 (4.5333e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [27][ 0/24]\tTime  0.268 ( 0.268)\tData  0.235 ( 0.235)\tLoss 3.8812e-01 (3.8812e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [27][10/24]\tTime  0.035 ( 0.065)\tData  0.002 ( 0.033)\tLoss 4.2570e-01 (3.8530e-01)\tAcc@1  75.00 ( 77.27)\tAcc@2 100.00 ( 96.59)\n","Epoch: [27][20/24]\tTime  0.028 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.2739e-01 (3.9526e-01)\tAcc@1  50.00 ( 74.40)\tAcc@2  75.00 ( 95.83)\n","Test: [0/4]\tTime  0.244 ( 0.244)\tLoss 4.5314e-01 (4.5314e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [28][ 0/24]\tTime  0.287 ( 0.287)\tData  0.256 ( 0.256)\tLoss 2.8458e-01 (2.8458e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [28][10/24]\tTime  0.038 ( 0.064)\tData  0.002 ( 0.033)\tLoss 4.1372e-01 (3.8785e-01)\tAcc@1  62.50 ( 80.68)\tAcc@2 100.00 ( 94.32)\n","Epoch: [28][20/24]\tTime  0.042 ( 0.054)\tData  0.000 ( 0.022)\tLoss 3.5194e-01 (3.9996e-01)\tAcc@1  87.50 ( 77.38)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.231 ( 0.231)\tLoss 4.5291e-01 (4.5291e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [29][ 0/24]\tTime  0.273 ( 0.273)\tData  0.234 ( 0.234)\tLoss 3.5929e-01 (3.5929e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [29][10/24]\tTime  0.028 ( 0.064)\tData  0.000 ( 0.034)\tLoss 4.0532e-01 (3.8109e-01)\tAcc@1  87.50 ( 79.55)\tAcc@2 100.00 ( 98.86)\n","Epoch: [29][20/24]\tTime  0.034 ( 0.054)\tData  0.000 ( 0.024)\tLoss 4.5649e-01 (3.9663e-01)\tAcc@1  75.00 ( 74.40)\tAcc@2  87.50 ( 96.43)\n","Test: [0/4]\tTime  0.236 ( 0.236)\tLoss 4.5276e-01 (4.5276e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [30][ 0/24]\tTime  0.268 ( 0.268)\tData  0.237 ( 0.237)\tLoss 4.0826e-01 (4.0826e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [30][10/24]\tTime  0.080 ( 0.067)\tData  0.051 ( 0.038)\tLoss 3.6495e-01 (4.0125e-01)\tAcc@1  87.50 ( 71.59)\tAcc@2 100.00 ( 95.45)\n","Epoch: [30][20/24]\tTime  0.040 ( 0.055)\tData  0.011 ( 0.025)\tLoss 3.7666e-01 (3.9796e-01)\tAcc@1  87.50 ( 73.81)\tAcc@2  87.50 ( 96.43)\n","Test: [0/4]\tTime  0.224 ( 0.224)\tLoss 4.5274e-01 (4.5274e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [31][ 0/24]\tTime  0.282 ( 0.282)\tData  0.240 ( 0.240)\tLoss 4.3772e-01 (4.3772e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [31][10/24]\tTime  0.045 ( 0.065)\tData  0.016 ( 0.032)\tLoss 4.0268e-01 (3.9644e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 ( 96.59)\n","Epoch: [31][20/24]\tTime  0.054 ( 0.055)\tData  0.022 ( 0.023)\tLoss 4.6030e-01 (4.0116e-01)\tAcc@1  62.50 ( 75.60)\tAcc@2  87.50 ( 96.43)\n","Test: [0/4]\tTime  0.275 ( 0.275)\tLoss 4.5270e-01 (4.5270e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [32][ 0/24]\tTime  0.279 ( 0.279)\tData  0.243 ( 0.243)\tLoss 4.0219e-01 (4.0219e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [32][10/24]\tTime  0.056 ( 0.064)\tData  0.027 ( 0.034)\tLoss 5.1499e-01 (4.0429e-01)\tAcc@1  37.50 ( 71.59)\tAcc@2  62.50 ( 94.32)\n","Epoch: [32][20/24]\tTime  0.048 ( 0.054)\tData  0.020 ( 0.023)\tLoss 3.8637e-01 (4.0288e-01)\tAcc@1  87.50 ( 73.21)\tAcc@2  87.50 ( 95.83)\n","Test: [0/4]\tTime  0.234 ( 0.234)\tLoss 4.5269e-01 (4.5269e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [33][ 0/24]\tTime  0.243 ( 0.243)\tData  0.211 ( 0.211)\tLoss 3.9659e-01 (3.9659e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [33][10/24]\tTime  0.043 ( 0.063)\tData  0.015 ( 0.033)\tLoss 4.4528e-01 (4.1797e-01)\tAcc@1  75.00 ( 69.32)\tAcc@2  87.50 ( 95.45)\n","Epoch: [33][20/24]\tTime  0.044 ( 0.054)\tData  0.016 ( 0.025)\tLoss 3.4831e-01 (4.0001e-01)\tAcc@1  75.00 ( 72.62)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.247 ( 0.247)\tLoss 4.5269e-01 (4.5269e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [34][ 0/24]\tTime  0.312 ( 0.312)\tData  0.258 ( 0.258)\tLoss 4.8675e-01 (4.8675e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [34][10/24]\tTime  0.045 ( 0.067)\tData  0.017 ( 0.032)\tLoss 4.2652e-01 (4.1707e-01)\tAcc@1  62.50 ( 73.86)\tAcc@2 100.00 ( 94.32)\n","Epoch: [34][20/24]\tTime  0.051 ( 0.055)\tData  0.022 ( 0.024)\tLoss 3.2188e-01 (4.0241e-01)\tAcc@1  75.00 ( 74.40)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.231 ( 0.231)\tLoss 4.5267e-01 (4.5267e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [35][ 0/24]\tTime  0.248 ( 0.248)\tData  0.202 ( 0.202)\tLoss 3.9745e-01 (3.9745e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [35][10/24]\tTime  0.033 ( 0.061)\tData  0.002 ( 0.028)\tLoss 3.5194e-01 (3.8625e-01)\tAcc@1 100.00 ( 75.00)\tAcc@2 100.00 ( 96.59)\n","Epoch: [35][20/24]\tTime  0.049 ( 0.053)\tData  0.018 ( 0.022)\tLoss 3.8048e-01 (3.9516e-01)\tAcc@1  87.50 ( 73.81)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.251 ( 0.251)\tLoss 4.5263e-01 (4.5263e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [36][ 0/24]\tTime  0.299 ( 0.299)\tData  0.237 ( 0.237)\tLoss 3.5232e-01 (3.5232e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [36][10/24]\tTime  0.058 ( 0.065)\tData  0.028 ( 0.033)\tLoss 4.2736e-01 (3.9316e-01)\tAcc@1  62.50 ( 78.41)\tAcc@2 100.00 ( 98.86)\n","Epoch: [36][20/24]\tTime  0.047 ( 0.055)\tData  0.019 ( 0.025)\tLoss 4.1517e-01 (3.9790e-01)\tAcc@1  87.50 ( 74.40)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.218 ( 0.218)\tLoss 4.5262e-01 (4.5262e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [37][ 0/24]\tTime  0.289 ( 0.289)\tData  0.247 ( 0.247)\tLoss 3.9237e-01 (3.9237e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [37][10/24]\tTime  0.054 ( 0.061)\tData  0.026 ( 0.029)\tLoss 4.5349e-01 (4.1210e-01)\tAcc@1  25.00 ( 72.73)\tAcc@2  87.50 ( 95.45)\n","Epoch: [37][20/24]\tTime  0.029 ( 0.054)\tData  0.000 ( 0.023)\tLoss 3.7754e-01 (4.0246e-01)\tAcc@1  75.00 ( 74.40)\tAcc@2 100.00 ( 95.24)\n","Test: [0/4]\tTime  0.241 ( 0.241)\tLoss 4.5260e-01 (4.5260e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [38][ 0/24]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 4.3333e-01 (4.3333e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [38][10/24]\tTime  0.052 ( 0.066)\tData  0.024 ( 0.037)\tLoss 4.5331e-01 (4.0542e-01)\tAcc@1  75.00 ( 80.68)\tAcc@2  87.50 ( 95.45)\n","Epoch: [38][20/24]\tTime  0.064 ( 0.057)\tData  0.031 ( 0.026)\tLoss 4.8386e-01 (4.0429e-01)\tAcc@1  62.50 ( 75.00)\tAcc@2  75.00 ( 94.64)\n","Test: [0/4]\tTime  0.228 ( 0.228)\tLoss 4.5259e-01 (4.5259e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n","Epoch: [39][ 0/24]\tTime  0.264 ( 0.264)\tData  0.227 ( 0.227)\tLoss 3.8958e-01 (3.8958e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [39][10/24]\tTime  0.035 ( 0.065)\tData  0.001 ( 0.033)\tLoss 4.1289e-01 (4.1137e-01)\tAcc@1  62.50 ( 69.32)\tAcc@2 100.00 ( 95.45)\n","Epoch: [39][20/24]\tTime  0.058 ( 0.055)\tData  0.031 ( 0.025)\tLoss 3.2603e-01 (3.9923e-01)\tAcc@1  87.50 ( 72.62)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.258 ( 0.258)\tLoss 4.5256e-01 (4.5256e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 75.000 Acc@2 90.625\n"]}]},{"cell_type":"markdown","source":["### Graphs"],"metadata":{"id":"MHKPbVJO1s_1"}},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'eval'+ eval_suffix + epoch + '/checkpoint.pth.tar')\n","history_df = cpkt['history_df']\n","cpkt['epoch']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHXEg80C1vGt","executionInfo":{"status":"ok","timestamp":1651642125706,"user_tz":420,"elapsed":4612,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"b3386e4e-4f47-47c0-9318-2b2cc8b25331"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":189}]},{"cell_type":"code","source":["_ = history_df[['train_loss', 'val_loss']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"y-U0dMqF2U8d","executionInfo":{"status":"ok","timestamp":1651642126754,"user_tz":420,"elapsed":38,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"c9616ff0-c068-4049-e307-3a4bd27326e6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df[['train_acc1', 'val_acc1']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"bIMKhORT2onL","executionInfo":{"status":"ok","timestamp":1651642127479,"user_tz":420,"elapsed":35,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"dce8dfe2-d274-4d19-ed3a-2896c0b8b96b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df[['train_acc2', 'val_acc2']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"23uLjur22wQM","executionInfo":{"status":"ok","timestamp":1651642127480,"user_tz":420,"elapsed":34,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"84532978-7b44-476e-d1bf-07ec771adf8c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# Test Set"],"metadata":{"id":"CKb0QIw72KxA"}},{"cell_type":"code","source":["test_loader, samples = get_val_loader(\n","    root_path + 'Split_images',\n","    lambda x: labels_df.loc[x].to_numpy(),\n","    2,\n","    test=True)"],"metadata":{"id":"8zABZkLoI-Gd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'eval'+ eval_suffix + epoch + '/model_best.pth.tar')\n","backbone = cpkt['backbone']\n","linear = cpkt['linear']\n","best_epoch = cpkt['epoch']\n","print(cpkt['history_df']['val_acc1'][best_epoch])\n","print(best_epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKcqFCTxDjwW","executionInfo":{"status":"ok","timestamp":1651642127483,"user_tz":420,"elapsed":29,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"3408f721-9b8c-4f8b-c1b7-950d13590f67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["75.0\n","40\n"]}]},{"cell_type":"code","source":["cpkt['history_df']['val_loss']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-gWDDIjYYu-","executionInfo":{"status":"ok","timestamp":1651642127484,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"24ae0705-3def-4c03-85f2-88fbbe8bf374"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1     0.651654\n","2     0.567229\n","3     0.522296\n","4     0.496902\n","5     0.477205\n","6     0.463353\n","7     0.451531\n","8     0.443042\n","9     0.435651\n","10    0.429640\n","11    0.425457\n","12    0.421827\n","13    0.418879\n","14    0.417007\n","15    0.413780\n","16    0.413511\n","17    0.413394\n","18    0.413138\n","19    0.412839\n","20    0.412721\n","21    0.412559\n","22    0.412292\n","23    0.412119\n","24    0.412014\n","25    0.411772\n","26    0.411505\n","27    0.411355\n","28    0.411187\n","29    0.410960\n","30    0.410782\n","31    0.410766\n","32    0.410734\n","33    0.410719\n","34    0.410711\n","35    0.410687\n","36    0.410657\n","37    0.410639\n","38    0.410620\n","39    0.410604\n","40    0.410581\n","Name: val_loss, dtype: float64"]},"metadata":{},"execution_count":195}]},{"cell_type":"code","source":["backbone.eval()\n","linear.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25e8fnGS-ER6","executionInfo":{"status":"ok","timestamp":1651642127485,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"43616c76-a10e-4b4e-e959-7802a7e5c204"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=16, out_features=4, bias=True)\n",")"]},"metadata":{},"execution_count":196}]},{"cell_type":"code","source":["preds, names, labels = None, None, None\n","\n","with torch.no_grad():\n","    for indices, images, labels in test_loader:\n","        preds = linear(backbone(images)).softmax(dim=1).cpu().numpy()\n","        names = np.array([x.split('/')[-1] for x in samples])\n","        labels = labels.numpy()\n","\n","df = pd.DataFrame(index=names)\n","preds = [list(x) for x in preds]\n","labels = [list(x) for x in labels]\n","df['target'] = labels\n","df['pred'] = preds\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"S8tMVLC8fLGY","executionInfo":{"status":"ok","timestamp":1651642128403,"user_tz":420,"elapsed":935,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"e847f663-12a9-4f26-c417-cb114bfd14d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","\n","                                                               pred  \n","Day 14_Y8-4-L.png  [0.020621985, 0.044490885, 0.2857706, 0.6491165]  \n","Day 7_Y8-4-L.png   [0.014222119, 0.08225552, 0.6991152, 0.20440714]  \n","Day 9_A8-1-R.png   [0.26532748, 0.3115717, 0.36659536, 0.056505483]  \n","Day 4_A8-1-R.png   [0.7606834, 0.18555875, 0.016921062, 0.03683677]  \n","Day 12_A8-1-R.png   [0.32857627, 0.13930322, 0.1964611, 0.33565935]  "],"text/html":["\n","  <div id=\"df-6bdf7f42-25eb-489f-ab2f-66cb6c1420b2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.020621985, 0.044490885, 0.2857706, 0.6491165]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.014222119, 0.08225552, 0.6991152, 0.20440714]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.26532748, 0.3115717, 0.36659536, 0.056505483]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.7606834, 0.18555875, 0.016921062, 0.03683677]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.32857627, 0.13930322, 0.1964611, 0.33565935]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bdf7f42-25eb-489f-ab2f-66cb6c1420b2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6bdf7f42-25eb-489f-ab2f-66cb6c1420b2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6bdf7f42-25eb-489f-ab2f-66cb6c1420b2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":197}]},{"cell_type":"code","source":["props = df.index.map(lambda x: re.match('^Day (\\d+)_(Y|A)8-(\\d)-(L|R)', x).groups())\n","df['Day'] = props.map(lambda x: int(x[0]))\n","df['Age'] = props.map(lambda x: x[1])\n","df['Mouse'] = props.map(lambda x: int(x[2]))\n","df['Side'] = props.map(lambda x: x[3])\n","df['True, Pred'] = (df.index.map(lambda x: [np.argmax(df.loc[x]['target']), np.argmax(df.loc[x]['pred'])]))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"id":"nhlvlmmh8xPN","executionInfo":{"status":"ok","timestamp":1651642128409,"user_tz":420,"elapsed":115,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"e18b58c6-364b-4192-d02a-4507cb966fe5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","\n","                                                               pred  Day Age  \\\n","Day 14_Y8-4-L.png  [0.020621985, 0.044490885, 0.2857706, 0.6491165]   14   Y   \n","Day 7_Y8-4-L.png   [0.014222119, 0.08225552, 0.6991152, 0.20440714]    7   Y   \n","Day 9_A8-1-R.png   [0.26532748, 0.3115717, 0.36659536, 0.056505483]    9   A   \n","Day 4_A8-1-R.png   [0.7606834, 0.18555875, 0.016921062, 0.03683677]    4   A   \n","Day 12_A8-1-R.png   [0.32857627, 0.13930322, 0.1964611, 0.33565935]   12   A   \n","\n","                   Mouse Side True, Pred  \n","Day 14_Y8-4-L.png      4    L     [3, 3]  \n","Day 7_Y8-4-L.png       4    L     [3, 2]  \n","Day 9_A8-1-R.png       1    R     [1, 2]  \n","Day 4_A8-1-R.png       1    R     [1, 0]  \n","Day 12_A8-1-R.png      1    R     [2, 3]  "],"text/html":["\n","  <div id=\"df-e3c8cc7b-4872-47f2-a15d-43f79fdcc48a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>Day</th>\n","      <th>Age</th>\n","      <th>Mouse</th>\n","      <th>Side</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.020621985, 0.044490885, 0.2857706, 0.6491165]</td>\n","      <td>14</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.014222119, 0.08225552, 0.6991152, 0.20440714]</td>\n","      <td>7</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","      <td>[3, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.26532748, 0.3115717, 0.36659536, 0.056505483]</td>\n","      <td>9</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.7606834, 0.18555875, 0.016921062, 0.03683677]</td>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.32857627, 0.13930322, 0.1964611, 0.33565935]</td>\n","      <td>12</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3c8cc7b-4872-47f2-a15d-43f79fdcc48a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e3c8cc7b-4872-47f2-a15d-43f79fdcc48a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e3c8cc7b-4872-47f2-a15d-43f79fdcc48a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":198}]},{"cell_type":"code","source":["young_df = df[df.Age == 'Y']\n","young_df.sort_values('Day')[['target', 'pred', 'True, Pred']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"t7gfkMTdFq19","executionInfo":{"status":"ok","timestamp":1651642128410,"user_tz":420,"elapsed":99,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"cbdee271-e119-4683-bbea-95d8cd5c5f97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_Y8-4-L.png                                [1.0, 0.0, 0.0, 0.0]   \n","Day 1_Y8-4-L.png                              [0.57, 0.43, 0.0, 0.0]   \n","Day 2_Y8-4-L.png                                [0.8, 0.2, 0.0, 0.0]   \n","Day 3_Y8-4-L.png                                [0.2, 0.8, 0.0, 0.0]   \n","Day 4_Y8-4-L.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 5_Y8-4-L.png                                [0.3, 0.5, 0.2, 0.0]   \n","Day 6_Y8-4-L.png                                [0.1, 0.3, 0.6, 0.0]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 8_Y8-4-L.png                                [0.0, 0.0, 0.6, 0.4]   \n","Day 9_Y8-4-L.png                                [0.0, 0.0, 0.6, 0.4]   \n","Day 10_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 11_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 12_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 13_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 15_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","\n","                                                                pred  \\\n","Day 0_Y8-4-L.png   [0.88382614, 0.10382155, 0.007956465, 0.004395...   \n","Day 1_Y8-4-L.png   [0.37944108, 0.075507626, 0.041998107, 0.5030532]   \n","Day 2_Y8-4-L.png   [0.57462627, 0.34022322, 0.07021604, 0.014934463]   \n","Day 3_Y8-4-L.png   [0.53562444, 0.34573466, 0.08509322, 0.033547685]   \n","Day 4_Y8-4-L.png   [0.34925234, 0.36240953, 0.26794338, 0.020394694]   \n","Day 5_Y8-4-L.png    [0.06525972, 0.33906868, 0.5708833, 0.024788318]   \n","Day 6_Y8-4-L.png    [0.08213276, 0.25464737, 0.5858849, 0.077334926]   \n","Day 7_Y8-4-L.png    [0.014222119, 0.08225552, 0.6991152, 0.20440714]   \n","Day 8_Y8-4-L.png     [0.035619378, 0.10566258, 0.672331, 0.18638705]   \n","Day 9_Y8-4-L.png    [0.013739447, 0.07032786, 0.6514677, 0.26446494]   \n","Day 10_Y8-4-L.png  [0.009235831, 0.038580097, 0.34419602, 0.60798...   \n","Day 11_Y8-4-L.png  [0.00674088, 0.011253357, 0.025083091, 0.95692...   \n","Day 12_Y8-4-L.png  [0.012455599, 0.028380424, 0.14368033, 0.8154836]   \n","Day 13_Y8-4-L.png  [0.0060287016, 0.017937087, 0.05150066, 0.9245...   \n","Day 14_Y8-4-L.png   [0.020621985, 0.044490885, 0.2857706, 0.6491165]   \n","Day 15_Y8-4-L.png   [0.004971997, 0.022036169, 0.1488364, 0.8241554]   \n","\n","                  True, Pred  \n","Day 0_Y8-4-L.png      [0, 0]  \n","Day 1_Y8-4-L.png      [0, 3]  \n","Day 2_Y8-4-L.png      [0, 0]  \n","Day 3_Y8-4-L.png      [1, 0]  \n","Day 4_Y8-4-L.png      [1, 1]  \n","Day 5_Y8-4-L.png      [1, 2]  \n","Day 6_Y8-4-L.png      [2, 2]  \n","Day 7_Y8-4-L.png      [3, 2]  \n","Day 8_Y8-4-L.png      [2, 2]  \n","Day 9_Y8-4-L.png      [2, 2]  \n","Day 10_Y8-4-L.png     [3, 3]  \n","Day 11_Y8-4-L.png     [3, 3]  \n","Day 12_Y8-4-L.png     [3, 3]  \n","Day 13_Y8-4-L.png     [3, 3]  \n","Day 14_Y8-4-L.png     [3, 3]  \n","Day 15_Y8-4-L.png     [3, 3]  "],"text/html":["\n","  <div id=\"df-b972d75e-f257-477a-9f1a-f39620abe7d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_Y8-4-L.png</th>\n","      <td>[1.0, 0.0, 0.0, 0.0]</td>\n","      <td>[0.88382614, 0.10382155, 0.007956465, 0.004395...</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_Y8-4-L.png</th>\n","      <td>[0.57, 0.43, 0.0, 0.0]</td>\n","      <td>[0.37944108, 0.075507626, 0.041998107, 0.5030532]</td>\n","      <td>[0, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_Y8-4-L.png</th>\n","      <td>[0.8, 0.2, 0.0, 0.0]</td>\n","      <td>[0.57462627, 0.34022322, 0.07021604, 0.014934463]</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_Y8-4-L.png</th>\n","      <td>[0.2, 0.8, 0.0, 0.0]</td>\n","      <td>[0.53562444, 0.34573466, 0.08509322, 0.033547685]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_Y8-4-L.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.34925234, 0.36240953, 0.26794338, 0.020394694]</td>\n","      <td>[1, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_Y8-4-L.png</th>\n","      <td>[0.3, 0.5, 0.2, 0.0]</td>\n","      <td>[0.06525972, 0.33906868, 0.5708833, 0.024788318]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_Y8-4-L.png</th>\n","      <td>[0.1, 0.3, 0.6, 0.0]</td>\n","      <td>[0.08213276, 0.25464737, 0.5858849, 0.077334926]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.014222119, 0.08225552, 0.6991152, 0.20440714]</td>\n","      <td>[3, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.6, 0.4]</td>\n","      <td>[0.035619378, 0.10566258, 0.672331, 0.18638705]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.6, 0.4]</td>\n","      <td>[0.013739447, 0.07032786, 0.6514677, 0.26446494]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[0.009235831, 0.038580097, 0.34419602, 0.60798...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.00674088, 0.011253357, 0.025083091, 0.95692...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[0.012455599, 0.028380424, 0.14368033, 0.8154836]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.0060287016, 0.017937087, 0.05150066, 0.9245...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.020621985, 0.044490885, 0.2857706, 0.6491165]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.004971997, 0.022036169, 0.1488364, 0.8241554]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b972d75e-f257-477a-9f1a-f39620abe7d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b972d75e-f257-477a-9f1a-f39620abe7d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b972d75e-f257-477a-9f1a-f39620abe7d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":199}]},{"cell_type":"code","source":["aged_df = df[df.Age == 'A']\n","aged_df.sort_values('Day')[['target', 'pred', 'True, Pred']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"R9VQDT9nHDUj","executionInfo":{"status":"ok","timestamp":1651642128414,"user_tz":420,"elapsed":100,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"3e5f2a6f-be64-4cbc-c17e-5b9d49be716d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_A8-1-R.png                                [0.9, 0.1, 0.0, 0.0]   \n","Day 1_A8-1-R.png                                [0.1, 0.8, 0.1, 0.0]   \n","Day 2_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 3_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 5_A8-1-R.png                                [0.2, 0.5, 0.3, 0.0]   \n","Day 6_A8-1-R.png                                [0.2, 0.7, 0.1, 0.0]   \n","Day 7_A8-1-R.png                                [0.1, 0.7, 0.1, 0.1]   \n","Day 8_A8-1-R.png                                [0.2, 0.6, 0.2, 0.0]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 10_A8-1-R.png                               [0.1, 0.4, 0.5, 0.0]   \n","Day 11_A8-1-R.png                               [0.0, 0.1, 0.8, 0.1]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","Day 13_A8-1-R.png                               [0.0, 0.1, 0.5, 0.4]   \n","Day 14_A8-1-R.png                               [0.0, 0.1, 0.3, 0.6]   \n","Day 15_A8-1-R.png                               [0.0, 0.1, 0.6, 0.3]   \n","\n","                                                                pred  \\\n","Day 0_A8-1-R.png     [0.5399561, 0.29846445, 0.06391708, 0.09766241]   \n","Day 1_A8-1-R.png   [0.7916739, 0.17597498, 0.018748876, 0.0136023...   \n","Day 2_A8-1-R.png   [0.5490177, 0.32527497, 0.059085824, 0.066621475]   \n","Day 3_A8-1-R.png      [0.7489331, 0.1820135, 0.03515026, 0.03390313]   \n","Day 4_A8-1-R.png    [0.7606834, 0.18555875, 0.016921062, 0.03683677]   \n","Day 5_A8-1-R.png      [0.05774922, 0.203861, 0.16239417, 0.57599556]   \n","Day 6_A8-1-R.png   [0.08646488, 0.25662076, 0.54953533, 0.107379004]   \n","Day 7_A8-1-R.png    [0.12131143, 0.26505777, 0.32414213, 0.28948867]   \n","Day 8_A8-1-R.png    [0.06821161, 0.15828532, 0.7395397, 0.033963438]   \n","Day 9_A8-1-R.png    [0.26532748, 0.3115717, 0.36659536, 0.056505483]   \n","Day 10_A8-1-R.png  [0.053256612, 0.15037107, 0.7028578, 0.093514524]   \n","Day 11_A8-1-R.png  [0.04980811, 0.17986444, 0.70947033, 0.060857143]   \n","Day 12_A8-1-R.png    [0.32857627, 0.13930322, 0.1964611, 0.33565935]   \n","Day 13_A8-1-R.png   [0.017771456, 0.057584055, 0.1803789, 0.7442656]   \n","Day 14_A8-1-R.png      [0.01380091, 0.1096443, 0.3687886, 0.5077662]   \n","Day 15_A8-1-R.png  [0.008611535, 0.022256723, 0.07629161, 0.89284...   \n","\n","                  True, Pred  \n","Day 0_A8-1-R.png      [0, 0]  \n","Day 1_A8-1-R.png      [1, 0]  \n","Day 2_A8-1-R.png      [1, 0]  \n","Day 3_A8-1-R.png      [1, 0]  \n","Day 4_A8-1-R.png      [1, 0]  \n","Day 5_A8-1-R.png      [1, 3]  \n","Day 6_A8-1-R.png      [1, 2]  \n","Day 7_A8-1-R.png      [1, 2]  \n","Day 8_A8-1-R.png      [1, 2]  \n","Day 9_A8-1-R.png      [1, 2]  \n","Day 10_A8-1-R.png     [2, 2]  \n","Day 11_A8-1-R.png     [2, 2]  \n","Day 12_A8-1-R.png     [2, 3]  \n","Day 13_A8-1-R.png     [2, 3]  \n","Day 14_A8-1-R.png     [3, 3]  \n","Day 15_A8-1-R.png     [2, 3]  "],"text/html":["\n","  <div id=\"df-f00e943b-1e35-4e02-a989-0d7cf55dbbb2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_A8-1-R.png</th>\n","      <td>[0.9, 0.1, 0.0, 0.0]</td>\n","      <td>[0.5399561, 0.29846445, 0.06391708, 0.09766241]</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_A8-1-R.png</th>\n","      <td>[0.1, 0.8, 0.1, 0.0]</td>\n","      <td>[0.7916739, 0.17597498, 0.018748876, 0.0136023...</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.5490177, 0.32527497, 0.059085824, 0.066621475]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.7489331, 0.1820135, 0.03515026, 0.03390313]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.7606834, 0.18555875, 0.016921062, 0.03683677]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_A8-1-R.png</th>\n","      <td>[0.2, 0.5, 0.3, 0.0]</td>\n","      <td>[0.05774922, 0.203861, 0.16239417, 0.57599556]</td>\n","      <td>[1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_A8-1-R.png</th>\n","      <td>[0.2, 0.7, 0.1, 0.0]</td>\n","      <td>[0.08646488, 0.25662076, 0.54953533, 0.107379004]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_A8-1-R.png</th>\n","      <td>[0.1, 0.7, 0.1, 0.1]</td>\n","      <td>[0.12131143, 0.26505777, 0.32414213, 0.28948867]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_A8-1-R.png</th>\n","      <td>[0.2, 0.6, 0.2, 0.0]</td>\n","      <td>[0.06821161, 0.15828532, 0.7395397, 0.033963438]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.26532748, 0.3115717, 0.36659536, 0.056505483]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_A8-1-R.png</th>\n","      <td>[0.1, 0.4, 0.5, 0.0]</td>\n","      <td>[0.053256612, 0.15037107, 0.7028578, 0.093514524]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.8, 0.1]</td>\n","      <td>[0.04980811, 0.17986444, 0.70947033, 0.060857143]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.32857627, 0.13930322, 0.1964611, 0.33565935]</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.5, 0.4]</td>\n","      <td>[0.017771456, 0.057584055, 0.1803789, 0.7442656]</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.3, 0.6]</td>\n","      <td>[0.01380091, 0.1096443, 0.3687886, 0.5077662]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.6, 0.3]</td>\n","      <td>[0.008611535, 0.022256723, 0.07629161, 0.89284...</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f00e943b-1e35-4e02-a989-0d7cf55dbbb2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f00e943b-1e35-4e02-a989-0d7cf55dbbb2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f00e943b-1e35-4e02-a989-0d7cf55dbbb2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":200}]},{"cell_type":"code","source":["test_acc = df['True, Pred'].map(lambda x: x[0] == x[1]).to_numpy().mean()\n","test_acc"],"metadata":{"id":"1vlydbcZHgRL","executionInfo":{"status":"ok","timestamp":1651642128414,"user_tz":420,"elapsed":96,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc65594b-f143-4dfa-aad0-3f226cf7fd03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":201}]},{"cell_type":"code","source":[""],"metadata":{"id":"hHOYI19EiGBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Some Cluster Analysis"],"metadata":{"id":"z1r-ZKrKArj2"}},{"cell_type":"code","source":["data_path = root_path + 'Split_images'\n","weights_path = root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + epoch + '.pth'\n","\n","encoder = get_model('resnet', 16, weights_path)\n","train_val_loader, train_samples = get_val_loader(data_path, lambda x: labels_df.loc[x].to_numpy(), 0, train=True)"],"metadata":{"id":"pn2NYH1DaE8b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder.eval()\n","\n","with torch.no_grad():\n","    for indices, images, labels in train_val_loader:\n","        embeddings = encoder(images)\n","\n","        _, fcm = fuzzy_c_means(embeddings, 4)\n","        preds = fcm.soft_predict(embeddings.numpy())\n","        labels = labels.numpy()\n","        x = 4\n"],"metadata":{"id":"BIlbNPTokWFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_preds = preds.argmax(axis=1)\n","single_labels = labels.argmax(axis=1)"],"metadata":{"id":"ImDAchhFqSgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_indices_0 = [i for (i, x) in enumerate(single_preds) if x == 0]\n","pred_indices_1 = [i for (i, x) in enumerate(single_preds) if x == 1]\n","pred_indices_2 = [i for (i, x) in enumerate(single_preds) if x == 2]\n","pred_indices_3 = [i for (i, x) in enumerate(single_preds) if x == 3]"],"metadata":{"id":"rTOobcZirIj3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(stats.mode(single_labels[pred_indices_0])[0][0])\n","print(stats.mode(single_labels[pred_indices_1])[0][0])\n","print(stats.mode(single_labels[pred_indices_2])[0][0])\n","print(stats.mode(single_labels[pred_indices_3])[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"804Y7tU3sNp_","executionInfo":{"status":"ok","timestamp":1651646066841,"user_tz":420,"elapsed":405,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"b69976d9-7dcd-49bf-d1d0-21ebe7d33df8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","2\n","2\n","3\n"]}]},{"cell_type":"code","source":["single_labels[pred_indices_1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDFh9Lb6sxZX","executionInfo":{"status":"ok","timestamp":1651646086744,"user_tz":420,"elapsed":395,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"0ee2fe93-7513-4509-f145-7290fefd45cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n","       2, 2, 3, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":277}]},{"cell_type":"code","source":["single_labels[pred_indices_2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQiam4hquTAz","executionInfo":{"status":"ok","timestamp":1651646087219,"user_tz":420,"elapsed":5,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"63b3b399-6fde-4be5-fbbf-81ccd1ae8e06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 2, 2, 3, 2, 0, 2, 1, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 1, 2, 0,\n","       2, 1, 2, 2, 2, 1, 1, 0, 2, 2, 0, 3, 2, 2, 2])"]},"metadata":{},"execution_count":278}]},{"cell_type":"code","source":["m = {0:0, 1:2, 2:1, 3:3}\n","preds = np.array([[p[m[0]], p[m[1]], p[m[2]], p[m[3]]] for p in preds])"],"metadata":{"id":"uGydNTeWucNe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_preds = preds.argmax(axis=1)"],"metadata":{"id":"x0chNz7cwHy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = (single_preds == single_labels).mean()\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_6a2nW-wI88","executionInfo":{"status":"ok","timestamp":1651646127226,"user_tz":420,"elapsed":3,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"e6c9d946-d7f4-4ff0-bd02-a1591de15d91"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5706806282722513"]},"metadata":{},"execution_count":281}]},{"cell_type":"code","source":[""],"metadata":{"id":"GMlaoULDxKPX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# KNN Evaluation"],"metadata":{"id":"a7Wgnq2pySgP"}},{"cell_type":"markdown","source":["### Misc Functions"],"metadata":{"id":"dlJFZPYmzNQT"}},{"cell_type":"code","source":["def l2_normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)"],"metadata":{"id":"cmvGyL_GyVGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def log(string, file):\n","    print(string)\n","    file.write(string + '\\n')"],"metadata":{"id":"UKLUR-fYR_aw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def faiss_knn(feats_train, targets_train, feats_val, targets_val, k):\n","    feats_train = feats_train.numpy()\n","    targets_train = targets_train.numpy()\n","    feats_val = feats_val.numpy()\n","    targets_val = targets_val.numpy()\n","\n","    d = feats_train.shape[-1]\n","\n","    index = faiss.IndexFlatL2(d)  # build the index\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    gpu_index = faiss.index_cpu_to_all_gpus(index, co)\n","    gpu_index.add(feats_train)\n","\n","    D, I = gpu_index.search(feats_val, k)\n","\n","    pred = np.zeros(I.shape[0], dtype=np.int)\n","    conf_mat = np.zeros((1000, 1000), dtype=np.int)\n","    for i in range(I.shape[0]):\n","        votes = list(Counter(targets_train[I[i]]).items())\n","        shuffle(votes)\n","        pred[i] = max(votes, key=lambda x: x[1])[0]\n","        conf_mat[targets_val[i], pred[i]] += 1\n","\n","    acc = 100.0 * (pred == targets_val).mean()\n","    assert acc == (100.0 * (np.trace(conf_mat) / np.sum(conf_mat)))\n","\n","    # per_cat_acc = 100.0 * (np.diag(conf_mat) / np.sum(conf_mat, axis=1))\n","    # sparse_cats = [58, 155, 356, 747, 865, 234, 268, 384, 385, 491, 498, 538, 646, 650, 726, 860, 887, 15, 170, 231]\n","    # s = ' '.join('{}'.format(c) for c in sparse_cats)\n","    # print('==> cats: {}'.format(s))\n","    # s = ' '.join('{:.1f}'.format(a) for a in per_cat_acc[sparse_cats])\n","    # print('==> acc/cat: {}'.format(s))\n","    # print('==> mean acc: {}'.format(per_cat_acc[sparse_cats].mean()))\n","\n","    return acc"],"metadata":{"id":"EQI68Ji_zc2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_feats(loader, model, print_freq):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, indices, ptr = None, None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (index, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = model(images).cpu()\n","            cur_indices = index.cpu()\n","\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","                indices = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets)\n","            indices.index_copy_(0, inds, cur_indices)\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","    return feats, labels, indices"],"metadata":{"id":"lWa_4FlEzsjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def subset_classes(dataset, num_classes=10):\n","    np.random.seed(1234)\n","    all_classes = sorted(dataset.class_to_idx.items(), key=lambda x: x[1])\n","    subset_classes = [all_classes[i] for i in np.random.permutation(len(all_classes))[:num_classes]]\n","    subset_classes = sorted(subset_classes, key=lambda x: x[1])\n","    dataset.classes_to_idx = {c: i for i, (c, _) in enumerate(subset_classes)}\n","    dataset.classes = [c for c, _ in subset_classes]\n","    orig_to_new_inds = {orig_ind: new_ind for new_ind, (_, orig_ind) in enumerate(subset_classes)}\n","    dataset.samples = [(p, orig_to_new_inds[i]) for p, i in dataset.samples if i in orig_to_new_inds]"],"metadata":{"id":"q3Th4r2zzwCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main Function"],"metadata":{"id":"qZWaHcM6z1gg"}},{"cell_type":"code","source":["def main_worker(arch, output_dim, data_path, wts_path, output_path, batch_size, \n","                label_fn, num_workers=2, print_freq=10):\n","\n","    start = time.time()\n","    # Get train/val loader \n","    # ---------------------------------------------------------------\n","    train_loader, _ = get_val_loader(data_path, label_fn, num_workers, batch_size, train=True)\n","    val_loader, _   = get_val_loader(data_path, label_fn, num_workers, batch_size)\n","    test_loader, _  = get_val_loader(data_path, label_fn, num_workers, batch_size, test=True)\n","\n","    # Create and load the model\n","    # If you want to evaluate your model, modify this part and load your model\n","    # ------------------------------------------------------------------------\n","    # MODIFY 'get_model' TO EVALUATE YOUR MODEL\n","    model = get_model(arch, output_dim, wts_path).cuda()\n","\n","    # ------------------------------------------------------------------------\n","    # Forward training samples throw the model and cache feats\n","    # ------------------------------------------------------------------------\n","    cudnn.benchmark = True\n","\n","    train_feats, train_labels, train_inds = get_feats(train_loader, model, print_freq)\n","\n","    val_feats, val_labels, val_inds = get_feats(val_loader, model, print_freq)\n","\n","    test_feats, test_labels, test_inds = get_feats(test_loader, model, print_freq)\n","\n","    # ------------------------------------------------------------------------\n","    # Calculate NN accuracy on validation set\n","    # ------------------------------------------------------------------------\n","\n","    # train_feats = l2_normalize(train_feats)\n","    # val_feats = l2_normalize(val_feats)\n","\n","    # mean = torch.mean(train_feats, dim=0)\n","    # std = torch.std(train_feats, dim=0)\n","\n","    # stdmean = std.mean()\n","    # train_feats = train_feats / stdmean\n","    # val_feats = val_feats / stdmean\n","\n","    # train_feats = train_feats / std\n","    # val_feats = val_feats / std\n","\n","    # train_feats = (train_feats - mean) / std\n","    # val_feats = (val_feats - mean) / std\n","\n","    # train_feats = train_feats - mean\n","    # val_feats = val_feats - mean\n","\n","    # train_feats = train_feats / TEMP\n","    # val_feats = val_feats / TEMP\n","\n","    train_feats = l2_normalize(train_feats)\n","    val_feats = l2_normalize(val_feats)\n","    test_feats = l2_normalize(test_feats)\n","\n","    output = open(output_path, 'w')\n","\n","    for k in range(1,21):\n","        log(f'k: {k}', output)\n","        val_acc  = faiss_knn(train_feats, train_labels, val_feats, val_labels, k)\n","        test_acc = faiss_knn(train_feats, train_labels, test_feats, test_labels, k)\n","        nn_time = time.time() - start\n","        log('=> time : {:.2f}s'.format(nn_time), output)\n","        log(' * Val_Acc {:.2f}'.format(val_acc), output)\n","        log(' * Test_Acc {:.2f}'.format(test_acc), output)\n","\n","    output.close()"],"metadata":{"id":"4mWQSYGXz3v1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"Iw2uh2AJzR-l"}},{"cell_type":"code","source":["main_worker(arch='resnet', \n","            output_dim=16, \n","            data_path=root_path + 'Split_images', \n","            wts_path=root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + epoch + '.pth', \n","            output_path=root_path + 'outputs/' + train_folder_name + 'eval' + eval_suffix + 'knn_' + epoch, \n","            batch_size=8, \n","            label_fn=lambda x: labels_map[x], \n","            num_workers=2, \n","            print_freq=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmWFCVGxzTqg","executionInfo":{"status":"ok","timestamp":1651655216509,"user_tz":420,"elapsed":14825,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"61e275d7-8b44-4745-adbd-2d78b812bab0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test: [ 0/24]\tTime  0.210 ( 0.210)\n","Test: [10/24]\tTime  0.055 ( 0.059)\n","Test: [20/24]\tTime  0.069 ( 0.055)\n","Test: [0/4]\tTime  0.215 ( 0.215)\n","Test: [0/4]\tTime  0.210 ( 0.210)\n","k: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]},{"output_type":"stream","name":"stdout","text":["=> time : 3.32s\n"," * Val_Acc 71.88\n"," * Test_Acc 81.25\n","k: 2\n","=> time : 3.94s\n"," * Val_Acc 65.62\n"," * Test_Acc 81.25\n","k: 3\n","=> time : 4.54s\n"," * Val_Acc 68.75\n"," * Test_Acc 68.75\n","k: 4\n","=> time : 5.13s\n"," * Val_Acc 68.75\n"," * Test_Acc 65.62\n","k: 5\n","=> time : 5.74s\n"," * Val_Acc 68.75\n"," * Test_Acc 65.62\n","k: 6\n","=> time : 6.35s\n"," * Val_Acc 68.75\n"," * Test_Acc 62.50\n","k: 7\n","=> time : 6.94s\n"," * Val_Acc 65.62\n"," * Test_Acc 53.12\n","k: 8\n","=> time : 7.55s\n"," * Val_Acc 65.62\n"," * Test_Acc 56.25\n","k: 9\n","=> time : 8.16s\n"," * Val_Acc 62.50\n"," * Test_Acc 56.25\n","k: 10\n","=> time : 8.76s\n"," * Val_Acc 68.75\n"," * Test_Acc 56.25\n","k: 11\n","=> time : 9.37s\n"," * Val_Acc 62.50\n"," * Test_Acc 56.25\n","k: 12\n","=> time : 9.96s\n"," * Val_Acc 65.62\n"," * Test_Acc 56.25\n","k: 13\n","=> time : 10.56s\n"," * Val_Acc 65.62\n"," * Test_Acc 53.12\n","k: 14\n","=> time : 11.17s\n"," * Val_Acc 65.62\n"," * Test_Acc 59.38\n","k: 15\n","=> time : 11.78s\n"," * Val_Acc 68.75\n"," * Test_Acc 59.38\n","k: 16\n","=> time : 12.39s\n"," * Val_Acc 65.62\n"," * Test_Acc 59.38\n","k: 17\n","=> time : 12.98s\n"," * Val_Acc 65.62\n"," * Test_Acc 56.25\n","k: 18\n","=> time : 13.58s\n"," * Val_Acc 65.62\n"," * Test_Acc 59.38\n","k: 19\n","=> time : 14.18s\n"," * Val_Acc 65.62\n"," * Test_Acc 53.12\n","k: 20\n","=> time : 14.78s\n"," * Val_Acc 59.38\n"," * Test_Acc 53.12\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0j-ob7dW5XJt"},"execution_count":null,"outputs":[]}]}