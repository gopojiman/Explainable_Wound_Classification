{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Supervised CMSF.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"fvTEIA7dC0y6"}},{"cell_type":"code","source":["#GPU runtime required, should give CUDA version\n","!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESeaDdP1QIzR","executionInfo":{"status":"ok","timestamp":1651691880602,"user_tz":420,"elapsed":327,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"49bde594-d5be-462f-926f-674ad58c4ff9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8daw-VRZBPmg","executionInfo":{"status":"ok","timestamp":1651691911704,"user_tz":420,"elapsed":30652,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"2e6f10d2-6345-479f-8961-254a5270417c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import builtins\n","import os\n","import sys\n","import time\n","import argparse\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torchvision import transforms, datasets, models\n","\n","from PIL import Image, ImageFilter\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","import re\n","from scipy import stats\n","\n","import shutil\n","import warnings\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","from collections import Counter, OrderedDict\n","from random import shuffle"],"metadata":{"id":"Hjz-nv7SCl0E","executionInfo":{"status":"ok","timestamp":1651691914823,"user_tz":420,"elapsed":3132,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["root_path = 'gdrive/MyDrive/Explainable_Wound_Classification/'"],"metadata":{"id":"5oXyo5yPOJxX","executionInfo":{"status":"ok","timestamp":1651691915345,"user_tz":420,"elapsed":528,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Supervised CMSF"],"metadata":{"id":"mjLmuIrIDV8l"}},{"cell_type":"markdown","source":["### Misc Functions"],"metadata":{"id":"CbvsjPM4F402"}},{"cell_type":"code","source":["def set_parameter_requires_grad(model):\n","    for param in model.parameters():\n","        param.requires_grad = False"],"metadata":{"id":"4ArBwU5AD7RC","executionInfo":{"status":"ok","timestamp":1651692750358,"user_tz":420,"elapsed":341,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["def get_mlp(inp_dim, hidden_dim, out_dim):\n","    mlp = nn.Sequential(\n","        nn.Linear(inp_dim, hidden_dim),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.ReLU(inplace=True),\n","        nn.Linear(hidden_dim, out_dim),\n","    )\n","    return mlp"],"metadata":{"id":"Vs25Cpt3E2JT","executionInfo":{"status":"ok","timestamp":1651692750652,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def get_shuffle_ids(bsz):\n","    \"\"\"generate shuffle ids for ShuffleBN\"\"\"\n","    forward_inds = torch.randperm(bsz).long().cuda()\n","    backward_inds = torch.zeros(bsz).long().cuda()\n","    value = torch.arange(bsz).long().cuda()\n","    backward_inds.index_copy_(0, forward_inds, value)\n","    return forward_inds, backward_inds"],"metadata":{"id":"wqAZJ455FRCh","executionInfo":{"status":"ok","timestamp":1651692750942,"user_tz":420,"elapsed":302,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["def adjust_learning_rate(epoch, optimizer, cos, learning_rate, epochs, lr_decay_epochs, lr_decay_rate):\n","    if cos:\n","        # NOTE: since epoch starts with 1, we have to subtract 1\n","        new_lr = learning_rate * 0.5 * (1. + math.cos(math.pi * (epoch-1) / epochs))\n","        print('LR: {}'.format(new_lr))\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = new_lr\n","    else:\n","        steps = np.sum(epoch >= np.asarray(lr_decay_epochs))\n","        if steps > 0:\n","            new_lr = learning_rate * (lr_decay_rate ** steps)\n","            print('LR: {}'.format(new_lr))\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = new_lr"],"metadata":{"id":"4g64T7MELa8W","executionInfo":{"status":"ok","timestamp":1651692750943,"user_tz":420,"elapsed":20,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"Xwdn5YTmMMUz","executionInfo":{"status":"ok","timestamp":1651692750943,"user_tz":420,"elapsed":18,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":["### Transforms/Data Loading"],"metadata":{"id":"1vpiooZfF7nA"}},{"cell_type":"code","source":["class Image_Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, root_dir, label_fn, transform=None):\n","        \"\"\"\n","        Image dataset. Returns tensorized images and labels with index\n","        Args:\n","            root_dir: path to a cropped mouse image dataset.\n","            label_fn: function that returns the correct label given an image name\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.label_fn = label_fn\n","        self.transform = transform\n","\n","        samples = []\n","        targets = []\n","        for f in os.listdir(root_dir):\n","            samples.append(os.path.join(root_dir, f))\n","            targets.append(label_fn(f))\n","        \n","        self.samples = samples\n","        self.targets = targets\n","\n","    def pil_loader(self, path):\n","        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n","        with open(path, 'rb') as f:\n","            img = Image.open(f)\n","            return img.convert('RGB')\n","\n","    def __getitem__(self, index: int):\n","            \"\"\"\n","            Returns index, tensor data, and tensorized label.\n","            \"\"\"\n","            img = self.pil_loader(self.samples[index])\n","            target = self.targets[index]\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return index, img, torch.tensor(target)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __str__(self):\n","        return \"Image_Dataset:\\n\" + \"Found \" + str(len(self)) + \" images in \" + self.root_dir + \"\\n\""],"metadata":{"id":"MJ7GdkQDCwlC","executionInfo":{"status":"ok","timestamp":1651692750943,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["class TwoCropsTransform:\n","    \"\"\"Take two random crops of one image as the query and target.\"\"\"\n","    def __init__(self, weak_transform, strong_transform):\n","        self.weak_transform = weak_transform\n","        self.strong_transform = strong_transform\n","        print(self.weak_transform)\n","        print(self.strong_transform)\n","\n","    def __call__(self, x):\n","        q = self.strong_transform(x)\n","        t = self.weak_transform(x)\n","        return [q, t]"],"metadata":{"id":"6R_odswKGEce","executionInfo":{"status":"ok","timestamp":1651692750944,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["# Create train loader\n","def get_train_loader(datapath, label_fn, batch_size, num_workers, weak_strong=True):\n","    traindir = os.path.join(datapath, 'train')\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","\n","    augmentation_strong = [\n","        transforms.Resize(224),\n","        transforms.ColorJitter(saturation=(0,1)),\n","        transforms.RandomRotation((0, 360)),\n","        transforms.RandomAffine((0,0), translate=(0.3, 0.3)),\n","        transforms.ToTensor(),\n","        normalize\n","    ]\n","\n","    augmentation_weak = [\n","        transforms.Resize(224),\n","        transforms.RandomRotation((0, 360)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]\n","\n","    if weak_strong:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_strong))\n","        )\n","    else:\n","        train_dataset = Image_Dataset(\n","            traindir, label_fn, \n","            TwoCropsTransform(transforms.Compose(augmentation_weak), transforms.Compose(augmentation_weak))\n","        )\n","\n","    print('==> train dataset')\n","    print(train_dataset)\n","\n","    # NOTE: remove drop_last\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, shuffle=True,\n","        num_workers=num_workers, pin_memory=True, drop_last=True)\n","\n","    return train_loader"],"metadata":{"id":"3B29JfGLGGHW","executionInfo":{"status":"ok","timestamp":1651692750945,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def get_val_loader(datapath, label_fn, num_workers, batch_size=-1, test=False, train=False):\n","    if test:\n","        valdir = os.path.join(datapath, 'test')\n","    elif train:\n","        valdir = os.path.join(datapath, 'train')\n","    else:\n","        valdir = os.path.join(datapath, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    val_transform = transforms.Compose([\n","        #transforms.Resize(256),\n","        #transforms.CenterCrop(224),\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    dataset = Image_Dataset(valdir, label_fn, val_transform)\n","\n","    if batch_size == -1:\n","        batch_size = len(dataset)\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False,\n","        num_workers=num_workers, pin_memory=True,\n","    )\n","    return val_loader, dataset.samples"],"metadata":{"id":"VU99AaukZbBq","executionInfo":{"status":"ok","timestamp":1651692750946,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":["### Model Architecture"],"metadata":{"id":"PkRnootKF_fr"}},{"cell_type":"code","source":["def initialize_encoder(model_name, output_dim, use_pretrained=True):\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, output_dim)\n","        input_size = 224\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size"],"metadata":{"id":"jNaKSk02DtOx","executionInfo":{"status":"ok","timestamp":1651692750947,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["class MeanShift(nn.Module):\n","    def __init__(self, arch, m=0.99, mem_bank_size=128000, topk=5, output_dim=16):\n","        super(MeanShift, self).__init__()\n","\n","        # save parameters\n","        self.m = m\n","        self.mem_bank_size = mem_bank_size\n","        self.topk = topk\n","\n","        # create encoders and projection layers\n","        # both encoders should have same arch\n","        if 'resnet' in arch:\n","            self.encoder_q = initialize_encoder(arch, output_dim)[0]\n","            self.encoder_t = initialize_encoder(arch, output_dim)[0]\n","\n","        # prediction layer\n","        self.predict_q = get_mlp(output_dim, output_dim * 2, output_dim)\n","\n","        # copy query encoder weights to target encoder\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data.copy_(param_q.data)\n","            param_t.requires_grad = False\n","\n","        print(\"using mem-bank size {}\".format(self.mem_bank_size))\n","        # setup queue (For Storing Random Targets)\n","        self.register_buffer('queue', torch.randn(self.mem_bank_size, output_dim))\n","        # normalize the queue embeddings\n","        self.queue = nn.functional.normalize(self.queue, dim=1)\n","        # initialize the labels queue (For Purity measurement)\n","        self.register_buffer('labels', -1*torch.ones(self.mem_bank_size).long())\n","        # setup the queue pointer\n","        self.register_buffer('queue_ptr', torch.zeros(1, dtype=torch.long))\n","\n","    @torch.no_grad()\n","    def _momentum_update_target_encoder(self):\n","        for param_q, param_t in zip(self.encoder_q.parameters(), self.encoder_t.parameters()):\n","            param_t.data = param_t.data * self.m + param_q.data * (1. - self.m)\n","\n","    @torch.no_grad()\n","    def data_parallel(self):\n","        self.encoder_q = torch.nn.DataParallel(self.encoder_q)\n","        self.encoder_t = torch.nn.DataParallel(self.encoder_t)\n","        self.predict_q = torch.nn.DataParallel(self.predict_q)\n","\n","    @torch.no_grad()\n","    def _dequeue_and_enqueue(self, targets, labels):\n","        batch_size = targets.shape[0]\n","\n","        ptr = int(self.queue_ptr)\n","        assert self.mem_bank_size % batch_size == 0 \n","\n","        # replace the targets at ptr (dequeue and enqueue)\n","        self.queue[ptr:ptr + batch_size] = targets\n","        self.labels[ptr:ptr + batch_size] = labels\n","        ptr = (ptr + batch_size) % self.mem_bank_size  # move pointer\n","\n","        self.queue_ptr[0] = ptr\n","\n","    def forward(self, im_q, im_t, labels):\n","        # compute query features\n","        feat_q = self.encoder_q(im_q)\n","        # compute predictions for instance level regression loss\n","        query = self.predict_q(feat_q)\n","        query = nn.functional.normalize(query, dim=1)\n","\n","        # compute target features\n","        with torch.no_grad():\n","            # update the target encoder\n","            self._momentum_update_target_encoder()\n","\n","            # shuffle targets\n","            shuffle_ids, reverse_ids = get_shuffle_ids(im_t.shape[0])\n","            im_t = im_t[shuffle_ids]\n","\n","            # forward through the target encoder\n","            current_target = self.encoder_t(im_t)\n","            current_target = nn.functional.normalize(current_target, dim=1)\n","\n","            # undo shuffle\n","            current_target = current_target[reverse_ids].detach()\n","            self._dequeue_and_enqueue(current_target, labels)\n","\n","        Q = query\n","        K = current_target\n","        M = self.queue.clone().detach()\n","\n","        Lx = labels\n","        Lm = self.labels.clone().detach()\n","\n","        b = Q.shape[0]\n","        m = M.shape[0]\n","        k = self.topk\n","\n","        # 1. reshape labels to have same size\n","        Lx1 = Lx.unsqueeze(1).expand((b, m))\n","        Lm1 = Lm.unsqueeze(0).expand((b, m))\n","        Msk = Lx1 != Lm1\n","\n","        # 2. calculate distances\n","        Dk = 2 - 2 * (K @ M.T)\n","        Dq = 2 - 2 * (Q @ M.T)\n","\n","        # 3. set non category distances to 5 (max distance)\n","        Dk[torch.where(Msk)] = 5.0\n","\n","        # 4. select indices of topk distances from Dk\n","        _, iNDk = Dk.topk(k, dim=1, largest=False)\n","\n","        # 5. using above indices, gather the distances from Dq\n","        NDq = torch.gather(Dq, 1, iNDk)\n","\n","        # 6. first, average over k, and then average over b\n","        L = NDq.mean(dim=1).mean()\n","        P = torch.gather(Lx1 == Lm1, 1, iNDk)\n","        purity = 100 * (torch.count_nonzero(P, dim=1) / k).mean()\n","\n","        return L, purity"],"metadata":{"id":"RK7_69iHDYD5","executionInfo":{"status":"ok","timestamp":1651692751641,"user_tz":420,"elapsed":709,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"R0W1IrT2G_y3"}},{"cell_type":"code","source":["def train(epoch, train_loader, mean_shift, optimizer, print_freq):\n","    \"\"\"\n","    one epoch training \n","    \"\"\"\n","    mean_shift.train()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    loss_meter = AverageMeter()\n","    purity_meter = AverageMeter()\n","\n","    end = time.time()\n","    for idx, (indices, (im_q, im_t), labels) in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","        im_q = im_q.cuda(non_blocking=True)\n","        im_t = im_t.cuda(non_blocking=True)\n","        labels = labels.cuda(non_blocking=True)\n","\n","        # ===================forward=====================\n","        loss, purity = mean_shift(im_q=im_q, im_t=im_t, labels=labels)\n","\n","        # ===================backward=====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ===================meters=====================\n","        loss_meter.update(loss.item(), im_q.size(0))\n","        purity_meter.update(purity.item(), im_q.size(0))\n","\n","        torch.cuda.synchronize()\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        # print info\n","        if (idx + 1) % print_freq == 0:\n","            print('Train: [{0}][{1}/{2}]\\t'\n","                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n","                  'purity {purity.val:.3f} ({purity.avg:.3f})\\t'.format(\n","                   epoch, idx + 1, len(train_loader),\n","                   batch_time=batch_time,\n","                   data_time=data_time,\n","                   purity=purity_meter,\n","                   loss=loss_meter))\n","            sys.stdout.flush()\n","            sys.stdout.flush()\n","\n","    return loss_meter.avg, purity_meter.avg"],"metadata":{"id":"Qtqx_T5HHCYA","executionInfo":{"status":"ok","timestamp":1651692751641,"user_tz":420,"elapsed":41,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["def cmsf_main(data_path, checkpoint_path, label_fn, batch_size=16, num_workers=2, \n","              epochs=200, print_freq=10, save_freq=10, weak_strong=True, \n","              debug=False, arch='resnet', momentum=0.99, mem_bank_size=128000, \n","              topk=5, learning_rate=0.05, sgd_momentum=0.9, weight_decay=1e-4, \n","              weights=None, resume=None, restart=False, cos=True, lr_decay_rate=0.2, \n","              lr_decay_epochs=[90,120], output_dim=16):\n","    opt = locals()\n","    del opt['label_fn']\n","    print(opt)\n","\n","    os.makedirs(checkpoint_path, exist_ok=True)\n","\n","    train_loader = get_train_loader(data_path, label_fn, batch_size, num_workers, weak_strong)\n","\n","    mean_shift = MeanShift(\n","        arch,\n","        m=momentum,\n","        mem_bank_size=mem_bank_size,\n","        topk=topk,\n","        output_dim=output_dim\n","    )\n","    mean_shift.data_parallel()\n","    mean_shift = mean_shift.cuda()\n","    print(mean_shift)\n","\n","    print(\"Params to learn:\")\n","    for name,param in mean_shift.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","    params = [p for p in mean_shift.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params,\n","                                lr=learning_rate,\n","                                momentum=sgd_momentum,\n","                                weight_decay=weight_decay)\n","\n","    cudnn.benchmark = True\n","    start_epoch = 1\n","\n","    history_df = pd.DataFrame(index=range(start_epoch, epochs + 1))\n","\n","    if weights:\n","        print('==> load weights from checkpoint: {}'.format(weights))\n","        ckpt = torch.load(weights)\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        if 'model' in ckpt:\n","            sd = ckpt['model']\n","        else:\n","            sd = ckpt['state_dict']\n","        msg = mean_shift.load_state_dict(sd, strict=False)\n","        optimizer.load_state_dict(ckpt['optimizer'])\n","        start_epoch = ckpt['epoch'] + 1\n","        history_df = ckpt['history_df']\n","        print(msg)\n","\n","    if resume:\n","        print('==> resume from checkpoint: {}'.format(resume))\n","        ckpt = torch.load(resume)\n","        print('==> resume from epoch: {}'.format(ckpt['epoch']))\n","        mean_shift.load_state_dict(ckpt['state_dict'], strict=True)\n","        if not restart:\n","            optimizer.load_state_dict(ckpt['optimizer'])\n","            start_epoch = ckpt['epoch'] + 1\n","            history_df = ckpt['history_df']\n","\n","    # routine\n","    for epoch in range(start_epoch, epochs + 1):\n","\n","        adjust_learning_rate(epoch=epoch,\n","                             optimizer=optimizer,\n","                             cos=cos,\n","                             learning_rate=learning_rate,\n","                             epochs=epochs,\n","                             lr_decay_epochs=lr_decay_epochs,\n","                             lr_decay_rate=lr_decay_rate)\n","        print(\"==> training...\")\n","\n","        time1 = time.time()\n","        loss, purity = train(epoch, train_loader, mean_shift, optimizer, print_freq)\n","\n","        time2 = time.time()\n","        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n","\n","        history_df.loc[epoch, 'loss'] = loss\n","        history_df.loc[epoch, 'purity'] = purity\n","\n","        # saving the model\n","        if epoch % save_freq == 0:\n","            print('==> Saving...')\n","            state = {\n","                'opt': opt,\n","                'state_dict': mean_shift.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epoch,\n","                'history_df': history_df\n","            }\n","\n","            save_file = os.path.join(checkpoint_path, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n","            torch.save(state, save_file)\n","\n","            # help release GPU memory\n","            del state\n","            torch.cuda.empty_cache()"],"metadata":{"id":"JmDJrTdqHuE3","executionInfo":{"status":"ok","timestamp":1651692751644,"user_tz":420,"elapsed":40,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5OXl_tTfN8kO","executionInfo":{"status":"ok","timestamp":1651692751645,"user_tz":420,"elapsed":39,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":["### Getting Label Assignments"],"metadata":{"id":"5yp7qblbkJ9J"}},{"cell_type":"code","source":["labels_df = pd.read_csv(root_path + 'Updated_Cropped_Images_Wound_Stage_Probabilities.csv', index_col='Image')\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"4pQa0ql3kI6v","executionInfo":{"status":"ok","timestamp":1651692751645,"user_tz":420,"elapsed":38,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"0990b249-702d-4b75-c8e0-a982e42d8031"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation\n","Image                                                                 \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000"],"text/html":["\n","  <div id=\"df-71b3a5ba-9311-413b-b653-0fbc4698bd93\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b3a5ba-9311-413b-b653-0fbc4698bd93')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-71b3a5ba-9311-413b-b653-0fbc4698bd93 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-71b3a5ba-9311-413b-b653-0fbc4698bd93');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["labels_df['label'] = labels_df.index.map(lambda x: labels_df.loc[x].argmax())\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"hvuzz2tgktSO","executionInfo":{"status":"ok","timestamp":1651692751646,"user_tz":420,"elapsed":33,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"853541c6-0dcc-48a2-a79e-66077231d116"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation  label\n","Image                                                                        \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818      2\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000      1\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091      3\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455      3\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000      1"],"text/html":["\n","  <div id=\"df-3a71dea6-ab98-46b8-9f8c-5772148da6e4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a71dea6-ab98-46b8-9f8c-5772148da6e4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a71dea6-ab98-46b8-9f8c-5772148da6e4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a71dea6-ab98-46b8-9f8c-5772148da6e4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["labels_map = labels_df['label']\n","labels_map.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UZrhjs_l7Bz","executionInfo":{"status":"ok","timestamp":1651692751647,"user_tz":420,"elapsed":30,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"5a7cc235-3912-4b7f-909d-13ff862752de"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Image\n","Day 8_A8-4-L.png     2\n","Day 4_A8-3-R.png     1\n","Day 14_Y8-4-L.png    3\n","Day 7_Y8-4-L.png     3\n","Day 2_A8-1-L.png     1\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","source":["### Folder to store outputs and number of epochs to run"],"metadata":{"id":"ChoSMs3wRIHO"}},{"cell_type":"code","source":["train_folder_name = 'supervised/2_topk5/'\n","epochs = 200"],"metadata":{"id":"22JGUWI8QWej","executionInfo":{"status":"ok","timestamp":1651692773803,"user_tz":420,"elapsed":414,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":["# Supervised CMSF Training"],"metadata":{"id":"F6xiA0D4O-BB"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"4om4mdoQrErk"}},{"cell_type":"code","source":["cmsf_main(\n","    data_path=root_path + 'Split_images', \n","    checkpoint_path=root_path + 'outputs/' + train_folder_name, \n","    label_fn=lambda x: labels_map[x],\n","    batch_size=8,\n","    num_workers=2,\n","    epochs=epochs,\n","    arch='resnet',\n","    topk=5,\n","    learning_rate=0.05,\n","    cos=True,\n","    mem_bank_size=128000,\n","    weak_strong=True,\n","    output_dim=16,\n","    debug=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udb2Oop0jJ7y","outputId":"84851d69-83d0-4802-96ac-e5ee6a4b9c1a","executionInfo":{"status":"ok","timestamp":1651693243176,"user_tz":420,"elapsed":449306,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_path': 'gdrive/MyDrive/Explainable_Wound_Classification/Split_images', 'checkpoint_path': 'gdrive/MyDrive/Explainable_Wound_Classification/outputs/supervised/2_topk5/', 'batch_size': 8, 'num_workers': 2, 'epochs': 200, 'print_freq': 10, 'save_freq': 10, 'weak_strong': True, 'debug': False, 'arch': 'resnet', 'momentum': 0.99, 'mem_bank_size': 128000, 'topk': 5, 'learning_rate': 0.05, 'sgd_momentum': 0.9, 'weight_decay': 0.0001, 'weights': None, 'resume': None, 'restart': False, 'cos': True, 'lr_decay_rate': 0.2, 'lr_decay_epochs': [90, 120], 'output_dim': 16}\n","Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    RandomRotation(degrees=[0.0, 360.0], interpolation=nearest, expand=False, fill=0)\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","Compose(\n","    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n","    ColorJitter(brightness=None, contrast=None, saturation=(0, 1), hue=None)\n","    RandomRotation(degrees=[0.0, 360.0], interpolation=nearest, expand=False, fill=0)\n","    RandomAffine(degrees=[0.0, 0.0], translate=(0.3, 0.3))\n","    ToTensor()\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",")\n","==> train dataset\n","Image_Dataset:\n","Found 191 images in gdrive/MyDrive/Explainable_Wound_Classification/Split_images/train\n","\n","using mem-bank size 128000\n","MeanShift(\n","  (encoder_q): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=16, bias=True)\n","    )\n","  )\n","  (encoder_t): DataParallel(\n","    (module): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=16, bias=True)\n","    )\n","  )\n","  (predict_q): DataParallel(\n","    (module): Sequential(\n","      (0): Linear(in_features=16, out_features=32, bias=True)\n","      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Linear(in_features=32, out_features=16, bias=True)\n","    )\n","  )\n",")\n","Params to learn:\n","\t encoder_q.module.fc.weight\n","\t encoder_q.module.fc.bias\n","\t predict_q.module.0.weight\n","\t predict_q.module.0.bias\n","\t predict_q.module.1.weight\n","\t predict_q.module.1.bias\n","\t predict_q.module.3.weight\n","\t predict_q.module.3.bias\n","LR: 0.05\n","==> training...\n","Train: [1][10/23]\tBT 0.079 (0.136)\tDT 0.000 (0.041)\tloss 0.312 (0.734)\tpurity 100.000 (93.500)\t\n","Train: [1][20/23]\tBT 0.081 (0.108)\tDT 0.014 (0.023)\tloss 0.416 (0.541)\tpurity 100.000 (96.750)\t\n","epoch 1, total time 2.40\n","LR: 0.04999691581204152\n","==> training...\n","Train: [2][10/23]\tBT 0.065 (0.105)\tDT 0.000 (0.030)\tloss 0.562 (0.496)\tpurity 100.000 (100.000)\t\n","Train: [2][20/23]\tBT 0.065 (0.096)\tDT 0.000 (0.019)\tloss 0.562 (0.543)\tpurity 100.000 (100.000)\t\n","epoch 2, total time 2.17\n","LR: 0.04998766400914329\n","==> training...\n","Train: [3][10/23]\tBT 0.067 (0.104)\tDT 0.000 (0.031)\tloss 0.515 (0.586)\tpurity 100.000 (100.000)\t\n","Train: [3][20/23]\tBT 0.088 (0.094)\tDT 0.000 (0.019)\tloss 0.439 (0.547)\tpurity 100.000 (100.000)\t\n","epoch 3, total time 2.13\n","LR: 0.049972246874049255\n","==> training...\n","Train: [4][10/23]\tBT 0.088 (0.107)\tDT 0.000 (0.030)\tloss 0.387 (0.409)\tpurity 100.000 (100.000)\t\n","Train: [4][20/23]\tBT 0.096 (0.094)\tDT 0.026 (0.018)\tloss 0.311 (0.382)\tpurity 100.000 (100.000)\t\n","epoch 4, total time 2.12\n","LR: 0.04995066821070679\n","==> training...\n","Train: [5][10/23]\tBT 0.074 (0.110)\tDT 0.009 (0.035)\tloss 0.284 (0.303)\tpurity 100.000 (100.000)\t\n","Train: [5][20/23]\tBT 0.080 (0.094)\tDT 0.000 (0.020)\tloss 0.271 (0.289)\tpurity 100.000 (100.000)\t\n","epoch 5, total time 2.12\n","LR: 0.0499229333433282\n","==> training...\n","Train: [6][10/23]\tBT 0.086 (0.104)\tDT 0.001 (0.026)\tloss 0.201 (0.241)\tpurity 100.000 (100.000)\t\n","Train: [6][20/23]\tBT 0.063 (0.094)\tDT 0.000 (0.020)\tloss 0.250 (0.231)\tpurity 100.000 (100.000)\t\n","epoch 6, total time 2.15\n","LR: 0.049889049115077\n","==> training...\n","Train: [7][10/23]\tBT 0.067 (0.104)\tDT 0.001 (0.027)\tloss 0.185 (0.209)\tpurity 100.000 (100.000)\t\n","Train: [7][20/23]\tBT 0.072 (0.096)\tDT 0.000 (0.020)\tloss 0.222 (0.210)\tpurity 100.000 (100.000)\t\n","epoch 7, total time 2.22\n","LR: 0.0498490238863795\n","==> training...\n","Train: [8][10/23]\tBT 0.082 (0.114)\tDT 0.000 (0.033)\tloss 0.196 (0.210)\tpurity 100.000 (100.000)\t\n","Train: [8][20/23]\tBT 0.064 (0.097)\tDT 0.000 (0.022)\tloss 0.230 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 8, total time 2.22\n","LR: 0.04980286753286195\n","==> training...\n","Train: [9][10/23]\tBT 0.089 (0.106)\tDT 0.000 (0.035)\tloss 0.341 (0.215)\tpurity 100.000 (100.000)\t\n","Train: [9][20/23]\tBT 0.072 (0.095)\tDT 0.000 (0.026)\tloss 0.214 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 9, total time 2.14\n","LR: 0.04975059144291394\n","==> training...\n","Train: [10][10/23]\tBT 0.106 (0.110)\tDT 0.028 (0.031)\tloss 0.213 (0.229)\tpurity 100.000 (100.000)\t\n","Train: [10][20/23]\tBT 0.098 (0.098)\tDT 0.031 (0.023)\tloss 0.245 (0.213)\tpurity 100.000 (100.000)\t\n","epoch 10, total time 2.19\n","==> Saving...\n","LR: 0.04969220851487845\n","==> training...\n","Train: [11][10/23]\tBT 0.065 (0.133)\tDT 0.000 (0.059)\tloss 0.164 (0.189)\tpurity 100.000 (100.000)\t\n","Train: [11][20/23]\tBT 0.063 (0.110)\tDT 0.000 (0.035)\tloss 0.188 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 11, total time 2.44\n","LR: 0.04962773315386935\n","==> training...\n","Train: [12][10/23]\tBT 0.064 (0.122)\tDT 0.000 (0.052)\tloss 0.174 (0.187)\tpurity 100.000 (100.000)\t\n","Train: [12][20/23]\tBT 0.086 (0.105)\tDT 0.000 (0.032)\tloss 0.210 (0.188)\tpurity 100.000 (100.000)\t\n","epoch 12, total time 2.36\n","LR: 0.049557181268217225\n","==> training...\n","Train: [13][10/23]\tBT 0.074 (0.128)\tDT 0.000 (0.052)\tloss 0.162 (0.188)\tpurity 100.000 (100.000)\t\n","Train: [13][20/23]\tBT 0.068 (0.111)\tDT 0.000 (0.028)\tloss 0.196 (0.186)\tpurity 100.000 (100.000)\t\n","epoch 13, total time 2.46\n","LR: 0.049480570265544144\n","==> training...\n","Train: [14][10/23]\tBT 0.089 (0.106)\tDT 0.000 (0.031)\tloss 0.157 (0.175)\tpurity 100.000 (100.000)\t\n","Train: [14][20/23]\tBT 0.077 (0.095)\tDT 0.000 (0.020)\tloss 0.254 (0.180)\tpurity 100.000 (100.000)\t\n","epoch 14, total time 2.15\n","LR: 0.049397919048468686\n","==> training...\n","Train: [15][10/23]\tBT 0.072 (0.140)\tDT 0.001 (0.038)\tloss 0.154 (0.183)\tpurity 100.000 (100.000)\t\n","Train: [15][20/23]\tBT 0.069 (0.115)\tDT 0.000 (0.028)\tloss 0.152 (0.188)\tpurity 100.000 (100.000)\t\n","epoch 15, total time 2.56\n","LR: 0.049309248009941915\n","==> training...\n","Train: [16][10/23]\tBT 0.082 (0.106)\tDT 0.000 (0.028)\tloss 0.200 (0.196)\tpurity 100.000 (100.000)\t\n","Train: [16][20/23]\tBT 0.075 (0.098)\tDT 0.007 (0.020)\tloss 0.172 (0.186)\tpurity 100.000 (100.000)\t\n","epoch 16, total time 2.20\n","LR: 0.04921457902821578\n","==> training...\n","Train: [17][10/23]\tBT 0.064 (0.107)\tDT 0.000 (0.032)\tloss 0.178 (0.206)\tpurity 100.000 (100.000)\t\n","Train: [17][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.023)\tloss 0.125 (0.216)\tpurity 100.000 (100.000)\t\n","epoch 17, total time 2.18\n","LR: 0.049113935461444956\n","==> training...\n","Train: [18][10/23]\tBT 0.070 (0.105)\tDT 0.000 (0.035)\tloss 0.251 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [18][20/23]\tBT 0.063 (0.096)\tDT 0.000 (0.025)\tloss 0.211 (0.222)\tpurity 100.000 (100.000)\t\n","epoch 18, total time 2.16\n","LR: 0.04900734214192358\n","==> training...\n","Train: [19][10/23]\tBT 0.081 (0.110)\tDT 0.000 (0.036)\tloss 0.149 (0.208)\tpurity 100.000 (100.000)\t\n","Train: [19][20/23]\tBT 0.067 (0.097)\tDT 0.000 (0.025)\tloss 0.229 (0.224)\tpurity 100.000 (100.000)\t\n","epoch 19, total time 2.19\n","LR: 0.048894825369958254\n","==> training...\n","Train: [20][10/23]\tBT 0.064 (0.106)\tDT 0.000 (0.034)\tloss 0.146 (0.214)\tpurity 100.000 (100.000)\t\n","Train: [20][20/23]\tBT 0.074 (0.097)\tDT 0.000 (0.025)\tloss 0.217 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 20, total time 2.19\n","==> Saving...\n","LR: 0.048776412907378844\n","==> training...\n","Train: [21][10/23]\tBT 0.065 (0.103)\tDT 0.000 (0.031)\tloss 0.294 (0.202)\tpurity 100.000 (100.000)\t\n","Train: [21][20/23]\tBT 0.085 (0.095)\tDT 0.000 (0.024)\tloss 0.358 (0.207)\tpurity 100.000 (100.000)\t\n","epoch 21, total time 2.15\n","LR: 0.048652133970688634\n","==> training...\n","Train: [22][10/23]\tBT 0.074 (0.112)\tDT 0.001 (0.032)\tloss 0.178 (0.202)\tpurity 100.000 (100.000)\t\n","Train: [22][20/23]\tBT 0.063 (0.099)\tDT 0.000 (0.024)\tloss 0.262 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 22, total time 2.21\n","LR: 0.04852201922385564\n","==> training...\n","Train: [23][10/23]\tBT 0.064 (0.101)\tDT 0.000 (0.027)\tloss 0.136 (0.213)\tpurity 100.000 (100.000)\t\n","Train: [23][20/23]\tBT 0.064 (0.095)\tDT 0.000 (0.019)\tloss 0.237 (0.239)\tpurity 100.000 (100.000)\t\n","epoch 23, total time 2.13\n","LR: 0.04838610077074669\n","==> training...\n","Train: [24][10/23]\tBT 0.071 (0.105)\tDT 0.000 (0.034)\tloss 0.186 (0.198)\tpurity 100.000 (100.000)\t\n","Train: [24][20/23]\tBT 0.075 (0.100)\tDT 0.000 (0.026)\tloss 0.285 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 24, total time 2.24\n","LR: 0.04824441214720629\n","==> training...\n","Train: [25][10/23]\tBT 0.110 (0.109)\tDT 0.000 (0.029)\tloss 0.100 (0.199)\tpurity 100.000 (100.000)\t\n","Train: [25][20/23]\tBT 0.068 (0.112)\tDT 0.000 (0.030)\tloss 0.280 (0.210)\tpurity 100.000 (100.000)\t\n","epoch 25, total time 2.51\n","LR: 0.04809698831278217\n","==> training...\n","Train: [26][10/23]\tBT 0.066 (0.106)\tDT 0.000 (0.022)\tloss 0.267 (0.238)\tpurity 100.000 (100.000)\t\n","Train: [26][20/23]\tBT 0.074 (0.092)\tDT 0.011 (0.013)\tloss 0.302 (0.244)\tpurity 100.000 (100.000)\t\n","epoch 26, total time 2.13\n","LR: 0.04794386564209953\n","==> training...\n","Train: [27][10/23]\tBT 0.065 (0.105)\tDT 0.000 (0.027)\tloss 0.183 (0.235)\tpurity 100.000 (100.000)\t\n","Train: [27][20/23]\tBT 0.064 (0.092)\tDT 0.000 (0.017)\tloss 0.268 (0.237)\tpurity 100.000 (100.000)\t\n","epoch 27, total time 2.12\n","LR: 0.04778508191588613\n","==> training...\n","Train: [28][10/23]\tBT 0.079 (0.102)\tDT 0.015 (0.030)\tloss 0.336 (0.259)\tpurity 100.000 (100.000)\t\n","Train: [28][20/23]\tBT 0.072 (0.095)\tDT 0.000 (0.023)\tloss 0.226 (0.261)\tpurity 100.000 (100.000)\t\n","epoch 28, total time 2.17\n","LR: 0.04762067631165049\n","==> training...\n","Train: [29][10/23]\tBT 0.074 (0.106)\tDT 0.000 (0.027)\tloss 0.359 (0.264)\tpurity 100.000 (100.000)\t\n","Train: [29][20/23]\tBT 0.079 (0.095)\tDT 0.000 (0.019)\tloss 0.457 (0.259)\tpurity 100.000 (100.000)\t\n","epoch 29, total time 2.17\n","LR: 0.047450689394015394\n","==> training...\n","Train: [30][10/23]\tBT 0.095 (0.107)\tDT 0.000 (0.024)\tloss 0.218 (0.285)\tpurity 100.000 (100.000)\t\n","Train: [30][20/23]\tBT 0.086 (0.094)\tDT 0.000 (0.014)\tloss 0.237 (0.267)\tpurity 100.000 (100.000)\t\n","epoch 30, total time 2.13\n","==> Saving...\n","LR: 0.047275163104709195\n","==> training...\n","Train: [31][10/23]\tBT 0.067 (0.108)\tDT 0.001 (0.036)\tloss 0.189 (0.239)\tpurity 100.000 (100.000)\t\n","Train: [31][20/23]\tBT 0.064 (0.095)\tDT 0.000 (0.023)\tloss 0.145 (0.246)\tpurity 100.000 (100.000)\t\n","epoch 31, total time 2.19\n","LR: 0.047094140752217344\n","==> training...\n","Train: [32][10/23]\tBT 0.068 (0.102)\tDT 0.000 (0.029)\tloss 0.220 (0.240)\tpurity 100.000 (100.000)\t\n","Train: [32][20/23]\tBT 0.073 (0.095)\tDT 0.000 (0.022)\tloss 0.211 (0.234)\tpurity 100.000 (100.000)\t\n","epoch 32, total time 2.13\n","LR: 0.04690766700109659\n","==> training...\n","Train: [33][10/23]\tBT 0.064 (0.105)\tDT 0.000 (0.036)\tloss 0.165 (0.218)\tpurity 100.000 (100.000)\t\n","Train: [33][20/23]\tBT 0.073 (0.098)\tDT 0.000 (0.026)\tloss 0.254 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 33, total time 2.23\n","LR: 0.04671578786095479\n","==> training...\n","Train: [34][10/23]\tBT 0.077 (0.110)\tDT 0.000 (0.037)\tloss 0.236 (0.281)\tpurity 100.000 (100.000)\t\n","Train: [34][20/23]\tBT 0.107 (0.102)\tDT 0.000 (0.028)\tloss 0.267 (0.269)\tpurity 100.000 (100.000)\t\n","epoch 34, total time 2.36\n","LR: 0.046518550675098594\n","==> training...\n","Train: [35][10/23]\tBT 0.064 (0.133)\tDT 0.000 (0.053)\tloss 0.144 (0.223)\tpurity 100.000 (100.000)\t\n","Train: [35][20/23]\tBT 0.088 (0.110)\tDT 0.021 (0.034)\tloss 0.365 (0.219)\tpurity 100.000 (100.000)\t\n","epoch 35, total time 2.46\n","LR: 0.04631600410885231\n","==> training...\n","Train: [36][10/23]\tBT 0.088 (0.112)\tDT 0.000 (0.039)\tloss 0.268 (0.221)\tpurity 100.000 (100.000)\t\n","Train: [36][20/23]\tBT 0.063 (0.100)\tDT 0.000 (0.029)\tloss 0.227 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 36, total time 2.24\n","LR: 0.04610819813755038\n","==> training...\n","Train: [37][10/23]\tBT 0.091 (0.108)\tDT 0.000 (0.031)\tloss 0.206 (0.224)\tpurity 100.000 (100.000)\t\n","Train: [37][20/23]\tBT 0.070 (0.092)\tDT 0.000 (0.017)\tloss 0.158 (0.238)\tpurity 100.000 (100.000)\t\n","epoch 37, total time 2.12\n","LR: 0.04589518403420676\n","==> training...\n","Train: [38][10/23]\tBT 0.093 (0.109)\tDT 0.000 (0.025)\tloss 0.346 (0.244)\tpurity 100.000 (100.000)\t\n","Train: [38][20/23]\tBT 0.088 (0.095)\tDT 0.000 (0.013)\tloss 0.151 (0.225)\tpurity 100.000 (100.000)\t\n","epoch 38, total time 2.13\n","LR: 0.04567701435686405\n","==> training...\n","Train: [39][10/23]\tBT 0.086 (0.106)\tDT 0.000 (0.029)\tloss 0.158 (0.210)\tpurity 100.000 (100.000)\t\n","Train: [39][20/23]\tBT 0.074 (0.097)\tDT 0.000 (0.022)\tloss 0.220 (0.224)\tpurity 100.000 (100.000)\t\n","epoch 39, total time 2.18\n","LR: 0.04545374293562559\n","==> training...\n","Train: [40][10/23]\tBT 0.069 (0.103)\tDT 0.000 (0.025)\tloss 0.278 (0.212)\tpurity 100.000 (100.000)\t\n","Train: [40][20/23]\tBT 0.064 (0.094)\tDT 0.000 (0.022)\tloss 0.109 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 40, total time 2.14\n","==> Saving...\n","LR: 0.04522542485937369\n","==> training...\n","Train: [41][10/23]\tBT 0.083 (0.113)\tDT 0.001 (0.038)\tloss 0.180 (0.242)\tpurity 100.000 (100.000)\t\n","Train: [41][20/23]\tBT 0.065 (0.099)\tDT 0.000 (0.026)\tloss 0.180 (0.227)\tpurity 100.000 (100.000)\t\n","epoch 41, total time 2.23\n","LR: 0.04499211646217727\n","==> training...\n","Train: [42][10/23]\tBT 0.071 (0.101)\tDT 0.000 (0.033)\tloss 0.147 (0.207)\tpurity 100.000 (100.000)\t\n","Train: [42][20/23]\tBT 0.068 (0.095)\tDT 0.000 (0.023)\tloss 0.162 (0.243)\tpurity 100.000 (100.000)\t\n","epoch 42, total time 2.14\n","LR: 0.04475387530939226\n","==> training...\n","Train: [43][10/23]\tBT 0.100 (0.110)\tDT 0.005 (0.038)\tloss 0.194 (0.187)\tpurity 100.000 (100.000)\t\n","Train: [43][20/23]\tBT 0.065 (0.094)\tDT 0.000 (0.022)\tloss 0.261 (0.210)\tpurity 100.000 (100.000)\t\n","epoch 43, total time 2.15\n","LR: 0.044510760183458245\n","==> training...\n","Train: [44][10/23]\tBT 0.082 (0.107)\tDT 0.003 (0.025)\tloss 0.264 (0.186)\tpurity 100.000 (100.000)\t\n","Train: [44][20/23]\tBT 0.086 (0.093)\tDT 0.002 (0.016)\tloss 0.156 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 44, total time 2.11\n","LR: 0.044262831069394735\n","==> training...\n","Train: [45][10/23]\tBT 0.070 (0.101)\tDT 0.000 (0.028)\tloss 0.151 (0.228)\tpurity 100.000 (100.000)\t\n","Train: [45][20/23]\tBT 0.091 (0.112)\tDT 0.003 (0.029)\tloss 0.371 (0.239)\tpurity 100.000 (100.000)\t\n","epoch 45, total time 2.48\n","LR: 0.04401014914000078\n","==> training...\n","Train: [46][10/23]\tBT 0.064 (0.105)\tDT 0.000 (0.035)\tloss 0.145 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [46][20/23]\tBT 0.064 (0.097)\tDT 0.000 (0.026)\tloss 0.198 (0.212)\tpurity 100.000 (100.000)\t\n","epoch 46, total time 2.18\n","LR: 0.043752776740761494\n","==> training...\n","Train: [47][10/23]\tBT 0.082 (0.103)\tDT 0.017 (0.028)\tloss 0.271 (0.222)\tpurity 100.000 (100.000)\t\n","Train: [47][20/23]\tBT 0.111 (0.096)\tDT 0.039 (0.022)\tloss 0.156 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 47, total time 2.17\n","LR: 0.043490777374465245\n","==> training...\n","Train: [48][10/23]\tBT 0.064 (0.103)\tDT 0.000 (0.033)\tloss 0.306 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [48][20/23]\tBT 0.083 (0.094)\tDT 0.000 (0.022)\tloss 0.220 (0.205)\tpurity 100.000 (100.000)\t\n","epoch 48, total time 2.15\n","LR: 0.04322421568553529\n","==> training...\n","Train: [49][10/23]\tBT 0.066 (0.101)\tDT 0.001 (0.029)\tloss 0.166 (0.208)\tpurity 100.000 (100.000)\t\n","Train: [49][20/23]\tBT 0.066 (0.095)\tDT 0.002 (0.023)\tloss 0.196 (0.219)\tpurity 100.000 (100.000)\t\n","epoch 49, total time 2.17\n","LR: 0.04295315744407972\n","==> training...\n","Train: [50][10/23]\tBT 0.092 (0.101)\tDT 0.000 (0.026)\tloss 0.222 (0.200)\tpurity 100.000 (100.000)\t\n","Train: [50][20/23]\tBT 0.081 (0.094)\tDT 0.000 (0.020)\tloss 0.187 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 50, total time 2.11\n","==> Saving...\n","LR: 0.04267766952966369\n","==> training...\n","Train: [51][10/23]\tBT 0.079 (0.105)\tDT 0.001 (0.031)\tloss 0.197 (0.219)\tpurity 100.000 (100.000)\t\n","Train: [51][20/23]\tBT 0.072 (0.096)\tDT 0.000 (0.022)\tloss 0.225 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 51, total time 2.16\n","LR: 0.04239781991480786\n","==> training...\n","Train: [52][10/23]\tBT 0.064 (0.103)\tDT 0.000 (0.029)\tloss 0.234 (0.219)\tpurity 100.000 (100.000)\t\n","Train: [52][20/23]\tBT 0.084 (0.096)\tDT 0.000 (0.021)\tloss 0.179 (0.210)\tpurity 100.000 (100.000)\t\n","epoch 52, total time 2.15\n","LR: 0.04211367764821722\n","==> training...\n","Train: [53][10/23]\tBT 0.069 (0.105)\tDT 0.000 (0.029)\tloss 0.220 (0.186)\tpurity 100.000 (100.000)\t\n","Train: [53][20/23]\tBT 0.092 (0.095)\tDT 0.000 (0.020)\tloss 0.154 (0.189)\tpurity 100.000 (100.000)\t\n","epoch 53, total time 2.16\n","LR: 0.041825312837744336\n","==> training...\n","Train: [54][10/23]\tBT 0.079 (0.105)\tDT 0.002 (0.028)\tloss 0.155 (0.215)\tpurity 100.000 (100.000)\t\n","Train: [54][20/23]\tBT 0.072 (0.096)\tDT 0.000 (0.023)\tloss 0.220 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 54, total time 2.15\n","LR: 0.0415327966330913\n","==> training...\n","Train: [55][10/23]\tBT 0.075 (0.103)\tDT 0.000 (0.026)\tloss 0.232 (0.212)\tpurity 100.000 (100.000)\t\n","Train: [55][20/23]\tBT 0.119 (0.106)\tDT 0.041 (0.026)\tloss 0.295 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 55, total time 2.47\n","LR: 0.041236201208254594\n","==> training...\n","Train: [56][10/23]\tBT 0.066 (0.107)\tDT 0.000 (0.034)\tloss 0.215 (0.206)\tpurity 100.000 (100.000)\t\n","Train: [56][20/23]\tBT 0.070 (0.093)\tDT 0.000 (0.021)\tloss 0.283 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 56, total time 2.15\n","LR: 0.040935599743717244\n","==> training...\n","Train: [57][10/23]\tBT 0.075 (0.103)\tDT 0.000 (0.027)\tloss 0.092 (0.182)\tpurity 100.000 (100.000)\t\n","Train: [57][20/23]\tBT 0.065 (0.092)\tDT 0.000 (0.019)\tloss 0.114 (0.198)\tpurity 100.000 (100.000)\t\n","epoch 57, total time 2.11\n","LR: 0.04063106640839264\n","==> training...\n","Train: [58][10/23]\tBT 0.076 (0.104)\tDT 0.000 (0.029)\tloss 0.241 (0.225)\tpurity 100.000 (100.000)\t\n","Train: [58][20/23]\tBT 0.071 (0.095)\tDT 0.000 (0.023)\tloss 0.328 (0.216)\tpurity 100.000 (100.000)\t\n","epoch 58, total time 2.15\n","LR: 0.040322676341324415\n","==> training...\n","Train: [59][10/23]\tBT 0.075 (0.103)\tDT 0.000 (0.032)\tloss 0.114 (0.225)\tpurity 100.000 (100.000)\t\n","Train: [59][20/23]\tBT 0.067 (0.093)\tDT 0.000 (0.020)\tloss 0.258 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 59, total time 2.12\n","LR: 0.040010505633147106\n","==> training...\n","Train: [60][10/23]\tBT 0.065 (0.104)\tDT 0.000 (0.036)\tloss 0.188 (0.223)\tpurity 100.000 (100.000)\t\n","Train: [60][20/23]\tBT 0.064 (0.096)\tDT 0.000 (0.027)\tloss 0.160 (0.227)\tpurity 100.000 (100.000)\t\n","epoch 60, total time 2.17\n","==> Saving...\n","LR: 0.03969463130731184\n","==> training...\n","Train: [61][10/23]\tBT 0.065 (0.115)\tDT 0.000 (0.027)\tloss 0.219 (0.172)\tpurity 100.000 (100.000)\t\n","Train: [61][20/23]\tBT 0.096 (0.099)\tDT 0.017 (0.017)\tloss 0.223 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 61, total time 2.24\n","LR: 0.03937513130108197\n","==> training...\n","Train: [62][10/23]\tBT 0.071 (0.110)\tDT 0.001 (0.034)\tloss 0.119 (0.223)\tpurity 100.000 (100.000)\t\n","Train: [62][20/23]\tBT 0.066 (0.096)\tDT 0.000 (0.022)\tloss 0.168 (0.216)\tpurity 100.000 (100.000)\t\n","epoch 62, total time 2.15\n","LR: 0.03905208444630327\n","==> training...\n","Train: [63][10/23]\tBT 0.064 (0.105)\tDT 0.000 (0.035)\tloss 0.143 (0.226)\tpurity 100.000 (100.000)\t\n","Train: [63][20/23]\tBT 0.074 (0.096)\tDT 0.000 (0.023)\tloss 0.258 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 63, total time 2.15\n","LR: 0.0387255704499533\n","==> training...\n","Train: [64][10/23]\tBT 0.077 (0.102)\tDT 0.000 (0.027)\tloss 0.145 (0.207)\tpurity 100.000 (100.000)\t\n","Train: [64][20/23]\tBT 0.068 (0.097)\tDT 0.000 (0.023)\tloss 0.183 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 64, total time 2.18\n","LR: 0.038395669874474916\n","==> training...\n","Train: [65][10/23]\tBT 0.072 (0.104)\tDT 0.000 (0.031)\tloss 0.173 (0.223)\tpurity 100.000 (100.000)\t\n","Train: [65][20/23]\tBT 0.068 (0.106)\tDT 0.000 (0.029)\tloss 0.260 (0.233)\tpurity 100.000 (100.000)\t\n","epoch 65, total time 2.46\n","LR: 0.03806246411789872\n","==> training...\n","Train: [66][10/23]\tBT 0.086 (0.112)\tDT 0.001 (0.036)\tloss 0.313 (0.252)\tpurity 100.000 (100.000)\t\n","Train: [66][20/23]\tBT 0.077 (0.098)\tDT 0.000 (0.022)\tloss 0.282 (0.219)\tpurity 100.000 (100.000)\t\n","epoch 66, total time 2.21\n","LR: 0.03772603539375929\n","==> training...\n","Train: [67][10/23]\tBT 0.090 (0.106)\tDT 0.000 (0.029)\tloss 0.210 (0.214)\tpurity 100.000 (100.000)\t\n","Train: [67][20/23]\tBT 0.068 (0.093)\tDT 0.000 (0.017)\tloss 0.129 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 67, total time 2.11\n","LR: 0.03738646671081019\n","==> training...\n","Train: [68][10/23]\tBT 0.073 (0.107)\tDT 0.000 (0.028)\tloss 0.230 (0.233)\tpurity 100.000 (100.000)\t\n","Train: [68][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.021)\tloss 0.326 (0.221)\tpurity 100.000 (100.000)\t\n","epoch 68, total time 2.16\n","LR: 0.037043841852542884\n","==> training...\n","Train: [69][10/23]\tBT 0.076 (0.103)\tDT 0.000 (0.030)\tloss 0.190 (0.215)\tpurity 100.000 (100.000)\t\n","Train: [69][20/23]\tBT 0.064 (0.092)\tDT 0.000 (0.018)\tloss 0.375 (0.225)\tpurity 100.000 (100.000)\t\n","epoch 69, total time 2.12\n","LR: 0.036698245356514336\n","==> training...\n","Train: [70][10/23]\tBT 0.084 (0.105)\tDT 0.000 (0.024)\tloss 0.353 (0.218)\tpurity 100.000 (100.000)\t\n","Train: [70][20/23]\tBT 0.068 (0.091)\tDT 0.000 (0.013)\tloss 0.239 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 70, total time 2.10\n","==> Saving...\n","LR: 0.03634976249348867\n","==> training...\n","Train: [71][10/23]\tBT 0.142 (0.108)\tDT 0.052 (0.029)\tloss 0.123 (0.212)\tpurity 100.000 (100.000)\t\n","Train: [71][20/23]\tBT 0.096 (0.095)\tDT 0.028 (0.017)\tloss 0.206 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 71, total time 2.15\n","LR: 0.035998479246397874\n","==> training...\n","Train: [72][10/23]\tBT 0.092 (0.111)\tDT 0.000 (0.030)\tloss 0.407 (0.230)\tpurity 100.000 (100.000)\t\n","Train: [72][20/23]\tBT 0.063 (0.097)\tDT 0.000 (0.022)\tloss 0.242 (0.226)\tpurity 100.000 (100.000)\t\n","epoch 72, total time 2.19\n","LR: 0.03564448228912682\n","==> training...\n","Train: [73][10/23]\tBT 0.083 (0.103)\tDT 0.001 (0.028)\tloss 0.176 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [73][20/23]\tBT 0.066 (0.098)\tDT 0.000 (0.024)\tloss 0.242 (0.223)\tpurity 100.000 (100.000)\t\n","epoch 73, total time 2.19\n","LR: 0.035287858965127726\n","==> training...\n","Train: [74][10/23]\tBT 0.086 (0.107)\tDT 0.000 (0.030)\tloss 0.146 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [74][20/23]\tBT 0.076 (0.095)\tDT 0.000 (0.018)\tloss 0.277 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 74, total time 2.14\n","LR: 0.034928697265869516\n","==> training...\n","Train: [75][10/23]\tBT 0.086 (0.133)\tDT 0.001 (0.044)\tloss 0.220 (0.241)\tpurity 100.000 (100.000)\t\n","Train: [75][20/23]\tBT 0.065 (0.109)\tDT 0.000 (0.027)\tloss 0.148 (0.236)\tpurity 100.000 (100.000)\t\n","epoch 75, total time 2.47\n","LR: 0.03456708580912725\n","==> training...\n","Train: [76][10/23]\tBT 0.092 (0.108)\tDT 0.000 (0.033)\tloss 0.149 (0.181)\tpurity 100.000 (100.000)\t\n","Train: [76][20/23]\tBT 0.068 (0.095)\tDT 0.000 (0.023)\tloss 0.150 (0.185)\tpurity 100.000 (100.000)\t\n","epoch 76, total time 2.16\n","LR: 0.03420311381711696\n","==> training...\n","Train: [77][10/23]\tBT 0.081 (0.104)\tDT 0.018 (0.036)\tloss 0.201 (0.208)\tpurity 100.000 (100.000)\t\n","Train: [77][20/23]\tBT 0.069 (0.095)\tDT 0.000 (0.026)\tloss 0.183 (0.211)\tpurity 100.000 (100.000)\t\n","epoch 77, total time 2.16\n","LR: 0.033836871094481434\n","==> training...\n","Train: [78][10/23]\tBT 0.083 (0.107)\tDT 0.000 (0.026)\tloss 0.283 (0.263)\tpurity 100.000 (100.000)\t\n","Train: [78][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.018)\tloss 0.175 (0.253)\tpurity 100.000 (100.000)\t\n","epoch 78, total time 2.15\n","LR: 0.033468448006132294\n","==> training...\n","Train: [79][10/23]\tBT 0.094 (0.111)\tDT 0.001 (0.031)\tloss 0.151 (0.183)\tpurity 100.000 (100.000)\t\n","Train: [79][20/23]\tBT 0.064 (0.093)\tDT 0.000 (0.016)\tloss 0.163 (0.199)\tpurity 100.000 (100.000)\t\n","epoch 79, total time 2.13\n","LR: 0.033097935454953736\n","==> training...\n","Train: [80][10/23]\tBT 0.096 (0.106)\tDT 0.000 (0.025)\tloss 0.236 (0.246)\tpurity 100.000 (100.000)\t\n","Train: [80][20/23]\tBT 0.064 (0.093)\tDT 0.000 (0.016)\tloss 0.149 (0.218)\tpurity 100.000 (100.000)\t\n","epoch 80, total time 2.12\n","==> Saving...\n","LR: 0.032725424859373686\n","==> training...\n","Train: [81][10/23]\tBT 0.082 (0.102)\tDT 0.012 (0.027)\tloss 0.354 (0.214)\tpurity 100.000 (100.000)\t\n","Train: [81][20/23]\tBT 0.087 (0.095)\tDT 0.000 (0.019)\tloss 0.167 (0.212)\tpurity 100.000 (100.000)\t\n","epoch 81, total time 2.13\n","LR: 0.0323510081308076\n","==> training...\n","Train: [82][10/23]\tBT 0.075 (0.104)\tDT 0.002 (0.025)\tloss 0.233 (0.186)\tpurity 100.000 (100.000)\t\n","Train: [82][20/23]\tBT 0.072 (0.092)\tDT 0.000 (0.015)\tloss 0.207 (0.200)\tpurity 100.000 (100.000)\t\n","epoch 82, total time 2.12\n","LR: 0.03197477765098074\n","==> training...\n","Train: [83][10/23]\tBT 0.078 (0.110)\tDT 0.000 (0.031)\tloss 0.167 (0.199)\tpurity 100.000 (100.000)\t\n","Train: [83][20/23]\tBT 0.064 (0.098)\tDT 0.000 (0.017)\tloss 0.230 (0.197)\tpurity 100.000 (100.000)\t\n","epoch 83, total time 2.19\n","LR: 0.03159682624913432\n","==> training...\n","Train: [84][10/23]\tBT 0.096 (0.110)\tDT 0.000 (0.025)\tloss 0.285 (0.186)\tpurity 100.000 (100.000)\t\n","Train: [84][20/23]\tBT 0.076 (0.094)\tDT 0.003 (0.013)\tloss 0.174 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 84, total time 2.12\n","LR: 0.031217247179121367\n","==> training...\n","Train: [85][10/23]\tBT 0.092 (0.109)\tDT 0.020 (0.030)\tloss 0.158 (0.203)\tpurity 100.000 (100.000)\t\n","Train: [85][20/23]\tBT 0.114 (0.115)\tDT 0.001 (0.020)\tloss 0.297 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 85, total time 2.56\n","LR: 0.03083613409639764\n","==> training...\n","Train: [86][10/23]\tBT 0.124 (0.109)\tDT 0.033 (0.029)\tloss 0.163 (0.184)\tpurity 100.000 (100.000)\t\n","Train: [86][20/23]\tBT 0.084 (0.096)\tDT 0.020 (0.020)\tloss 0.134 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 86, total time 2.19\n","LR: 0.03045358103491357\n","==> training...\n","Train: [87][10/23]\tBT 0.076 (0.108)\tDT 0.001 (0.035)\tloss 0.259 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [87][20/23]\tBT 0.063 (0.094)\tDT 0.000 (0.023)\tloss 0.173 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 87, total time 2.14\n","LR: 0.03006968238391282\n","==> training...\n","Train: [88][10/23]\tBT 0.083 (0.107)\tDT 0.001 (0.032)\tloss 0.299 (0.223)\tpurity 100.000 (100.000)\t\n","Train: [88][20/23]\tBT 0.067 (0.100)\tDT 0.000 (0.024)\tloss 0.270 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 88, total time 2.24\n","LR: 0.02968453286464312\n","==> training...\n","Train: [89][10/23]\tBT 0.085 (0.107)\tDT 0.000 (0.028)\tloss 0.189 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [89][20/23]\tBT 0.064 (0.094)\tDT 0.000 (0.018)\tloss 0.159 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 89, total time 2.11\n","LR: 0.029298227506985238\n","==> training...\n","Train: [90][10/23]\tBT 0.072 (0.106)\tDT 0.000 (0.034)\tloss 0.207 (0.189)\tpurity 100.000 (100.000)\t\n","Train: [90][20/23]\tBT 0.074 (0.098)\tDT 0.000 (0.025)\tloss 0.145 (0.190)\tpurity 100.000 (100.000)\t\n","epoch 90, total time 2.19\n","==> Saving...\n","LR: 0.028910861626005774\n","==> training...\n","Train: [91][10/23]\tBT 0.108 (0.111)\tDT 0.003 (0.038)\tloss 0.217 (0.207)\tpurity 100.000 (100.000)\t\n","Train: [91][20/23]\tBT 0.073 (0.095)\tDT 0.000 (0.023)\tloss 0.194 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 91, total time 2.16\n","LR: 0.028522530798439572\n","==> training...\n","Train: [92][10/23]\tBT 0.080 (0.103)\tDT 0.004 (0.029)\tloss 0.182 (0.180)\tpurity 100.000 (100.000)\t\n","Train: [92][20/23]\tBT 0.068 (0.092)\tDT 0.000 (0.020)\tloss 0.188 (0.190)\tpurity 100.000 (100.000)\t\n","epoch 92, total time 2.10\n","LR: 0.028133330839107615\n","==> training...\n","Train: [93][10/23]\tBT 0.071 (0.108)\tDT 0.000 (0.035)\tloss 0.177 (0.214)\tpurity 100.000 (100.000)\t\n","Train: [93][20/23]\tBT 0.076 (0.097)\tDT 0.000 (0.022)\tloss 0.162 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 93, total time 2.18\n","LR: 0.027743357777276136\n","==> training...\n","Train: [94][10/23]\tBT 0.099 (0.107)\tDT 0.000 (0.031)\tloss 0.192 (0.176)\tpurity 100.000 (100.000)\t\n","Train: [94][20/23]\tBT 0.078 (0.092)\tDT 0.000 (0.016)\tloss 0.195 (0.186)\tpurity 100.000 (100.000)\t\n","epoch 94, total time 2.09\n","LR: 0.02735270783296286\n","==> training...\n","Train: [95][10/23]\tBT 0.108 (0.112)\tDT 0.000 (0.033)\tloss 0.330 (0.228)\tpurity 100.000 (100.000)\t\n","Train: [95][20/23]\tBT 0.089 (0.109)\tDT 0.000 (0.022)\tloss 0.127 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 95, total time 2.49\n","LR: 0.026961477393196126\n","==> training...\n","Train: [96][10/23]\tBT 0.065 (0.108)\tDT 0.002 (0.025)\tloss 0.259 (0.250)\tpurity 100.000 (100.000)\t\n","Train: [96][20/23]\tBT 0.064 (0.093)\tDT 0.000 (0.013)\tloss 0.223 (0.235)\tpurity 100.000 (100.000)\t\n","epoch 96, total time 2.13\n","LR: 0.02656976298823284\n","==> training...\n","Train: [97][10/23]\tBT 0.076 (0.104)\tDT 0.000 (0.025)\tloss 0.305 (0.202)\tpurity 100.000 (100.000)\t\n","Train: [97][20/23]\tBT 0.068 (0.093)\tDT 0.000 (0.016)\tloss 0.257 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 97, total time 2.10\n","LR: 0.026177661267741067\n","==> training...\n","Train: [98][10/23]\tBT 0.096 (0.106)\tDT 0.000 (0.027)\tloss 0.248 (0.205)\tpurity 100.000 (100.000)\t\n","Train: [98][20/23]\tBT 0.074 (0.091)\tDT 0.000 (0.014)\tloss 0.154 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 98, total time 2.06\n","LR: 0.02578526897695321\n","==> training...\n","Train: [99][10/23]\tBT 0.079 (0.103)\tDT 0.002 (0.031)\tloss 0.164 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [99][20/23]\tBT 0.071 (0.091)\tDT 0.000 (0.017)\tloss 0.242 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 99, total time 2.07\n","LR: 0.02539268293279552\n","==> training...\n","Train: [100][10/23]\tBT 0.067 (0.105)\tDT 0.000 (0.032)\tloss 0.220 (0.216)\tpurity 100.000 (100.000)\t\n","Train: [100][20/23]\tBT 0.067 (0.094)\tDT 0.000 (0.020)\tloss 0.166 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 100, total time 2.17\n","==> Saving...\n","LR: 0.025\n","==> training...\n","Train: [101][10/23]\tBT 0.080 (0.106)\tDT 0.000 (0.024)\tloss 0.195 (0.187)\tpurity 100.000 (100.000)\t\n","Train: [101][20/23]\tBT 0.080 (0.095)\tDT 0.000 (0.015)\tloss 0.117 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 101, total time 2.16\n","LR: 0.02460731706720449\n","==> training...\n","Train: [102][10/23]\tBT 0.084 (0.108)\tDT 0.001 (0.026)\tloss 0.170 (0.191)\tpurity 100.000 (100.000)\t\n","Train: [102][20/23]\tBT 0.073 (0.097)\tDT 0.000 (0.020)\tloss 0.181 (0.191)\tpurity 100.000 (100.000)\t\n","epoch 102, total time 2.18\n","LR: 0.024214731023046793\n","==> training...\n","Train: [103][10/23]\tBT 0.068 (0.107)\tDT 0.000 (0.036)\tloss 0.344 (0.216)\tpurity 100.000 (100.000)\t\n","Train: [103][20/23]\tBT 0.066 (0.097)\tDT 0.000 (0.022)\tloss 0.208 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 103, total time 2.17\n","LR: 0.023822338732258936\n","==> training...\n","Train: [104][10/23]\tBT 0.073 (0.105)\tDT 0.000 (0.027)\tloss 0.357 (0.198)\tpurity 100.000 (100.000)\t\n","Train: [104][20/23]\tBT 0.075 (0.097)\tDT 0.000 (0.021)\tloss 0.192 (0.194)\tpurity 100.000 (100.000)\t\n","epoch 104, total time 2.18\n","LR: 0.023430237011767167\n","==> training...\n","Train: [105][10/23]\tBT 0.179 (0.118)\tDT 0.001 (0.031)\tloss 0.138 (0.169)\tpurity 100.000 (100.000)\t\n","Train: [105][20/23]\tBT 0.066 (0.115)\tDT 0.000 (0.026)\tloss 0.274 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 105, total time 2.54\n","LR: 0.02303852260680388\n","==> training...\n","Train: [106][10/23]\tBT 0.068 (0.102)\tDT 0.000 (0.030)\tloss 0.214 (0.200)\tpurity 100.000 (100.000)\t\n","Train: [106][20/23]\tBT 0.069 (0.093)\tDT 0.000 (0.020)\tloss 0.193 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 106, total time 2.15\n","LR: 0.022647292167037144\n","==> training...\n","Train: [107][10/23]\tBT 0.074 (0.102)\tDT 0.002 (0.026)\tloss 0.259 (0.201)\tpurity 100.000 (100.000)\t\n","Train: [107][20/23]\tBT 0.072 (0.092)\tDT 0.000 (0.018)\tloss 0.183 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 107, total time 2.10\n","LR: 0.02225664222272387\n","==> training...\n","Train: [108][10/23]\tBT 0.066 (0.108)\tDT 0.003 (0.039)\tloss 0.109 (0.190)\tpurity 100.000 (100.000)\t\n","Train: [108][20/23]\tBT 0.063 (0.097)\tDT 0.000 (0.028)\tloss 0.203 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 108, total time 2.20\n","LR: 0.0218666691608924\n","==> training...\n","Train: [109][10/23]\tBT 0.074 (0.106)\tDT 0.000 (0.035)\tloss 0.163 (0.187)\tpurity 100.000 (100.000)\t\n","Train: [109][20/23]\tBT 0.073 (0.097)\tDT 0.000 (0.026)\tloss 0.231 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 109, total time 2.18\n","LR: 0.02147746920156044\n","==> training...\n","Train: [110][10/23]\tBT 0.087 (0.106)\tDT 0.000 (0.028)\tloss 0.210 (0.218)\tpurity 100.000 (100.000)\t\n","Train: [110][20/23]\tBT 0.086 (0.093)\tDT 0.022 (0.016)\tloss 0.145 (0.203)\tpurity 100.000 (100.000)\t\n","epoch 110, total time 2.13\n","==> Saving...\n","LR: 0.021089138373994232\n","==> training...\n","Train: [111][10/23]\tBT 0.081 (0.106)\tDT 0.000 (0.027)\tloss 0.187 (0.184)\tpurity 100.000 (100.000)\t\n","Train: [111][20/23]\tBT 0.065 (0.094)\tDT 0.000 (0.021)\tloss 0.148 (0.177)\tpurity 100.000 (100.000)\t\n","epoch 111, total time 2.12\n","LR: 0.02070177249301476\n","==> training...\n","Train: [112][10/23]\tBT 0.083 (0.105)\tDT 0.000 (0.031)\tloss 0.250 (0.205)\tpurity 100.000 (100.000)\t\n","Train: [112][20/23]\tBT 0.117 (0.094)\tDT 0.035 (0.019)\tloss 0.177 (0.194)\tpurity 100.000 (100.000)\t\n","epoch 112, total time 2.16\n","LR: 0.020315467135356886\n","==> training...\n","Train: [113][10/23]\tBT 0.074 (0.100)\tDT 0.004 (0.026)\tloss 0.285 (0.215)\tpurity 100.000 (100.000)\t\n","Train: [113][20/23]\tBT 0.108 (0.093)\tDT 0.031 (0.020)\tloss 0.270 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 113, total time 2.12\n","LR: 0.01993031761608719\n","==> training...\n","Train: [114][10/23]\tBT 0.085 (0.106)\tDT 0.000 (0.027)\tloss 0.241 (0.190)\tpurity 100.000 (100.000)\t\n","Train: [114][20/23]\tBT 0.077 (0.094)\tDT 0.000 (0.016)\tloss 0.155 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 114, total time 2.12\n","LR: 0.019546418965086444\n","==> training...\n","Train: [115][10/23]\tBT 0.082 (0.115)\tDT 0.000 (0.035)\tloss 0.290 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [115][20/23]\tBT 0.106 (0.115)\tDT 0.000 (0.031)\tloss 0.209 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 115, total time 2.59\n","LR: 0.019163865903602362\n","==> training...\n","Train: [116][10/23]\tBT 0.069 (0.110)\tDT 0.001 (0.032)\tloss 0.295 (0.214)\tpurity 100.000 (100.000)\t\n","Train: [116][20/23]\tBT 0.063 (0.096)\tDT 0.000 (0.020)\tloss 0.152 (0.213)\tpurity 100.000 (100.000)\t\n","epoch 116, total time 2.19\n","LR: 0.01878275282087863\n","==> training...\n","Train: [117][10/23]\tBT 0.078 (0.105)\tDT 0.000 (0.033)\tloss 0.172 (0.181)\tpurity 100.000 (100.000)\t\n","Train: [117][20/23]\tBT 0.065 (0.097)\tDT 0.000 (0.025)\tloss 0.238 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 117, total time 2.17\n","LR: 0.01840317375086568\n","==> training...\n","Train: [118][10/23]\tBT 0.082 (0.107)\tDT 0.000 (0.026)\tloss 0.206 (0.179)\tpurity 100.000 (100.000)\t\n","Train: [118][20/23]\tBT 0.069 (0.093)\tDT 0.000 (0.014)\tloss 0.332 (0.193)\tpurity 100.000 (100.000)\t\n","epoch 118, total time 2.10\n","LR: 0.018025222349019272\n","==> training...\n","Train: [119][10/23]\tBT 0.065 (0.102)\tDT 0.000 (0.026)\tloss 0.134 (0.176)\tpurity 100.000 (100.000)\t\n","Train: [119][20/23]\tBT 0.065 (0.095)\tDT 0.000 (0.015)\tloss 0.217 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 119, total time 2.13\n","LR: 0.017648991869192405\n","==> training...\n","Train: [120][10/23]\tBT 0.066 (0.102)\tDT 0.000 (0.026)\tloss 0.181 (0.207)\tpurity 100.000 (100.000)\t\n","Train: [120][20/23]\tBT 0.116 (0.094)\tDT 0.047 (0.022)\tloss 0.188 (0.207)\tpurity 100.000 (100.000)\t\n","epoch 120, total time 2.12\n","==> Saving...\n","LR: 0.017274575140626323\n","==> training...\n","Train: [121][10/23]\tBT 0.076 (0.105)\tDT 0.003 (0.027)\tloss 0.169 (0.198)\tpurity 100.000 (100.000)\t\n","Train: [121][20/23]\tBT 0.097 (0.093)\tDT 0.000 (0.015)\tloss 0.175 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 121, total time 2.11\n","LR: 0.016902064545046263\n","==> training...\n","Train: [122][10/23]\tBT 0.071 (0.105)\tDT 0.000 (0.029)\tloss 0.380 (0.213)\tpurity 100.000 (100.000)\t\n","Train: [122][20/23]\tBT 0.079 (0.096)\tDT 0.000 (0.021)\tloss 0.163 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 122, total time 2.19\n","LR: 0.016531551993867716\n","==> training...\n","Train: [123][10/23]\tBT 0.065 (0.104)\tDT 0.000 (0.026)\tloss 0.187 (0.182)\tpurity 100.000 (100.000)\t\n","Train: [123][20/23]\tBT 0.084 (0.096)\tDT 0.000 (0.019)\tloss 0.206 (0.194)\tpurity 100.000 (100.000)\t\n","epoch 123, total time 2.17\n","LR: 0.016163128905518576\n","==> training...\n","Train: [124][10/23]\tBT 0.077 (0.111)\tDT 0.001 (0.034)\tloss 0.291 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [124][20/23]\tBT 0.076 (0.097)\tDT 0.000 (0.021)\tloss 0.251 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 124, total time 2.18\n","LR: 0.01579688618288306\n","==> training...\n","Train: [125][10/23]\tBT 0.067 (0.102)\tDT 0.000 (0.024)\tloss 0.231 (0.180)\tpurity 100.000 (100.000)\t\n","Train: [125][20/23]\tBT 0.066 (0.108)\tDT 0.000 (0.022)\tloss 0.190 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 125, total time 2.42\n","LR: 0.015432914190872763\n","==> training...\n","Train: [126][10/23]\tBT 0.081 (0.107)\tDT 0.000 (0.034)\tloss 0.282 (0.202)\tpurity 100.000 (100.000)\t\n","Train: [126][20/23]\tBT 0.067 (0.095)\tDT 0.000 (0.022)\tloss 0.264 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 126, total time 2.14\n","LR: 0.015071302734130482\n","==> training...\n","Train: [127][10/23]\tBT 0.068 (0.101)\tDT 0.000 (0.025)\tloss 0.135 (0.206)\tpurity 100.000 (100.000)\t\n","Train: [127][20/23]\tBT 0.071 (0.093)\tDT 0.000 (0.019)\tloss 0.199 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 127, total time 2.13\n","LR: 0.014712141034872282\n","==> training...\n","Train: [128][10/23]\tBT 0.087 (0.106)\tDT 0.000 (0.030)\tloss 0.268 (0.200)\tpurity 100.000 (100.000)\t\n","Train: [128][20/23]\tBT 0.084 (0.096)\tDT 0.000 (0.022)\tloss 0.179 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 128, total time 2.15\n","LR: 0.014355517710873185\n","==> training...\n","Train: [129][10/23]\tBT 0.091 (0.105)\tDT 0.000 (0.031)\tloss 0.224 (0.226)\tpurity 100.000 (100.000)\t\n","Train: [129][20/23]\tBT 0.064 (0.096)\tDT 0.000 (0.024)\tloss 0.156 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 129, total time 2.16\n","LR: 0.014001520753602122\n","==> training...\n","Train: [130][10/23]\tBT 0.078 (0.103)\tDT 0.004 (0.034)\tloss 0.190 (0.233)\tpurity 100.000 (100.000)\t\n","Train: [130][20/23]\tBT 0.068 (0.095)\tDT 0.000 (0.023)\tloss 0.212 (0.213)\tpurity 100.000 (100.000)\t\n","epoch 130, total time 2.14\n","==> Saving...\n","LR: 0.013650237506511332\n","==> training...\n","Train: [131][10/23]\tBT 0.071 (0.113)\tDT 0.000 (0.033)\tloss 0.223 (0.238)\tpurity 100.000 (100.000)\t\n","Train: [131][20/23]\tBT 0.117 (0.097)\tDT 0.031 (0.019)\tloss 0.177 (0.211)\tpurity 100.000 (100.000)\t\n","epoch 131, total time 2.20\n","LR: 0.01330175464348567\n","==> training...\n","Train: [132][10/23]\tBT 0.075 (0.106)\tDT 0.000 (0.027)\tloss 0.272 (0.184)\tpurity 100.000 (100.000)\t\n","Train: [132][20/23]\tBT 0.064 (0.098)\tDT 0.000 (0.022)\tloss 0.183 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 132, total time 2.20\n","LR: 0.012956158147457115\n","==> training...\n","Train: [133][10/23]\tBT 0.093 (0.117)\tDT 0.000 (0.037)\tloss 0.407 (0.200)\tpurity 100.000 (100.000)\t\n","Train: [133][20/23]\tBT 0.068 (0.101)\tDT 0.000 (0.025)\tloss 0.207 (0.203)\tpurity 100.000 (100.000)\t\n","epoch 133, total time 2.26\n","LR: 0.01261353328918981\n","==> training...\n","Train: [134][10/23]\tBT 0.069 (0.106)\tDT 0.000 (0.033)\tloss 0.200 (0.196)\tpurity 100.000 (100.000)\t\n","Train: [134][20/23]\tBT 0.070 (0.096)\tDT 0.000 (0.025)\tloss 0.164 (0.198)\tpurity 100.000 (100.000)\t\n","epoch 134, total time 2.19\n","LR: 0.012273964606240717\n","==> training...\n","Train: [135][10/23]\tBT 0.094 (0.128)\tDT 0.000 (0.028)\tloss 0.135 (0.238)\tpurity 100.000 (100.000)\t\n","Train: [135][20/23]\tBT 0.119 (0.117)\tDT 0.000 (0.017)\tloss 0.153 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 135, total time 2.57\n","LR: 0.01193753588210128\n","==> training...\n","Train: [136][10/23]\tBT 0.064 (0.103)\tDT 0.000 (0.031)\tloss 0.157 (0.206)\tpurity 100.000 (100.000)\t\n","Train: [136][20/23]\tBT 0.085 (0.095)\tDT 0.014 (0.019)\tloss 0.207 (0.211)\tpurity 100.000 (100.000)\t\n","epoch 136, total time 2.16\n","LR: 0.01160433012552508\n","==> training...\n","Train: [137][10/23]\tBT 0.075 (0.104)\tDT 0.000 (0.031)\tloss 0.208 (0.229)\tpurity 100.000 (100.000)\t\n","Train: [137][20/23]\tBT 0.076 (0.093)\tDT 0.000 (0.019)\tloss 0.173 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 137, total time 2.11\n","LR: 0.011274429550046703\n","==> training...\n","Train: [138][10/23]\tBT 0.073 (0.107)\tDT 0.000 (0.025)\tloss 0.235 (0.216)\tpurity 100.000 (100.000)\t\n","Train: [138][20/23]\tBT 0.066 (0.093)\tDT 0.000 (0.014)\tloss 0.376 (0.216)\tpurity 100.000 (100.000)\t\n","epoch 138, total time 2.11\n","LR: 0.010947915553696733\n","==> training...\n","Train: [139][10/23]\tBT 0.064 (0.104)\tDT 0.000 (0.033)\tloss 0.203 (0.221)\tpurity 100.000 (100.000)\t\n","Train: [139][20/23]\tBT 0.064 (0.097)\tDT 0.000 (0.022)\tloss 0.139 (0.200)\tpurity 100.000 (100.000)\t\n","epoch 139, total time 2.18\n","LR: 0.010624868698918037\n","==> training...\n","Train: [140][10/23]\tBT 0.083 (0.106)\tDT 0.005 (0.034)\tloss 0.192 (0.197)\tpurity 100.000 (100.000)\t\n","Train: [140][20/23]\tBT 0.065 (0.094)\tDT 0.000 (0.022)\tloss 0.145 (0.193)\tpurity 100.000 (100.000)\t\n","epoch 140, total time 2.13\n","==> Saving...\n","LR: 0.010305368692688175\n","==> training...\n","Train: [141][10/23]\tBT 0.076 (0.101)\tDT 0.000 (0.025)\tloss 0.385 (0.211)\tpurity 100.000 (100.000)\t\n","Train: [141][20/23]\tBT 0.107 (0.095)\tDT 0.039 (0.018)\tloss 0.164 (0.202)\tpurity 100.000 (100.000)\t\n","epoch 141, total time 2.14\n","LR: 0.009989494366852904\n","==> training...\n","Train: [142][10/23]\tBT 0.066 (0.104)\tDT 0.001 (0.036)\tloss 0.148 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [142][20/23]\tBT 0.087 (0.100)\tDT 0.000 (0.027)\tloss 0.175 (0.190)\tpurity 100.000 (100.000)\t\n","epoch 142, total time 2.26\n","LR: 0.009677323658675586\n","==> training...\n","Train: [143][10/23]\tBT 0.064 (0.103)\tDT 0.000 (0.025)\tloss 0.172 (0.195)\tpurity 100.000 (100.000)\t\n","Train: [143][20/23]\tBT 0.074 (0.094)\tDT 0.001 (0.019)\tloss 0.189 (0.205)\tpurity 100.000 (100.000)\t\n","epoch 143, total time 2.14\n","LR: 0.00936893359160737\n","==> training...\n","Train: [144][10/23]\tBT 0.070 (0.108)\tDT 0.000 (0.036)\tloss 0.149 (0.177)\tpurity 100.000 (100.000)\t\n","Train: [144][20/23]\tBT 0.069 (0.098)\tDT 0.000 (0.028)\tloss 0.194 (0.203)\tpurity 100.000 (100.000)\t\n","epoch 144, total time 2.24\n","LR: 0.009064400256282757\n","==> training...\n","Train: [145][10/23]\tBT 0.063 (0.105)\tDT 0.000 (0.025)\tloss 0.277 (0.234)\tpurity 100.000 (100.000)\t\n","Train: [145][20/23]\tBT 0.067 (0.112)\tDT 0.000 (0.021)\tloss 0.248 (0.217)\tpurity 100.000 (100.000)\t\n","epoch 145, total time 2.51\n","LR: 0.008763798791745412\n","==> training...\n","Train: [146][10/23]\tBT 0.065 (0.105)\tDT 0.000 (0.029)\tloss 0.136 (0.198)\tpurity 100.000 (100.000)\t\n","Train: [146][20/23]\tBT 0.080 (0.094)\tDT 0.000 (0.017)\tloss 0.163 (0.187)\tpurity 100.000 (100.000)\t\n","epoch 146, total time 2.12\n","LR: 0.008467203366908708\n","==> training...\n","Train: [147][10/23]\tBT 0.081 (0.105)\tDT 0.000 (0.036)\tloss 0.147 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [147][20/23]\tBT 0.078 (0.093)\tDT 0.000 (0.023)\tloss 0.153 (0.199)\tpurity 100.000 (100.000)\t\n","epoch 147, total time 2.11\n","LR: 0.008174687162255665\n","==> training...\n","Train: [148][10/23]\tBT 0.109 (0.105)\tDT 0.036 (0.030)\tloss 0.264 (0.215)\tpurity 100.000 (100.000)\t\n","Train: [148][20/23]\tBT 0.068 (0.094)\tDT 0.000 (0.016)\tloss 0.171 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 148, total time 2.12\n","LR: 0.007886322351782783\n","==> training...\n","Train: [149][10/23]\tBT 0.080 (0.103)\tDT 0.000 (0.025)\tloss 0.184 (0.202)\tpurity 100.000 (100.000)\t\n","Train: [149][20/23]\tBT 0.074 (0.093)\tDT 0.003 (0.016)\tloss 0.114 (0.197)\tpurity 100.000 (100.000)\t\n","epoch 149, total time 2.12\n","LR: 0.0076021800851921425\n","==> training...\n","Train: [150][10/23]\tBT 0.069 (0.106)\tDT 0.000 (0.024)\tloss 0.163 (0.171)\tpurity 100.000 (100.000)\t\n","Train: [150][20/23]\tBT 0.064 (0.091)\tDT 0.000 (0.013)\tloss 0.223 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 150, total time 2.08\n","==> Saving...\n","LR: 0.0073223304703363135\n","==> training...\n","Train: [151][10/23]\tBT 0.095 (0.106)\tDT 0.011 (0.027)\tloss 0.135 (0.234)\tpurity 100.000 (100.000)\t\n","Train: [151][20/23]\tBT 0.086 (0.096)\tDT 0.001 (0.017)\tloss 0.233 (0.231)\tpurity 100.000 (100.000)\t\n","epoch 151, total time 2.16\n","LR: 0.007046842555920283\n","==> training...\n","Train: [152][10/23]\tBT 0.073 (0.103)\tDT 0.000 (0.027)\tloss 0.234 (0.249)\tpurity 100.000 (100.000)\t\n","Train: [152][20/23]\tBT 0.074 (0.094)\tDT 0.000 (0.019)\tloss 0.175 (0.215)\tpurity 100.000 (100.000)\t\n","epoch 152, total time 2.13\n","LR: 0.006775784314464717\n","==> training...\n","Train: [153][10/23]\tBT 0.090 (0.112)\tDT 0.006 (0.039)\tloss 0.243 (0.195)\tpurity 100.000 (100.000)\t\n","Train: [153][20/23]\tBT 0.071 (0.097)\tDT 0.000 (0.025)\tloss 0.322 (0.203)\tpurity 100.000 (100.000)\t\n","epoch 153, total time 2.18\n","LR: 0.006509222625534755\n","==> training...\n","Train: [154][10/23]\tBT 0.085 (0.112)\tDT 0.000 (0.039)\tloss 0.200 (0.200)\tpurity 100.000 (100.000)\t\n","Train: [154][20/23]\tBT 0.064 (0.098)\tDT 0.000 (0.025)\tloss 0.170 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 154, total time 2.19\n","LR: 0.0062472232592385105\n","==> training...\n","Train: [155][10/23]\tBT 0.081 (0.108)\tDT 0.000 (0.031)\tloss 0.205 (0.204)\tpurity 100.000 (100.000)\t\n","Train: [155][20/23]\tBT 0.113 (0.107)\tDT 0.022 (0.022)\tloss 0.220 (0.218)\tpurity 100.000 (100.000)\t\n","epoch 155, total time 2.45\n","LR: 0.005989850859999227\n","==> training...\n","Train: [156][10/23]\tBT 0.073 (0.108)\tDT 0.000 (0.038)\tloss 0.147 (0.205)\tpurity 100.000 (100.000)\t\n","Train: [156][20/23]\tBT 0.081 (0.098)\tDT 0.000 (0.025)\tloss 0.121 (0.182)\tpurity 100.000 (100.000)\t\n","epoch 156, total time 2.20\n","LR: 0.005737168930605272\n","==> training...\n","Train: [157][10/23]\tBT 0.079 (0.105)\tDT 0.011 (0.026)\tloss 0.158 (0.228)\tpurity 100.000 (100.000)\t\n","Train: [157][20/23]\tBT 0.101 (0.095)\tDT 0.035 (0.019)\tloss 0.191 (0.212)\tpurity 100.000 (100.000)\t\n","epoch 157, total time 2.17\n","LR: 0.005489239816541761\n","==> training...\n","Train: [158][10/23]\tBT 0.087 (0.108)\tDT 0.000 (0.031)\tloss 0.205 (0.187)\tpurity 100.000 (100.000)\t\n","Train: [158][20/23]\tBT 0.065 (0.094)\tDT 0.000 (0.020)\tloss 0.151 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 158, total time 2.13\n","LR: 0.00524612469060774\n","==> training...\n","Train: [159][10/23]\tBT 0.083 (0.101)\tDT 0.017 (0.032)\tloss 0.176 (0.164)\tpurity 100.000 (100.000)\t\n","Train: [159][20/23]\tBT 0.120 (0.096)\tDT 0.024 (0.025)\tloss 0.261 (0.192)\tpurity 100.000 (100.000)\t\n","epoch 159, total time 2.19\n","LR: 0.005007883537822735\n","==> training...\n","Train: [160][10/23]\tBT 0.076 (0.110)\tDT 0.000 (0.035)\tloss 0.164 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [160][20/23]\tBT 0.086 (0.097)\tDT 0.000 (0.020)\tloss 0.213 (0.190)\tpurity 100.000 (100.000)\t\n","epoch 160, total time 2.18\n","==> Saving...\n","LR: 0.004774575140626317\n","==> training...\n","Train: [161][10/23]\tBT 0.099 (0.108)\tDT 0.000 (0.034)\tloss 0.198 (0.168)\tpurity 100.000 (100.000)\t\n","Train: [161][20/23]\tBT 0.074 (0.096)\tDT 0.000 (0.018)\tloss 0.252 (0.200)\tpurity 100.000 (100.000)\t\n","epoch 161, total time 2.16\n","LR: 0.004546257064374418\n","==> training...\n","Train: [162][10/23]\tBT 0.065 (0.104)\tDT 0.000 (0.026)\tloss 0.163 (0.219)\tpurity 100.000 (100.000)\t\n","Train: [162][20/23]\tBT 0.094 (0.097)\tDT 0.000 (0.020)\tloss 0.201 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 162, total time 2.18\n","LR: 0.004322985643135957\n","==> training...\n","Train: [163][10/23]\tBT 0.066 (0.108)\tDT 0.000 (0.029)\tloss 0.221 (0.227)\tpurity 100.000 (100.000)\t\n","Train: [163][20/23]\tBT 0.098 (0.098)\tDT 0.024 (0.024)\tloss 0.230 (0.221)\tpurity 100.000 (100.000)\t\n","epoch 163, total time 2.21\n","LR: 0.004104815965793249\n","==> training...\n","Train: [164][10/23]\tBT 0.067 (0.105)\tDT 0.002 (0.031)\tloss 0.217 (0.210)\tpurity 100.000 (100.000)\t\n","Train: [164][20/23]\tBT 0.069 (0.099)\tDT 0.000 (0.024)\tloss 0.174 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 164, total time 2.22\n","LR: 0.003891801862449629\n","==> training...\n","Train: [165][10/23]\tBT 0.156 (0.117)\tDT 0.000 (0.032)\tloss 0.236 (0.226)\tpurity 100.000 (100.000)\t\n","Train: [165][20/23]\tBT 0.065 (0.117)\tDT 0.001 (0.033)\tloss 0.228 (0.214)\tpurity 100.000 (100.000)\t\n","epoch 165, total time 2.60\n","LR: 0.0036839958911477014\n","==> training...\n","Train: [166][10/23]\tBT 0.073 (0.108)\tDT 0.000 (0.027)\tloss 0.245 (0.234)\tpurity 100.000 (100.000)\t\n","Train: [166][20/23]\tBT 0.083 (0.096)\tDT 0.000 (0.018)\tloss 0.182 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 166, total time 2.16\n","LR: 0.0034814493249014063\n","==> training...\n","Train: [167][10/23]\tBT 0.067 (0.105)\tDT 0.002 (0.034)\tloss 0.107 (0.193)\tpurity 100.000 (100.000)\t\n","Train: [167][20/23]\tBT 0.089 (0.096)\tDT 0.014 (0.022)\tloss 0.178 (0.210)\tpurity 100.000 (100.000)\t\n","epoch 167, total time 2.19\n","LR: 0.0032842121390452175\n","==> training...\n","Train: [168][10/23]\tBT 0.065 (0.105)\tDT 0.002 (0.026)\tloss 0.192 (0.228)\tpurity 100.000 (100.000)\t\n","Train: [168][20/23]\tBT 0.064 (0.096)\tDT 0.000 (0.020)\tloss 0.297 (0.236)\tpurity 100.000 (100.000)\t\n","epoch 168, total time 2.17\n","LR: 0.0030923329989034107\n","==> training...\n","Train: [169][10/23]\tBT 0.083 (0.112)\tDT 0.000 (0.028)\tloss 0.144 (0.205)\tpurity 100.000 (100.000)\t\n","Train: [169][20/23]\tBT 0.083 (0.097)\tDT 0.000 (0.016)\tloss 0.192 (0.218)\tpurity 100.000 (100.000)\t\n","epoch 169, total time 2.22\n","LR: 0.0029058592477826635\n","==> training...\n","Train: [170][10/23]\tBT 0.079 (0.107)\tDT 0.001 (0.025)\tloss 0.160 (0.183)\tpurity 100.000 (100.000)\t\n","Train: [170][20/23]\tBT 0.074 (0.095)\tDT 0.000 (0.018)\tloss 0.157 (0.203)\tpurity 100.000 (100.000)\t\n","epoch 170, total time 2.17\n","==> Saving...\n","LR: 0.0027248368952908055\n","==> training...\n","Train: [171][10/23]\tBT 0.091 (0.109)\tDT 0.022 (0.030)\tloss 0.375 (0.206)\tpurity 100.000 (100.000)\t\n","Train: [171][20/23]\tBT 0.102 (0.098)\tDT 0.029 (0.021)\tloss 0.260 (0.207)\tpurity 100.000 (100.000)\t\n","epoch 171, total time 2.19\n","LR: 0.002549310605984612\n","==> training...\n","Train: [172][10/23]\tBT 0.099 (0.114)\tDT 0.000 (0.040)\tloss 0.153 (0.158)\tpurity 100.000 (100.000)\t\n","Train: [172][20/23]\tBT 0.091 (0.098)\tDT 0.000 (0.023)\tloss 0.290 (0.182)\tpurity 100.000 (100.000)\t\n","epoch 172, total time 2.20\n","LR: 0.0023793236883495163\n","==> training...\n","Train: [173][10/23]\tBT 0.071 (0.108)\tDT 0.000 (0.038)\tloss 0.181 (0.227)\tpurity 100.000 (100.000)\t\n","Train: [173][20/23]\tBT 0.072 (0.097)\tDT 0.000 (0.026)\tloss 0.168 (0.217)\tpurity 100.000 (100.000)\t\n","epoch 173, total time 2.20\n","LR: 0.002214918084113873\n","==> training...\n","Train: [174][10/23]\tBT 0.097 (0.112)\tDT 0.000 (0.036)\tloss 0.108 (0.181)\tpurity 100.000 (100.000)\t\n","Train: [174][20/23]\tBT 0.074 (0.099)\tDT 0.000 (0.025)\tloss 0.264 (0.189)\tpurity 100.000 (100.000)\t\n","epoch 174, total time 2.21\n","LR: 0.0020561343579004773\n","==> training...\n","Train: [175][10/23]\tBT 0.112 (0.119)\tDT 0.000 (0.031)\tloss 0.146 (0.164)\tpurity 100.000 (100.000)\t\n","Train: [175][20/23]\tBT 0.075 (0.114)\tDT 0.000 (0.024)\tloss 0.213 (0.185)\tpurity 100.000 (100.000)\t\n","epoch 175, total time 2.52\n","LR: 0.0019030116872178371\n","==> training...\n","Train: [176][10/23]\tBT 0.067 (0.107)\tDT 0.000 (0.038)\tloss 0.175 (0.199)\tpurity 100.000 (100.000)\t\n","Train: [176][20/23]\tBT 0.064 (0.095)\tDT 0.000 (0.026)\tloss 0.143 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 176, total time 2.18\n","LR: 0.0017555878527937164\n","==> training...\n","Train: [177][10/23]\tBT 0.073 (0.104)\tDT 0.000 (0.031)\tloss 0.258 (0.213)\tpurity 100.000 (100.000)\t\n","Train: [177][20/23]\tBT 0.079 (0.095)\tDT 0.000 (0.023)\tloss 0.176 (0.206)\tpurity 100.000 (100.000)\t\n","epoch 177, total time 2.16\n","LR: 0.0016138992292533156\n","==> training...\n","Train: [178][10/23]\tBT 0.086 (0.102)\tDT 0.014 (0.029)\tloss 0.262 (0.183)\tpurity 100.000 (100.000)\t\n","Train: [178][20/23]\tBT 0.110 (0.097)\tDT 0.045 (0.023)\tloss 0.302 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 178, total time 2.18\n","LR: 0.0014779807761443637\n","==> training...\n","Train: [179][10/23]\tBT 0.089 (0.102)\tDT 0.026 (0.027)\tloss 0.223 (0.177)\tpurity 100.000 (100.000)\t\n","Train: [179][20/23]\tBT 0.096 (0.096)\tDT 0.033 (0.024)\tloss 0.170 (0.175)\tpurity 100.000 (100.000)\t\n","epoch 179, total time 2.17\n","LR: 0.0013478660293113677\n","==> training...\n","Train: [180][10/23]\tBT 0.064 (0.108)\tDT 0.000 (0.035)\tloss 0.149 (0.222)\tpurity 100.000 (100.000)\t\n","Train: [180][20/23]\tBT 0.077 (0.097)\tDT 0.000 (0.022)\tloss 0.151 (0.222)\tpurity 100.000 (100.000)\t\n","epoch 180, total time 2.18\n","==> Saving...\n","LR: 0.0012235870926211618\n","==> training...\n","Train: [181][10/23]\tBT 0.101 (0.107)\tDT 0.032 (0.032)\tloss 0.139 (0.176)\tpurity 100.000 (100.000)\t\n","Train: [181][20/23]\tBT 0.086 (0.097)\tDT 0.000 (0.019)\tloss 0.176 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 181, total time 2.17\n","LR: 0.001105174630041747\n","==> training...\n","Train: [182][10/23]\tBT 0.085 (0.110)\tDT 0.000 (0.037)\tloss 0.140 (0.190)\tpurity 100.000 (100.000)\t\n","Train: [182][20/23]\tBT 0.064 (0.096)\tDT 0.000 (0.024)\tloss 0.171 (0.219)\tpurity 100.000 (100.000)\t\n","epoch 182, total time 2.20\n","LR: 0.0009926578580764262\n","==> training...\n","Train: [183][10/23]\tBT 0.086 (0.110)\tDT 0.000 (0.034)\tloss 0.191 (0.189)\tpurity 100.000 (100.000)\t\n","Train: [183][20/23]\tBT 0.065 (0.101)\tDT 0.000 (0.022)\tloss 0.129 (0.188)\tpurity 100.000 (100.000)\t\n","epoch 183, total time 2.25\n","LR: 0.0008860645385550509\n","==> training...\n","Train: [184][10/23]\tBT 0.081 (0.106)\tDT 0.000 (0.032)\tloss 0.164 (0.211)\tpurity 100.000 (100.000)\t\n","Train: [184][20/23]\tBT 0.079 (0.097)\tDT 0.000 (0.023)\tloss 0.159 (0.201)\tpurity 100.000 (100.000)\t\n","epoch 184, total time 2.20\n","LR: 0.0007854209717842259\n","==> training...\n","Train: [185][10/23]\tBT 0.140 (0.120)\tDT 0.001 (0.043)\tloss 0.173 (0.171)\tpurity 100.000 (100.000)\t\n","Train: [185][20/23]\tBT 0.066 (0.114)\tDT 0.000 (0.034)\tloss 0.365 (0.186)\tpurity 100.000 (100.000)\t\n","epoch 185, total time 2.53\n","LR: 0.0006907519900580862\n","==> training...\n","Train: [186][10/23]\tBT 0.064 (0.105)\tDT 0.000 (0.030)\tloss 0.116 (0.179)\tpurity 100.000 (100.000)\t\n","Train: [186][20/23]\tBT 0.075 (0.097)\tDT 0.009 (0.024)\tloss 0.121 (0.176)\tpurity 100.000 (100.000)\t\n","epoch 186, total time 2.18\n","LR: 0.0006020809515313169\n","==> training...\n","Train: [187][10/23]\tBT 0.067 (0.104)\tDT 0.002 (0.027)\tloss 0.161 (0.173)\tpurity 100.000 (100.000)\t\n","Train: [187][20/23]\tBT 0.064 (0.095)\tDT 0.000 (0.022)\tloss 0.286 (0.188)\tpurity 100.000 (100.000)\t\n","epoch 187, total time 2.18\n","LR: 0.0005194297344558535\n","==> training...\n","Train: [188][10/23]\tBT 0.073 (0.109)\tDT 0.000 (0.037)\tloss 0.156 (0.180)\tpurity 100.000 (100.000)\t\n","Train: [188][20/23]\tBT 0.076 (0.095)\tDT 0.000 (0.020)\tloss 0.221 (0.191)\tpurity 100.000 (100.000)\t\n","epoch 188, total time 2.15\n","LR: 0.000442818731782782\n","==> training...\n","Train: [189][10/23]\tBT 0.066 (0.105)\tDT 0.000 (0.029)\tloss 0.166 (0.218)\tpurity 100.000 (100.000)\t\n","Train: [189][20/23]\tBT 0.073 (0.095)\tDT 0.000 (0.022)\tloss 0.231 (0.208)\tpurity 100.000 (100.000)\t\n","epoch 189, total time 2.16\n","LR: 0.00037226684613065334\n","==> training...\n","Train: [190][10/23]\tBT 0.074 (0.102)\tDT 0.000 (0.030)\tloss 0.262 (0.182)\tpurity 100.000 (100.000)\t\n","Train: [190][20/23]\tBT 0.064 (0.095)\tDT 0.000 (0.018)\tloss 0.347 (0.209)\tpurity 100.000 (100.000)\t\n","epoch 190, total time 2.15\n","==> Saving...\n","LR: 0.00030779148512155856\n","==> training...\n","Train: [191][10/23]\tBT 0.075 (0.105)\tDT 0.000 (0.035)\tloss 0.193 (0.183)\tpurity 100.000 (100.000)\t\n","Train: [191][20/23]\tBT 0.075 (0.096)\tDT 0.000 (0.023)\tloss 0.184 (0.198)\tpurity 100.000 (100.000)\t\n","epoch 191, total time 2.18\n","LR: 0.0002494085570860616\n","==> training...\n","Train: [192][10/23]\tBT 0.069 (0.109)\tDT 0.000 (0.038)\tloss 0.249 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [192][20/23]\tBT 0.090 (0.098)\tDT 0.000 (0.025)\tloss 0.146 (0.198)\tpurity 100.000 (100.000)\t\n","epoch 192, total time 2.21\n","LR: 0.0001971324671380559\n","==> training...\n","Train: [193][10/23]\tBT 0.073 (0.106)\tDT 0.000 (0.027)\tloss 0.158 (0.198)\tpurity 100.000 (100.000)\t\n","Train: [193][20/23]\tBT 0.076 (0.097)\tDT 0.000 (0.023)\tloss 0.430 (0.213)\tpurity 100.000 (100.000)\t\n","epoch 193, total time 2.19\n","LR: 0.00015097611362051012\n","==> training...\n","Train: [194][10/23]\tBT 0.087 (0.108)\tDT 0.000 (0.030)\tloss 0.127 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [194][20/23]\tBT 0.069 (0.096)\tDT 0.000 (0.019)\tloss 0.298 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 194, total time 2.16\n","LR: 0.0001109508849230001\n","==> training...\n","Train: [195][10/23]\tBT 0.246 (0.121)\tDT 0.117 (0.042)\tloss 0.168 (0.189)\tpurity 100.000 (100.000)\t\n","Train: [195][20/23]\tBT 0.076 (0.114)\tDT 0.000 (0.031)\tloss 0.275 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 195, total time 2.57\n","LR: 7.70666566718009e-05\n","==> training...\n","Train: [196][10/23]\tBT 0.100 (0.121)\tDT 0.001 (0.035)\tloss 0.329 (0.228)\tpurity 100.000 (100.000)\t\n","Train: [196][20/23]\tBT 0.065 (0.102)\tDT 0.000 (0.023)\tloss 0.463 (0.216)\tpurity 100.000 (100.000)\t\n","epoch 196, total time 2.28\n","LR: 4.933178929321103e-05\n","==> training...\n","Train: [197][10/23]\tBT 0.070 (0.104)\tDT 0.001 (0.027)\tloss 0.135 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [197][20/23]\tBT 0.084 (0.097)\tDT 0.000 (0.020)\tloss 0.180 (0.195)\tpurity 100.000 (100.000)\t\n","epoch 197, total time 2.19\n","LR: 2.775312595075241e-05\n","==> training...\n","Train: [198][10/23]\tBT 0.069 (0.105)\tDT 0.002 (0.025)\tloss 0.131 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [198][20/23]\tBT 0.078 (0.095)\tDT 0.000 (0.015)\tloss 0.223 (0.204)\tpurity 100.000 (100.000)\t\n","epoch 198, total time 2.17\n","LR: 1.233599085671e-05\n","==> training...\n","Train: [199][10/23]\tBT 0.077 (0.106)\tDT 0.001 (0.028)\tloss 0.202 (0.194)\tpurity 100.000 (100.000)\t\n","Train: [199][20/23]\tBT 0.093 (0.096)\tDT 0.013 (0.020)\tloss 0.248 (0.196)\tpurity 100.000 (100.000)\t\n","epoch 199, total time 2.19\n","LR: 3.0841879584853073e-06\n","==> training...\n","Train: [200][10/23]\tBT 0.082 (0.112)\tDT 0.000 (0.029)\tloss 0.188 (0.195)\tpurity 100.000 (100.000)\t\n","Train: [200][20/23]\tBT 0.066 (0.094)\tDT 0.000 (0.017)\tloss 0.157 (0.212)\tpurity 100.000 (100.000)\t\n","epoch 200, total time 2.16\n","==> Saving...\n"]}]},{"cell_type":"markdown","source":["### Graphs"],"metadata":{"id":"tISDTul2rLhi"}},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + str(epochs) + '.pth')\n","history_df = cpkt['history_df']"],"metadata":{"id":"mxJcEVaHrOa5","executionInfo":{"status":"ok","timestamp":1651693243650,"user_tz":420,"elapsed":480,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["_ = history_df['loss'].plot.line(xlabel='epochs', ylabel='loss', color='orange')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"7y3ii5bUsr25","executionInfo":{"status":"ok","timestamp":1651693243652,"user_tz":420,"elapsed":31,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"43c79c68-1e6d-47a0-cc0c-c0170b25c5c5"},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df['purity'].plot.line(xlabel='epochs', ylabel='purity')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"oGM9Ul3IwpL9","executionInfo":{"status":"ok","timestamp":1651693243653,"user_tz":420,"elapsed":28,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"ba05560b-56b8-48c0-8c7b-caeef67a66db"},"execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"7VPzfg2rTQPH","executionInfo":{"status":"ok","timestamp":1651693243654,"user_tz":420,"elapsed":27,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["# Linear Evaluation"],"metadata":{"id":"rWpGZ0dmqWqI"}},{"cell_type":"markdown","source":["### Misc Setup"],"metadata":{"id":"VzeXb2y52ktA"}},{"cell_type":"code","source":["def save_checkpoint(state, is_best, save_dir):\n","    ckpt_path = os.path.join(save_dir, 'checkpoint.pth.tar')\n","    torch.save(state, ckpt_path)\n","    if is_best:\n","        best_ckpt_path = os.path.join(save_dir, 'model_best.pth.tar')\n","        shutil.copyfile(ckpt_path, best_ckpt_path)"],"metadata":{"id":"a23gwiZuVeb3","executionInfo":{"status":"ok","timestamp":1651693904753,"user_tz":420,"elapsed":401,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)"],"metadata":{"id":"8YB15TJKWHFf","executionInfo":{"status":"ok","timestamp":1651693905131,"user_tz":420,"elapsed":18,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["class ProgressMeter(object):\n","    def __init__(self, num_batches, meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def display(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        return '\\t'.join(entries)\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"],"metadata":{"id":"UwoVG510W5Wg","executionInfo":{"status":"ok","timestamp":1651693905131,"user_tz":420,"elapsed":17,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        _, pred = output.topk(maxk, 1, True, True)\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","        # pdb.set_trace()\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"metadata":{"id":"F8UiiXrgXETR","executionInfo":{"status":"ok","timestamp":1651693905132,"user_tz":420,"elapsed":17,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["### Load Model"],"metadata":{"id":"d9Ho4O8VWM4N"}},{"cell_type":"code","source":["def load_weights(model, wts_path):\n","    wts = torch.load(wts_path)\n","    # pdb.set_trace()\n","    if 'state_dict' in wts:\n","        ckpt = wts['state_dict']\n","    elif 'model' in wts:\n","        ckpt = wts['model']\n","    else:\n","        ckpt = wts\n","\n","    ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n","    ckpt = {k: v for k, v in ckpt.items() if 'encoder_t' not in k}\n","    ckpt = {k.replace('encoder_q.', ''): v for k, v in ckpt.items()}\n","    state_dict = {}\n","\n","    for m_key, m_val in model.state_dict().items():\n","        if m_key in ckpt:\n","            state_dict[m_key] = ckpt[m_key]\n","        else:\n","            state_dict[m_key] = m_val\n","            print('not copied => ' + m_key)\n","\n","    model.load_state_dict(state_dict)"],"metadata":{"id":"6Edp6TK5qbKw","executionInfo":{"status":"ok","timestamp":1651693905133,"user_tz":420,"elapsed":17,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["def get_model(arch, output_dim, wts_path):\n","    model, _ = initialize_encoder(arch, output_dim)\n","    load_weights(model, wts_path)\n","\n","    for p in model.parameters():\n","        p.requires_grad = False\n","\n","    return model"],"metadata":{"id":"llr6zKaHv_Mw","executionInfo":{"status":"ok","timestamp":1651693905133,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["class Normalize(nn.Module):\n","    def forward(self, x):\n","        return x / x.norm(2, dim=1, keepdim=True)\n","\n","\n","class FullBatchNorm(nn.Module):\n","    def __init__(self, var, mean):\n","        super(FullBatchNorm, self).__init__()\n","        self.register_buffer('inv_std', (1.0 / torch.sqrt(var + 1e-5)))\n","        self.register_buffer('mean', mean)\n","\n","    def forward(self, x):\n","        return (x - self.mean) * self.inv_std"],"metadata":{"id":"L35H3XpAwAPY","executionInfo":{"status":"ok","timestamp":1651693905134,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["def normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)"],"metadata":{"id":"_G27DtRTwbnw","executionInfo":{"status":"ok","timestamp":1651693905135,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["def get_feats(loader, model, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, ptr = None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = normalize(model(images)).cpu()\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets.argmax(axis=1))\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","    return feats, labels"],"metadata":{"id":"ue02EocuyLgy","executionInfo":{"status":"ok","timestamp":1651693905136,"user_tz":420,"elapsed":15,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["### Training Functions"],"metadata":{"id":"uYvYec8y2n8g"}},{"cell_type":"code","source":["def train(train_loader, backbone, linear, optimizer, epoch, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(train_loader),\n","        [batch_time, data_time, losses, top1, top2],\n","        prefix=\"Epoch: [{}]\".format(epoch))\n","\n","    # switch to train mode\n","    backbone.eval()\n","    linear.train()\n","\n","    end = time.time()\n","    for i, (indices, images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # compute output\n","        with torch.no_grad():\n","            output = backbone(images)\n","        output = linear(output)\n","        loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","        # measure accuracy and record loss\n","        acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","        losses.update(loss.item(), images.size(0))\n","        top1.update(acc1[0], images.size(0))\n","        top2.update(acc2[0], images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            print(progress.display(i))\n","\n","    return losses.avg, top1.avg.item(), top2.avg.item()"],"metadata":{"id":"1gWHh9br2g-T","executionInfo":{"status":"ok","timestamp":1651693905138,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["def validate(val_loader, backbone, linear, print_freq, logger):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top2 = AverageMeter('Acc@2', ':6.2f')\n","    progress = ProgressMeter(\n","        len(val_loader),\n","        [batch_time, losses, top1, top2],\n","        prefix='Test: ')\n","\n","    backbone.eval()\n","    linear.eval()\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (indices, images, target) in enumerate(val_loader):\n","            images = images.cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = backbone(images)\n","            output = linear(output)\n","            loss = F.binary_cross_entropy_with_logits(output, target)\n","\n","            # measure accuracy and record loss\n","            \n","            acc1, acc2 = accuracy(output, target.argmax(axis=1), topk=(1, 2))\n","            losses.update(loss.item(), images.size(0))\n","            top1.update(acc1[0], images.size(0))\n","            top2.update(acc2[0], images.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","        # TODO: this should also be done with the ProgressMeter\n","        print(' * Acc@1 {top1.avg:.3f} Acc@2 {top2.avg:.3f}'\n","              .format(top1=top1, top2=top2))\n","\n","    return losses.avg, top1.avg.item(), top2.avg.item()"],"metadata":{"id":"tzM_L9xK3qP2","executionInfo":{"status":"ok","timestamp":1651693905139,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["def main_worker(data, label_fn, weights, save, logger=None, batch_size=16, workers=2, \n","                epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                resume=None, evaluate=False, n_classes=4, output_dim=16):\n","    best_acc1 = 0\n","    best_loss = np.inf\n","\n","    # Data loading code\n","    traindir = os.path.join(data, 'train')\n","    valdir = os.path.join(data, 'val')\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","\n","    train_transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.RandomRotation((0, 360)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    train_dataset = Image_Dataset(traindir, label_fn, train_transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size, shuffle=True,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(valdir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    train_val_loader = torch.utils.data.DataLoader(\n","        Image_Dataset(traindir, label_fn, val_transform),\n","        batch_size=batch_size, shuffle=False,\n","        num_workers=workers, pin_memory=True,\n","    )\n","\n","    backbone = get_model(arch, output_dim, weights)\n","    backbone = nn.DataParallel(backbone).cuda()\n","    backbone.eval()\n","\n","\n","    cached_feats = '%s/var_mean.pth.tar' % save\n","    if not os.path.exists(cached_feats):\n","        train_feats, _ = get_feats(train_val_loader, backbone, print_freq, logger)\n","        train_var, train_mean = torch.var_mean(train_feats, dim=0)\n","        torch.save((train_var, train_mean), cached_feats)\n","    else:\n","        train_var, train_mean = torch.load(cached_feats)\n","    if mlp:\n","        c = output_dim\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(output_dim, c),\n","            nn.BatchNorm1d(c),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(c, n_classes),\n","        )\n","    else:\n","        linear = nn.Sequential(\n","            Normalize(),\n","            FullBatchNorm(train_var, train_mean),\n","            nn.Linear(output_dim, n_classes)\n","        )\n","\n","    print(backbone)\n","    print(linear)\n","\n","    linear = linear.cuda()\n","\n","    optimizer = torch.optim.SGD(linear.parameters(),\n","                                lr,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay)\n","\n","    sched = [int(x) for x in lr_schedule.split(',')]\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer, milestones=sched\n","    )\n","\n","    start_epoch = 0\n","    history_df = pd.DataFrame(index=range(start_epoch + 1, epochs + 1))\n","\n","    # optionally resume from a checkpoint\n","    if resume:\n","        if os.path.isfile(resume):\n","            print(\"=> loading checkpoint '{}'\".format(resume))\n","            checkpoint = torch.load(resume)\n","            start_epoch = checkpoint['epoch']\n","            linear.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            history_df = checkpoint['history_df']\n","            print(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(resume, checkpoint['epoch']))\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(resume))\n","\n","    cudnn.benchmark = True\n","\n","    if evaluate:\n","        validate(val_loader, backbone, linear, print_freq, logger)\n","        return\n","\n","    for epoch in range(start_epoch, epochs):\n","        # train for one epoch\n","        loss, acc1, acc2 = train(\n","            train_loader, backbone, linear, optimizer, epoch, print_freq, logger)\n","\n","        # evaluate on validation set\n","        val_loss, val_acc1, val_acc2 = validate(\n","            val_loader, backbone, linear, print_freq, logger)\n","        \n","        history_df.loc[epoch + 1, 'train_loss'] = loss\n","        history_df.loc[epoch + 1, 'train_acc1'] = acc1\n","        history_df.loc[epoch + 1, 'train_acc2'] = acc2\n","        history_df.loc[epoch + 1, 'val_loss'] = val_loss\n","        history_df.loc[epoch + 1, 'val_acc1'] = val_acc1\n","        history_df.loc[epoch + 1, 'val_acc2'] = val_acc2\n","\n","        # modify lr\n","        lr_scheduler.step()\n","        # logger.info('LR: {:f}'.format(lr_scheduler.get_last_lr()[-1]))\n","\n","        # remember best acc@1 and save checkpoint\n","        #is_best = val_acc1 > best_acc1\n","        is_best = val_loss < best_loss\n","        if is_best:\n","            best_loss = val_loss\n","\n","\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': linear.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","            'backbone': backbone,\n","            'linear': linear,\n","            'history_df': history_df\n","        }, is_best, save)"],"metadata":{"id":"_44olm-z7fG1","executionInfo":{"status":"ok","timestamp":1651693905772,"user_tz":420,"elapsed":648,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["def main_linear_eval(data, label_fn, weights, save, batch_size=16, workers=2, \n","                     epochs=40, arch='resnet50', print_freq=10, mlp=True, lr=0.01, \n","                     momentum=0.9, weight_decay=1e-4, lr_schedule='15,30,40', \n","                     resume=None, evaluate=False, seed=None, n_classes=4, output_dim=16):\n","    args = locals()\n","    del args['label_fn']\n","\n","    os.makedirs(save, exist_ok=True)\n","    print(args)\n","\n","    if seed is not None:\n","        random.seed(seed)\n","        torch.manual_seed(seed)\n","        cudnn.deterministic = True\n","        warnings.warn('You have chosen to seed training. '\n","                      'This will turn on the CUDNN deterministic setting, '\n","                      'which can slow down your training considerably! '\n","                      'You may see unexpected behavior when restarting '\n","                      'from checkpoints.')\n","\n","    main_worker(data=data, label_fn=label_fn, weights=weights, save=save, \n","                batch_size=batch_size, workers=workers, \n","                epochs=epochs, arch=arch, print_freq=print_freq, mlp=mlp, \n","                lr=lr, momentum=momentum, weight_decay=weight_decay, \n","                lr_schedule=lr_schedule, resume=resume, evaluate=evaluate, \n","                n_classes=n_classes, output_dim=output_dim)"],"metadata":{"id":"EJy6AFcZDlK8","executionInfo":{"status":"ok","timestamp":1651693905777,"user_tz":420,"elapsed":34,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":["### Getting Labels"],"metadata":{"id":"cw-FQg2fHl9Z"}},{"cell_type":"code","source":["labels_df = pd.read_csv(root_path + 'Updated_Cropped_Images_Wound_Stage_Probabilities.csv', index_col='Image')\n","labels_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"Q613sTN9OH9z","executionInfo":{"status":"ok","timestamp":1651693905778,"user_tz":420,"elapsed":34,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"302b9239-0e94-4827-b69f-b9d0a4b55e14"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   hemostasis  inflammatory  proliferative  maturation\n","Image                                                                 \n","Day 8_A8-4-L.png     0.181818      0.090909       0.545455    0.181818\n","Day 4_A8-3-R.png     0.090909      0.909091       0.000000    0.000000\n","Day 14_Y8-4-L.png    0.000000      0.000000       0.090909    0.909091\n","Day 7_Y8-4-L.png     0.000000      0.000000       0.454545    0.545455\n","Day 2_A8-1-L.png     0.181818      0.727273       0.090909    0.000000"],"text/html":["\n","  <div id=\"df-8446754d-e479-476d-a0be-c15622028d88\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hemostasis</th>\n","      <th>inflammatory</th>\n","      <th>proliferative</th>\n","      <th>maturation</th>\n","    </tr>\n","    <tr>\n","      <th>Image</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 8_A8-4-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.090909</td>\n","      <td>0.545455</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-3-R.png</th>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.090909</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454545</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-L.png</th>\n","      <td>0.181818</td>\n","      <td>0.727273</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8446754d-e479-476d-a0be-c15622028d88')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8446754d-e479-476d-a0be-c15622028d88 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8446754d-e479-476d-a0be-c15622028d88');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["labels_df.loc['Day 8_A8-4-L.png'].to_numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpskZYsoPOrq","executionInfo":{"status":"ok","timestamp":1651693905784,"user_tz":420,"elapsed":35,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"742f0bea-2682-495d-d453-59129b2d17f7"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.18181818, 0.09090909, 0.54545455, 0.18181818])"]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["### Epoch number of CMSF to evaluate"],"metadata":{"id":"JpaVfWQTQ8XF"}},{"cell_type":"code","source":["epoch = '100'\n","eval_suffix = '_1_'"],"metadata":{"id":"N9Pe4XCJQO6T","executionInfo":{"status":"ok","timestamp":1651694024057,"user_tz":420,"elapsed":554,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["# Linear Evaluation Training"],"metadata":{"id":"AoS9kV5iOBUC"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"IrWc3kqD1pW3"}},{"cell_type":"code","source":["main_linear_eval(\n","    data=root_path + 'Split_images', \n","    label_fn=lambda x: labels_df.loc[x].to_numpy(), \n","    weights=root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + epoch + '.pth',\n","    save=root_path + 'outputs/' + train_folder_name + 'eval' + eval_suffix + epoch + '/', \n","    batch_size=8, \n","    workers=2, \n","    epochs=40, \n","    arch='resnet', \n","    print_freq=10, \n","    mlp=True, \n","    lr=0.01,\n","    output_dim=16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqLRidzrRF3A","executionInfo":{"status":"ok","timestamp":1651694108588,"user_tz":420,"elapsed":81609,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"70eca1df-6979-40d6-ba80-0051a4c99999"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["{'data': 'gdrive/MyDrive/Explainable_Wound_Classification/Split_images', 'weights': 'gdrive/MyDrive/Explainable_Wound_Classification/outputs/supervised/2_topk5/ckpt_epoch_100.pth', 'save': 'gdrive/MyDrive/Explainable_Wound_Classification/outputs/supervised/2_topk5/eval_1_100/', 'batch_size': 8, 'workers': 2, 'epochs': 40, 'arch': 'resnet', 'print_freq': 10, 'mlp': True, 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_schedule': '15,30,40', 'resume': None, 'evaluate': False, 'seed': None, 'n_classes': 4, 'output_dim': 16}\n","Test: [ 0/24]\tTime  0.225 ( 0.225)\n","Test: [10/24]\tTime  0.059 ( 0.065)\n","Test: [20/24]\tTime  0.055 ( 0.057)\n","DataParallel(\n","  (module): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=16, bias=True)\n","  )\n",")\n","Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=16, out_features=16, bias=True)\n","  (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU(inplace=True)\n","  (5): Linear(in_features=16, out_features=4, bias=True)\n",")\n","Epoch: [0][ 0/24]\tTime  0.223 ( 0.223)\tData  0.183 ( 0.183)\tLoss 7.0686e-01 (7.0686e-01)\tAcc@1  12.50 ( 12.50)\tAcc@2  50.00 ( 50.00)\n","Epoch: [0][10/24]\tTime  0.033 ( 0.064)\tData  0.002 ( 0.030)\tLoss 6.6983e-01 (6.9007e-01)\tAcc@1  37.50 ( 25.00)\tAcc@2  62.50 ( 40.91)\n","Epoch: [0][20/24]\tTime  0.032 ( 0.056)\tData  0.000 ( 0.023)\tLoss 6.0785e-01 (6.6804e-01)\tAcc@1  50.00 ( 30.36)\tAcc@2  75.00 ( 47.62)\n","Test: [0/4]\tTime  0.236 ( 0.236)\tLoss 6.1228e-01 (6.1228e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  62.50 ( 62.50)\n"," * Acc@1 43.750 Acc@2 65.625\n","Epoch: [1][ 0/24]\tTime  0.228 ( 0.228)\tData  0.193 ( 0.193)\tLoss 6.0362e-01 (6.0362e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  62.50 ( 62.50)\n","Epoch: [1][10/24]\tTime  0.063 ( 0.065)\tData  0.035 ( 0.033)\tLoss 5.4676e-01 (5.8425e-01)\tAcc@1  50.00 ( 38.64)\tAcc@2 100.00 ( 71.59)\n","Epoch: [1][20/24]\tTime  0.061 ( 0.057)\tData  0.030 ( 0.025)\tLoss 5.3410e-01 (5.6865e-01)\tAcc@1  75.00 ( 45.24)\tAcc@2  87.50 ( 75.00)\n","Test: [0/4]\tTime  0.249 ( 0.249)\tLoss 5.4693e-01 (5.4693e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 43.750 Acc@2 75.000\n","Epoch: [2][ 0/24]\tTime  0.226 ( 0.226)\tData  0.196 ( 0.196)\tLoss 5.5544e-01 (5.5544e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [2][10/24]\tTime  0.029 ( 0.064)\tData  0.000 ( 0.030)\tLoss 5.1691e-01 (5.2612e-01)\tAcc@1  75.00 ( 51.14)\tAcc@2  75.00 ( 85.23)\n","Epoch: [2][20/24]\tTime  0.066 ( 0.055)\tData  0.031 ( 0.022)\tLoss 5.2409e-01 (5.1785e-01)\tAcc@1  37.50 ( 55.36)\tAcc@2  62.50 ( 86.31)\n","Test: [0/4]\tTime  0.198 ( 0.198)\tLoss 5.1487e-01 (5.1487e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 59.375 Acc@2 75.000\n","Epoch: [3][ 0/24]\tTime  0.215 ( 0.215)\tData  0.183 ( 0.183)\tLoss 4.9201e-01 (4.9201e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [3][10/24]\tTime  0.062 ( 0.061)\tData  0.032 ( 0.030)\tLoss 4.7818e-01 (4.8889e-01)\tAcc@1  75.00 ( 62.50)\tAcc@2 100.00 ( 87.50)\n","Epoch: [3][20/24]\tTime  0.071 ( 0.055)\tData  0.038 ( 0.025)\tLoss 4.9021e-01 (4.8499e-01)\tAcc@1  62.50 ( 63.10)\tAcc@2 100.00 ( 89.29)\n","Test: [0/4]\tTime  0.190 ( 0.190)\tLoss 4.9350e-01 (4.9350e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 59.375 Acc@2 78.125\n","Epoch: [4][ 0/24]\tTime  0.216 ( 0.216)\tData  0.185 ( 0.185)\tLoss 4.5732e-01 (4.5732e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  75.00 ( 75.00)\n","Epoch: [4][10/24]\tTime  0.051 ( 0.062)\tData  0.024 ( 0.032)\tLoss 4.4677e-01 (4.5708e-01)\tAcc@1  50.00 ( 69.32)\tAcc@2  87.50 ( 90.91)\n","Epoch: [4][20/24]\tTime  0.068 ( 0.056)\tData  0.038 ( 0.026)\tLoss 4.7839e-01 (4.6489e-01)\tAcc@1  62.50 ( 64.29)\tAcc@2 100.00 ( 91.07)\n","Test: [0/4]\tTime  0.225 ( 0.225)\tLoss 4.7640e-01 (4.7640e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 56.250 Acc@2 78.125\n","Epoch: [5][ 0/24]\tTime  0.250 ( 0.250)\tData  0.213 ( 0.213)\tLoss 4.4228e-01 (4.4228e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [5][10/24]\tTime  0.043 ( 0.060)\tData  0.013 ( 0.028)\tLoss 4.8342e-01 (4.5753e-01)\tAcc@1  50.00 ( 63.64)\tAcc@2  75.00 ( 85.23)\n","Epoch: [5][20/24]\tTime  0.029 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.9199e-01 (4.6865e-01)\tAcc@1  37.50 ( 58.33)\tAcc@2  75.00 ( 86.31)\n","Test: [0/4]\tTime  0.221 ( 0.221)\tLoss 4.6425e-01 (4.6425e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 59.375 Acc@2 78.125\n","Epoch: [6][ 0/24]\tTime  0.259 ( 0.259)\tData  0.227 ( 0.227)\tLoss 4.5454e-01 (4.5454e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  75.00 ( 75.00)\n","Epoch: [6][10/24]\tTime  0.064 ( 0.063)\tData  0.036 ( 0.031)\tLoss 4.7128e-01 (4.3925e-01)\tAcc@1  75.00 ( 64.77)\tAcc@2 100.00 ( 90.91)\n","Epoch: [6][20/24]\tTime  0.068 ( 0.055)\tData  0.039 ( 0.024)\tLoss 4.2918e-01 (4.3263e-01)\tAcc@1  50.00 ( 67.86)\tAcc@2 100.00 ( 91.07)\n","Test: [0/4]\tTime  0.226 ( 0.226)\tLoss 4.5661e-01 (4.5661e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n"," * Acc@1 62.500 Acc@2 81.250\n","Epoch: [7][ 0/24]\tTime  0.220 ( 0.220)\tData  0.182 ( 0.182)\tLoss 4.3766e-01 (4.3766e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [7][10/24]\tTime  0.055 ( 0.060)\tData  0.027 ( 0.029)\tLoss 4.0652e-01 (4.2803e-01)\tAcc@1  62.50 ( 69.32)\tAcc@2  87.50 ( 93.18)\n","Epoch: [7][20/24]\tTime  0.054 ( 0.053)\tData  0.025 ( 0.022)\tLoss 3.7602e-01 (4.3624e-01)\tAcc@1  75.00 ( 65.48)\tAcc@2  87.50 ( 89.88)\n","Test: [0/4]\tTime  0.211 ( 0.211)\tLoss 4.4807e-01 (4.4807e-01)\tAcc@1  25.00 ( 25.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 53.125 Acc@2 84.375\n","Epoch: [8][ 0/24]\tTime  0.225 ( 0.225)\tData  0.192 ( 0.192)\tLoss 4.2778e-01 (4.2778e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [8][10/24]\tTime  0.046 ( 0.062)\tData  0.006 ( 0.029)\tLoss 4.5355e-01 (4.2547e-01)\tAcc@1  50.00 ( 69.32)\tAcc@2  87.50 ( 88.64)\n","Epoch: [8][20/24]\tTime  0.032 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.5406e-01 (4.2525e-01)\tAcc@1  75.00 ( 67.26)\tAcc@2  87.50 ( 91.07)\n","Test: [0/4]\tTime  0.222 ( 0.222)\tLoss 4.4753e-01 (4.4753e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 62.500 Acc@2 84.375\n","Epoch: [9][ 0/24]\tTime  0.251 ( 0.251)\tData  0.212 ( 0.212)\tLoss 4.2624e-01 (4.2624e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2 100.00 (100.00)\n","Epoch: [9][10/24]\tTime  0.049 ( 0.063)\tData  0.020 ( 0.031)\tLoss 4.7175e-01 (4.3771e-01)\tAcc@1  62.50 ( 54.55)\tAcc@2  75.00 ( 92.05)\n","Epoch: [9][20/24]\tTime  0.047 ( 0.056)\tData  0.019 ( 0.024)\tLoss 4.4020e-01 (4.3054e-01)\tAcc@1  62.50 ( 61.90)\tAcc@2 100.00 ( 93.45)\n","Test: [0/4]\tTime  0.209 ( 0.209)\tLoss 4.3555e-01 (4.3555e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 62.500 Acc@2 84.375\n","Epoch: [10][ 0/24]\tTime  0.214 ( 0.214)\tData  0.180 ( 0.180)\tLoss 3.7768e-01 (3.7768e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [10][10/24]\tTime  0.037 ( 0.061)\tData  0.000 ( 0.029)\tLoss 4.6316e-01 (4.0537e-01)\tAcc@1  50.00 ( 69.32)\tAcc@2 100.00 ( 96.59)\n","Epoch: [10][20/24]\tTime  0.031 ( 0.055)\tData  0.000 ( 0.023)\tLoss 4.0792e-01 (4.0759e-01)\tAcc@1  62.50 ( 73.21)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.220 ( 0.220)\tLoss 4.3517e-01 (4.3517e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 65.625 Acc@2 84.375\n","Epoch: [11][ 0/24]\tTime  0.235 ( 0.235)\tData  0.190 ( 0.190)\tLoss 4.0568e-01 (4.0568e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [11][10/24]\tTime  0.030 ( 0.058)\tData  0.000 ( 0.025)\tLoss 4.6044e-01 (4.1978e-01)\tAcc@1  37.50 ( 65.91)\tAcc@2  87.50 ( 93.18)\n","Epoch: [11][20/24]\tTime  0.027 ( 0.054)\tData  0.000 ( 0.021)\tLoss 4.6371e-01 (4.1386e-01)\tAcc@1  62.50 ( 67.86)\tAcc@2  87.50 ( 92.86)\n","Test: [0/4]\tTime  0.220 ( 0.220)\tLoss 4.1959e-01 (4.1959e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 68.750 Acc@2 87.500\n","Epoch: [12][ 0/24]\tTime  0.209 ( 0.209)\tData  0.177 ( 0.177)\tLoss 4.3103e-01 (4.3103e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2 100.00 (100.00)\n","Epoch: [12][10/24]\tTime  0.071 ( 0.065)\tData  0.042 ( 0.032)\tLoss 3.9507e-01 (4.0968e-01)\tAcc@1  62.50 ( 70.45)\tAcc@2  87.50 ( 90.91)\n","Epoch: [12][20/24]\tTime  0.052 ( 0.056)\tData  0.022 ( 0.024)\tLoss 3.8502e-01 (4.1285e-01)\tAcc@1  87.50 ( 69.64)\tAcc@2 100.00 ( 92.26)\n","Test: [0/4]\tTime  0.190 ( 0.190)\tLoss 4.2992e-01 (4.2992e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [13][ 0/24]\tTime  0.251 ( 0.251)\tData  0.219 ( 0.219)\tLoss 3.5524e-01 (3.5524e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [13][10/24]\tTime  0.063 ( 0.068)\tData  0.035 ( 0.037)\tLoss 4.2555e-01 (3.9253e-01)\tAcc@1  87.50 ( 77.27)\tAcc@2 100.00 ( 95.45)\n","Epoch: [13][20/24]\tTime  0.058 ( 0.057)\tData  0.028 ( 0.026)\tLoss 4.7073e-01 (3.9888e-01)\tAcc@1  62.50 ( 73.81)\tAcc@2 100.00 ( 92.86)\n","Test: [0/4]\tTime  0.202 ( 0.202)\tLoss 4.2765e-01 (4.2765e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [14][ 0/24]\tTime  0.224 ( 0.224)\tData  0.185 ( 0.185)\tLoss 4.3758e-01 (4.3758e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [14][10/24]\tTime  0.059 ( 0.063)\tData  0.031 ( 0.031)\tLoss 4.1893e-01 (4.0599e-01)\tAcc@1  62.50 ( 71.59)\tAcc@2  87.50 ( 95.45)\n","Epoch: [14][20/24]\tTime  0.029 ( 0.055)\tData  0.000 ( 0.024)\tLoss 3.4354e-01 (4.0943e-01)\tAcc@1  75.00 ( 71.43)\tAcc@2 100.00 ( 92.86)\n","Test: [0/4]\tTime  0.228 ( 0.228)\tLoss 4.1757e-01 (4.1757e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [15][ 0/24]\tTime  0.208 ( 0.208)\tData  0.175 ( 0.175)\tLoss 3.9120e-01 (3.9120e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [15][10/24]\tTime  0.044 ( 0.061)\tData  0.016 ( 0.028)\tLoss 4.1051e-01 (4.0186e-01)\tAcc@1  75.00 ( 64.77)\tAcc@2  87.50 ( 89.77)\n","Epoch: [15][20/24]\tTime  0.028 ( 0.054)\tData  0.000 ( 0.024)\tLoss 3.8840e-01 (4.0435e-01)\tAcc@1  75.00 ( 66.67)\tAcc@2  87.50 ( 91.07)\n","Test: [0/4]\tTime  0.203 ( 0.203)\tLoss 4.2616e-01 (4.2616e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [16][ 0/24]\tTime  0.217 ( 0.217)\tData  0.184 ( 0.184)\tLoss 4.2171e-01 (4.2171e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [16][10/24]\tTime  0.029 ( 0.061)\tData  0.000 ( 0.030)\tLoss 3.5406e-01 (4.3145e-01)\tAcc@1  87.50 ( 67.05)\tAcc@2 100.00 ( 90.91)\n","Epoch: [16][20/24]\tTime  0.037 ( 0.054)\tData  0.006 ( 0.024)\tLoss 3.3914e-01 (4.1619e-01)\tAcc@1  75.00 ( 68.45)\tAcc@2 100.00 ( 91.67)\n","Test: [0/4]\tTime  0.206 ( 0.206)\tLoss 4.2110e-01 (4.2110e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [17][ 0/24]\tTime  0.196 ( 0.196)\tData  0.164 ( 0.164)\tLoss 4.5149e-01 (4.5149e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  75.00 ( 75.00)\n","Epoch: [17][10/24]\tTime  0.064 ( 0.058)\tData  0.035 ( 0.027)\tLoss 5.6021e-01 (4.1107e-01)\tAcc@1  50.00 ( 77.27)\tAcc@2  62.50 ( 89.77)\n","Epoch: [17][20/24]\tTime  0.066 ( 0.053)\tData  0.036 ( 0.023)\tLoss 3.8460e-01 (4.0512e-01)\tAcc@1  75.00 ( 76.79)\tAcc@2 100.00 ( 92.26)\n","Test: [0/4]\tTime  0.232 ( 0.232)\tLoss 4.1946e-01 (4.1946e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [18][ 0/24]\tTime  0.231 ( 0.231)\tData  0.194 ( 0.194)\tLoss 4.0982e-01 (4.0982e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [18][10/24]\tTime  0.063 ( 0.063)\tData  0.031 ( 0.032)\tLoss 4.6050e-01 (4.0060e-01)\tAcc@1  75.00 ( 72.73)\tAcc@2 100.00 ( 94.32)\n","Epoch: [18][20/24]\tTime  0.029 ( 0.053)\tData  0.000 ( 0.022)\tLoss 3.6565e-01 (3.9675e-01)\tAcc@1  75.00 ( 71.43)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.296 ( 0.296)\tLoss 4.2671e-01 (4.2671e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [19][ 0/24]\tTime  0.278 ( 0.278)\tData  0.246 ( 0.246)\tLoss 3.8826e-01 (3.8826e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [19][10/24]\tTime  0.053 ( 0.066)\tData  0.024 ( 0.034)\tLoss 4.4003e-01 (3.9735e-01)\tAcc@1  37.50 ( 71.59)\tAcc@2 100.00 ( 95.45)\n","Epoch: [19][20/24]\tTime  0.059 ( 0.059)\tData  0.028 ( 0.027)\tLoss 3.9792e-01 (3.9711e-01)\tAcc@1  87.50 ( 70.24)\tAcc@2  87.50 ( 91.67)\n","Test: [0/4]\tTime  0.219 ( 0.219)\tLoss 4.2464e-01 (4.2464e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [20][ 0/24]\tTime  0.226 ( 0.226)\tData  0.195 ( 0.195)\tLoss 3.9025e-01 (3.9025e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [20][10/24]\tTime  0.028 ( 0.062)\tData  0.000 ( 0.031)\tLoss 4.0334e-01 (4.2711e-01)\tAcc@1  75.00 ( 65.91)\tAcc@2 100.00 ( 92.05)\n","Epoch: [20][20/24]\tTime  0.028 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.2289e-01 (4.2328e-01)\tAcc@1  87.50 ( 64.88)\tAcc@2 100.00 ( 91.07)\n","Test: [0/4]\tTime  0.226 ( 0.226)\tLoss 4.2451e-01 (4.2451e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [21][ 0/24]\tTime  0.210 ( 0.210)\tData  0.178 ( 0.178)\tLoss 3.8856e-01 (3.8856e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 (100.00)\n","Epoch: [21][10/24]\tTime  0.042 ( 0.062)\tData  0.013 ( 0.032)\tLoss 3.3748e-01 (3.9500e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2 100.00 ( 97.73)\n","Epoch: [21][20/24]\tTime  0.059 ( 0.057)\tData  0.031 ( 0.027)\tLoss 3.7388e-01 (3.9454e-01)\tAcc@1  50.00 ( 69.64)\tAcc@2 100.00 ( 97.02)\n","Test: [0/4]\tTime  0.240 ( 0.240)\tLoss 4.2140e-01 (4.2140e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [22][ 0/24]\tTime  0.248 ( 0.248)\tData  0.202 ( 0.202)\tLoss 3.8910e-01 (3.8910e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [22][10/24]\tTime  0.076 ( 0.061)\tData  0.046 ( 0.029)\tLoss 4.9462e-01 (3.8826e-01)\tAcc@1  62.50 ( 77.27)\tAcc@2  87.50 ( 96.59)\n","Epoch: [22][20/24]\tTime  0.067 ( 0.055)\tData  0.039 ( 0.023)\tLoss 3.8448e-01 (4.0273e-01)\tAcc@1  62.50 ( 69.64)\tAcc@2 100.00 ( 94.05)\n","Test: [0/4]\tTime  0.217 ( 0.217)\tLoss 4.2246e-01 (4.2246e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [23][ 0/24]\tTime  0.225 ( 0.225)\tData  0.193 ( 0.193)\tLoss 3.3526e-01 (3.3526e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2 100.00 (100.00)\n","Epoch: [23][10/24]\tTime  0.055 ( 0.060)\tData  0.023 ( 0.030)\tLoss 3.9930e-01 (3.9692e-01)\tAcc@1 100.00 ( 77.27)\tAcc@2 100.00 ( 97.73)\n","Epoch: [23][20/24]\tTime  0.068 ( 0.055)\tData  0.037 ( 0.024)\tLoss 3.7890e-01 (4.0503e-01)\tAcc@1  75.00 ( 73.81)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.211 ( 0.211)\tLoss 4.1773e-01 (4.1773e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [24][ 0/24]\tTime  0.227 ( 0.227)\tData  0.190 ( 0.190)\tLoss 3.8103e-01 (3.8103e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [24][10/24]\tTime  0.029 ( 0.060)\tData  0.000 ( 0.031)\tLoss 4.1878e-01 (3.8868e-01)\tAcc@1  62.50 ( 69.32)\tAcc@2 100.00 ( 98.86)\n","Epoch: [24][20/24]\tTime  0.038 ( 0.055)\tData  0.000 ( 0.024)\tLoss 3.7642e-01 (3.9734e-01)\tAcc@1  75.00 ( 70.83)\tAcc@2  87.50 ( 96.43)\n","Test: [0/4]\tTime  0.217 ( 0.217)\tLoss 4.2880e-01 (4.2880e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [25][ 0/24]\tTime  0.256 ( 0.256)\tData  0.218 ( 0.218)\tLoss 4.6588e-01 (4.6588e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [25][10/24]\tTime  0.064 ( 0.065)\tData  0.034 ( 0.034)\tLoss 4.4633e-01 (4.0641e-01)\tAcc@1  50.00 ( 69.32)\tAcc@2  87.50 ( 94.32)\n","Epoch: [25][20/24]\tTime  0.065 ( 0.057)\tData  0.035 ( 0.026)\tLoss 4.1641e-01 (4.0134e-01)\tAcc@1  62.50 ( 69.05)\tAcc@2  87.50 ( 93.45)\n","Test: [0/4]\tTime  0.213 ( 0.213)\tLoss 4.1770e-01 (4.1770e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [26][ 0/24]\tTime  0.229 ( 0.229)\tData  0.198 ( 0.198)\tLoss 4.5483e-01 (4.5483e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [26][10/24]\tTime  0.031 ( 0.061)\tData  0.000 ( 0.031)\tLoss 5.2167e-01 (4.0705e-01)\tAcc@1  62.50 ( 72.73)\tAcc@2  75.00 ( 89.77)\n","Epoch: [26][20/24]\tTime  0.031 ( 0.055)\tData  0.000 ( 0.025)\tLoss 3.8721e-01 (3.9712e-01)\tAcc@1  50.00 ( 73.21)\tAcc@2 100.00 ( 92.86)\n","Test: [0/4]\tTime  0.223 ( 0.223)\tLoss 4.2586e-01 (4.2586e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [27][ 0/24]\tTime  0.226 ( 0.226)\tData  0.192 ( 0.192)\tLoss 4.5420e-01 (4.5420e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [27][10/24]\tTime  0.064 ( 0.063)\tData  0.034 ( 0.033)\tLoss 3.5277e-01 (4.2468e-01)\tAcc@1  75.00 ( 65.91)\tAcc@2 100.00 ( 95.45)\n","Epoch: [27][20/24]\tTime  0.059 ( 0.055)\tData  0.029 ( 0.024)\tLoss 3.3117e-01 (4.0324e-01)\tAcc@1 100.00 ( 69.64)\tAcc@2 100.00 ( 96.43)\n","Test: [0/4]\tTime  0.221 ( 0.221)\tLoss 4.2317e-01 (4.2317e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [28][ 0/24]\tTime  0.252 ( 0.252)\tData  0.211 ( 0.211)\tLoss 4.0542e-01 (4.0542e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [28][10/24]\tTime  0.070 ( 0.064)\tData  0.039 ( 0.033)\tLoss 3.2170e-01 (3.8296e-01)\tAcc@1  75.00 ( 69.32)\tAcc@2 100.00 ( 96.59)\n","Epoch: [28][20/24]\tTime  0.033 ( 0.054)\tData  0.000 ( 0.023)\tLoss 4.4752e-01 (3.9727e-01)\tAcc@1  62.50 ( 70.83)\tAcc@2  87.50 ( 95.83)\n","Test: [0/4]\tTime  0.206 ( 0.206)\tLoss 4.2918e-01 (4.2918e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [29][ 0/24]\tTime  0.266 ( 0.266)\tData  0.233 ( 0.233)\tLoss 4.1439e-01 (4.1439e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [29][10/24]\tTime  0.065 ( 0.068)\tData  0.035 ( 0.036)\tLoss 3.9249e-01 (3.8667e-01)\tAcc@1  75.00 ( 73.86)\tAcc@2 100.00 ( 95.45)\n","Epoch: [29][20/24]\tTime  0.069 ( 0.060)\tData  0.037 ( 0.029)\tLoss 4.2277e-01 (3.8871e-01)\tAcc@1  50.00 ( 73.21)\tAcc@2 100.00 ( 97.62)\n","Test: [0/4]\tTime  0.207 ( 0.207)\tLoss 4.2034e-01 (4.2034e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [30][ 0/24]\tTime  0.223 ( 0.223)\tData  0.190 ( 0.190)\tLoss 4.7469e-01 (4.7469e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [30][10/24]\tTime  0.074 ( 0.065)\tData  0.037 ( 0.035)\tLoss 3.9190e-01 (4.1480e-01)\tAcc@1  75.00 ( 71.59)\tAcc@2 100.00 ( 95.45)\n","Epoch: [30][20/24]\tTime  0.075 ( 0.059)\tData  0.043 ( 0.026)\tLoss 3.8624e-01 (4.0366e-01)\tAcc@1  75.00 ( 70.83)\tAcc@2 100.00 ( 95.83)\n","Test: [0/4]\tTime  0.211 ( 0.211)\tLoss 4.1660e-01 (4.1660e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [31][ 0/24]\tTime  0.224 ( 0.224)\tData  0.193 ( 0.193)\tLoss 3.2183e-01 (3.2183e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [31][10/24]\tTime  0.033 ( 0.060)\tData  0.000 ( 0.029)\tLoss 3.5715e-01 (3.8782e-01)\tAcc@1  87.50 ( 76.14)\tAcc@2 100.00 ( 97.73)\n","Epoch: [31][20/24]\tTime  0.029 ( 0.055)\tData  0.000 ( 0.024)\tLoss 3.7870e-01 (4.0231e-01)\tAcc@1  75.00 ( 73.21)\tAcc@2  87.50 ( 95.24)\n","Test: [0/4]\tTime  0.184 ( 0.184)\tLoss 4.2227e-01 (4.2227e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [32][ 0/24]\tTime  0.232 ( 0.232)\tData  0.200 ( 0.200)\tLoss 5.4262e-01 (5.4262e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  75.00 ( 75.00)\n","Epoch: [32][10/24]\tTime  0.061 ( 0.063)\tData  0.032 ( 0.033)\tLoss 3.4823e-01 (3.9479e-01)\tAcc@1  87.50 ( 72.73)\tAcc@2 100.00 ( 96.59)\n","Epoch: [32][20/24]\tTime  0.027 ( 0.054)\tData  0.000 ( 0.023)\tLoss 4.5656e-01 (4.0824e-01)\tAcc@1  62.50 ( 69.05)\tAcc@2 100.00 ( 94.64)\n","Test: [0/4]\tTime  0.224 ( 0.224)\tLoss 4.2101e-01 (4.2101e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [33][ 0/24]\tTime  0.241 ( 0.241)\tData  0.209 ( 0.209)\tLoss 4.0837e-01 (4.0837e-01)\tAcc@1  87.50 ( 87.50)\tAcc@2  87.50 ( 87.50)\n","Epoch: [33][10/24]\tTime  0.063 ( 0.067)\tData  0.034 ( 0.037)\tLoss 4.0385e-01 (3.9113e-01)\tAcc@1  62.50 ( 78.41)\tAcc@2 100.00 ( 94.32)\n","Epoch: [33][20/24]\tTime  0.064 ( 0.057)\tData  0.033 ( 0.027)\tLoss 4.2794e-01 (3.9663e-01)\tAcc@1  62.50 ( 75.60)\tAcc@2  87.50 ( 94.05)\n","Test: [0/4]\tTime  0.222 ( 0.222)\tLoss 4.2478e-01 (4.2478e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [34][ 0/24]\tTime  0.265 ( 0.265)\tData  0.221 ( 0.221)\tLoss 4.9076e-01 (4.9076e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  62.50 ( 62.50)\n","Epoch: [34][10/24]\tTime  0.031 ( 0.060)\tData  0.000 ( 0.027)\tLoss 4.2425e-01 (4.2559e-01)\tAcc@1  87.50 ( 64.77)\tAcc@2 100.00 ( 88.64)\n","Epoch: [34][20/24]\tTime  0.058 ( 0.055)\tData  0.028 ( 0.023)\tLoss 2.8209e-01 (4.0458e-01)\tAcc@1 100.00 ( 69.64)\tAcc@2 100.00 ( 91.67)\n","Test: [0/4]\tTime  0.278 ( 0.278)\tLoss 4.1787e-01 (4.1787e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [35][ 0/24]\tTime  0.276 ( 0.276)\tData  0.232 ( 0.232)\tLoss 4.4695e-01 (4.4695e-01)\tAcc@1  50.00 ( 50.00)\tAcc@2  62.50 ( 62.50)\n","Epoch: [35][10/24]\tTime  0.074 ( 0.068)\tData  0.045 ( 0.036)\tLoss 4.8183e-01 (3.9163e-01)\tAcc@1  50.00 ( 67.05)\tAcc@2 100.00 ( 95.45)\n","Epoch: [35][20/24]\tTime  0.072 ( 0.060)\tData  0.044 ( 0.028)\tLoss 3.2932e-01 (3.9015e-01)\tAcc@1 100.00 ( 70.83)\tAcc@2 100.00 ( 97.02)\n","Test: [0/4]\tTime  0.196 ( 0.196)\tLoss 4.1987e-01 (4.1987e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [36][ 0/24]\tTime  0.239 ( 0.239)\tData  0.206 ( 0.206)\tLoss 4.2418e-01 (4.2418e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 (100.00)\n","Epoch: [36][10/24]\tTime  0.030 ( 0.063)\tData  0.000 ( 0.031)\tLoss 4.5037e-01 (4.0279e-01)\tAcc@1  62.50 ( 70.45)\tAcc@2  87.50 ( 94.32)\n","Epoch: [36][20/24]\tTime  0.034 ( 0.055)\tData  0.000 ( 0.024)\tLoss 4.1038e-01 (4.0050e-01)\tAcc@1  75.00 ( 72.02)\tAcc@2  87.50 ( 94.05)\n","Test: [0/4]\tTime  0.236 ( 0.236)\tLoss 4.2329e-01 (4.2329e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [37][ 0/24]\tTime  0.236 ( 0.236)\tData  0.203 ( 0.203)\tLoss 3.9187e-01 (3.9187e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n","Epoch: [37][10/24]\tTime  0.048 ( 0.065)\tData  0.009 ( 0.033)\tLoss 3.9968e-01 (4.1735e-01)\tAcc@1  62.50 ( 62.50)\tAcc@2 100.00 ( 90.91)\n","Epoch: [37][20/24]\tTime  0.054 ( 0.056)\tData  0.026 ( 0.026)\tLoss 4.2864e-01 (4.1171e-01)\tAcc@1  50.00 ( 66.67)\tAcc@2  87.50 ( 91.67)\n","Test: [0/4]\tTime  0.203 ( 0.203)\tLoss 4.1740e-01 (4.1740e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [38][ 0/24]\tTime  0.261 ( 0.261)\tData  0.227 ( 0.227)\tLoss 4.5907e-01 (4.5907e-01)\tAcc@1  37.50 ( 37.50)\tAcc@2  75.00 ( 75.00)\n","Epoch: [38][10/24]\tTime  0.067 ( 0.065)\tData  0.038 ( 0.035)\tLoss 5.2819e-01 (4.1984e-01)\tAcc@1  62.50 ( 68.18)\tAcc@2  62.50 ( 86.36)\n","Epoch: [38][20/24]\tTime  0.045 ( 0.056)\tData  0.016 ( 0.024)\tLoss 3.3627e-01 (4.0075e-01)\tAcc@1  62.50 ( 72.02)\tAcc@2 100.00 ( 91.07)\n","Test: [0/4]\tTime  0.220 ( 0.220)\tLoss 4.2227e-01 (4.2227e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n","Epoch: [39][ 0/24]\tTime  0.236 ( 0.236)\tData  0.205 ( 0.205)\tLoss 3.3552e-01 (3.3552e-01)\tAcc@1 100.00 (100.00)\tAcc@2 100.00 (100.00)\n","Epoch: [39][10/24]\tTime  0.042 ( 0.065)\tData  0.000 ( 0.033)\tLoss 4.4004e-01 (4.0937e-01)\tAcc@1  87.50 ( 80.68)\tAcc@2 100.00 ( 96.59)\n","Epoch: [39][20/24]\tTime  0.029 ( 0.056)\tData  0.000 ( 0.025)\tLoss 3.8694e-01 (4.0989e-01)\tAcc@1 100.00 ( 76.79)\tAcc@2 100.00 ( 94.05)\n","Test: [0/4]\tTime  0.205 ( 0.205)\tLoss 4.2680e-01 (4.2680e-01)\tAcc@1  75.00 ( 75.00)\tAcc@2  87.50 ( 87.50)\n"," * Acc@1 71.875 Acc@2 87.500\n"]}]},{"cell_type":"markdown","source":["### Graphs"],"metadata":{"id":"MHKPbVJO1s_1"}},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'eval'+ eval_suffix + epoch + '/checkpoint.pth.tar')\n","history_df = cpkt['history_df']\n","cpkt['epoch']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHXEg80C1vGt","executionInfo":{"status":"ok","timestamp":1651694109106,"user_tz":420,"elapsed":523,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"f851fa6e-8afd-4d15-dfe0-8e4310479e00"},"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["_ = history_df[['train_loss', 'val_loss']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"y-U0dMqF2U8d","executionInfo":{"status":"ok","timestamp":1651694109107,"user_tz":420,"elapsed":13,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"843b2e0d-c1d9-468f-cc38-68f0def44f35"},"execution_count":118,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df[['train_acc1', 'val_acc1']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"bIMKhORT2onL","executionInfo":{"status":"ok","timestamp":1651694109705,"user_tz":420,"elapsed":608,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"0cdf293c-b70d-4489-d543-e077e2608f88"},"execution_count":119,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["_ = history_df[['train_acc2', 'val_acc2']].plot.line()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"23uLjur22wQM","executionInfo":{"status":"ok","timestamp":1651694109706,"user_tz":420,"elapsed":44,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"ba39ec90-f43b-41bb-9efb-bcfb0469708d"},"execution_count":120,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdf748deHRRAFQRZBUMEdN1DULNNcWtQac0ltGUetqaaaafE3TTbV1Ew140zTot/K9tJWy8qassVdc0dBRVFxB1Q2vQiCbPfz++NeCZXlAvdy7+G+n4+HD+493HPOmyO87+d+lvdRWmuEEEIYj4ezAxBCCNEwksCFEMKgJIELIYRBSQIXQgiDkgQuhBAG5dWUJwsJCdHR0dFNeUohhDC87du352qtQy/d3qQJPDo6msTExKY8pRBCGJ5S6lh126ULRQghDEoSuBBCGJQkcCGEMChJ4EIIYVCSwIUQwqAkgQshhEFJAhdCCIOSBC6EsElOQQmLtx2nvMLs7FCEVZMu5BFCGFN+cRnT393CvlMFJKeb+OfEviilnB2W25MWuBD1dCT3HKfyzzs7jAY5kFVAfnFZvfY5X1bBPYsSOZRTyI19I/h0azqvrEhzUISiPqQFLkQ9aK2Z8d5WAL5/8Gr8fb2dHJHtcgpKuHH+esLb+PLejEF0a+df5z4VZs3sz5PZcuQ0826NZ3xce1ou8WTeyjTCAny444pOTRC5qIm0wEWzdOZcqUOOezj3HMdPF3H8dBFPf7PHIedwlO92naCsQlN4vpxJr29k9f7sWl+vteYf/9vDst2nePLGWG6Oj0Qpxb8m9WVkj1CeWprCT3tONVH0ojqSwEWzsz4thwHPLa8zQTXEugM5ANySEMVXSZksTcq0+zkcZWlSJn0iA/j+wWFEtfXjrg+28e4vR6jpvrgL1h5i4aZj3D0sht8P61y53dvTg9fuGEDfqEAe/DSJbUdPN9WPIC4hCVw0K1prXvhpP1rDG2sO2f3469Ny6RTsx9xJfRnYKYgnl6ZwPK/I7uext0M5hezMyGdCfCTtA1uy5A9Xcm1sO579bi9//Xo3peUXzyz5IjGd//y4n5vj2/P42NjLjufXwov3Zw4iMrAld32wjbSsgqb6UUQVksCbKa01f/16N3e8s/myP87mbPneLHZl5NO/YyBbjpxmd0a+3Y5dUl7BpkN5DO8WipenB6/cGo9S8NDiJJun1i1NymTgc8t55ts9Duvmqc43SZl4KBgf1x6AVj5evPHbBB4Y2YVPt6bzu/e2VMazen82c77azdVdQ3jhljg8PKqfbdK2VQsW3jkYH29PZry3lZP5xU3289TX62sOMm7eerLPGnPwuSaSwJupL3dk8smW42w4mMeLP+93djhNwmzWvLT8ADEhrXh/5iBa+3jx9vrDdjv+9qNnKC6rYHh3S139qCA/np/Yl6TjJuavrH1WhtmseeGnfTy8OBl/X28WbTrK8BdW89a6Q5SUV9gtxuporfk6OZOhXUMIC/Ct3O7hoXj0hp68PC2OHcdMTHh9A0uTMrn/ox3ERvjzxvQEWnjVniI6tPXjg1mDOHu+nJnvbSO/qH4zXJrCwexCXl5+gL0nzzLz/W0UnHe9GBtKEngzdDT3HH/7JoUrYtpy2+COvLnuML+k5To7LIdblnKSfacKePjabgT6teDWQR34fvdJMk32aRmuS8vFy0NxZZfgym3j49pzS0IUr64+yJbDedXuV1Razn0fb+e11Ye4dVAHfnp4OD88NJyETkH8c9k+rn1pLd/tOlFjX3Rj7Th+hvTTxUzsH1nt9yf2j+LTe4ZwrqSchxcnE+rvw/szB9Pax7ZJar3bt+Gt6Qkczi1k+ntbSMm036eextJa88y3e/D19uSlqXEcyCrgDx9td/ibZlORBN7MlJabefCzJLw9PXh5Wjx/u6kXXcNaM/vzZPIKS5wdnsNUmDWvrEijW1hrbupn6SaYdXUMAB9sOGKXc6w7kMOATkGXJbZnxvemY1s/HlmcfFkL9ISpmFsWbGL53iyeuqkX/5rUlxZeHvQI9+eDWYP58K7BtGrhxR8/SWLSgo1sP2b/AcGvkzJp6e3JDb3Da3xNQqcglj4wlOlDOrHozsGE+vvU6xxXdQ3h1dsHkHGmmN+8+guzP0/mhJ3eOBvjh5RT/HIwl/93XXcmDYjiP7f0Y8PBPP78xS7MZse8YTYlSeDNzMsrDrArI5+5k/rSPrAlLVt4Mv/W/piKynjsy10Oa+U527c7MzmYXcgj13XH09pnGxnYknF9I/hsa3qjPzbnFJSw9+RZrul+2W0Jae3jxbxb+5NdUMLjX/96jZOOn+Hm1zZw/HQR784cxF1Xx1y2enFYt1C+f3AY/7mlH5lnipm8YBN//GQHxaX2aSGWlpv5btdJru/djlZ1tKijgvx4dkIfokNaNehcN/QOZ82jI7h3eBe+23WSkf9dw39/2k9hSXmDjtdYRaXlPPfdXnqG+/PbIZb56pMGRDFnbE/+t/MEz32favi/B0ngzcjGg7m8sfYQtw3uwNi+EZXbe7UPYM7YnqxIzeajzdXeWs/QyirMvLIijV4RAYy5pJV597AYCkrKWbwtvVHnWJ9mmT44vNvlCRwgrkMgs6/vzrLdp/giMYNvkjOZ9tZmfL09+Or+qxjZI6zGY3t6KKYO7MCaR0fw0OhufL/7JH/61PaB0dqsPZCDqaiMCTV0n9hbgK83c8b2ZOXsaxjTJ5xXVx9kxAur+XjLsSavofLqqoOcyD/PsxP64OX5a6q7d3hnZg2N5r0NR+w6RuIMshKzmThzrpRHPk8mJqQVT93U67Lvzxoazbq0HJ77PpUrOgfT3YZVeEbx1Y4MjuUV8c7vBl42Y6JfVCCDY9ry/oajzLwq+qI/5PpYn5ZL21Yt6N0+oMbX3Du8C+sP5PLk0hRKK8wMjm7LG9MTaNuqhU3n8GvhxSPXdSfE34enlqbw1Dcpja45sjQpk+BWLRjWNaTBx2iIDm39mHdrf2YNjeH57/fyxNcpfLDhKOPj2tc4qwWgezt/ruwSbHP/e00O5RTy9vrDTBoQyaDothd9TynFUzf2IrughH8u20eovw8T+0c16nzOIgm8GdBa89iXuzh9rpR3ZwzCr8Xl/61KKV64JY6x89bx4KdJLH1gKL7enk6I1r5KyiuYv/IgcR0CGR1bfSv37mGduXtRIstSTlVOo6sPs1mzPi2Hq7uG1Jp8PD0UL0+LZ/KCjQzvHsLfx/epcxZHdaYP6UT22fP836qDhPn78sh13et9DICz58tYnprF7YM7NviNq7HiOwTy+b1X8tOeLP7z4z5eXH6gzn28PRUJnYIY3j2Ua7qHEhseUOt1v1TlwKWXZ7Vz2MEyA+elqXGcLizl0S92EdzKp3J2kZFIAm8GPtl6nJ/3ZvHkjbH0iWxT4+tC/X3475Q4Zr6/jbk/7OOZ8b0bfM78ojIOZBeQ0DGoXn9c9vb5tnQyTcX8a1LNLdXRPcPoHNKKd9Yf5jf9Iurdot178iy5haU2/YGHt/Hll8dGNrpS3+zrupN19nyjao78uPsUpeXmGmefNBWlFGP6hHND73aU1tKNUmHWJB83sTYth3UHcvnPj/v5z4/7CWntw/BuIVzTI5QbeofX2fD4ac8p1qfl8vRvetU6GOvj5cmbv0tg2pub+cNH2/nsniH0iwps8M/pDJLADS4tq4Bnv9vLsG4h3Dk0ps7Xj+gRxp1DY3hvwxGGdw9hVM92Np2nwqxJTjex7kAO69Jy2JluwqwtfcxP3Hh5l01TOF9WwaurDzIoOohh3WruIvDwUNx5dQxPLk1h65HTXNE5uMbXVmddZf+3bd0Q9iizqpTinxP7kltYylNLUwhp7VPrLJLqfJ2USeeQVvSLqvlNvSkppfDxqj35XtU1hKu6hvD4WMg+e551abmsO5DD6v3ZfJWUSVRQS/4ypmeNb8RFpeU8+10qPcP9mT6k7je9AF9vFs4axKQFG7nj7S3Mv71/reMVrkYGMQ3sfFkFD36WTKsWXrw4teYVc5d6bGwPYiMCePSLXew9cZb000XV/juYXcjibcd54OMdDHh2OZMXbGT+qjTMGv44qhtTB0bx9vojvL3OOQNBH20+RtbZEmZf16POpDl5QBRBft68vb7+UwrXH8ilZ7j/RYtgmoKXpwev3t6ffg2oOXLCVMzmI3lM6B9p2LrdYQG+3JIQxfzb+pP45HUsvHMw/r7ePPhpEhNe31jt9Xht9UEyTcX84+Y+NncbhQX48vm9V9LBWh/mnfWHDTM7RVrgBrXpUB7PL9tL6smzvDdzIGH+ticXHy9P5t8az29e/YVx89fX+fp2AT5c36sdw7uHcnXXEIKsg3IVZs25kgqeX5ZKWIAPN8c33Uf1otJy3lh7iKFdgy9aWFOTli08mT6kE/+3+iCHcwrpHNrapvOcKykn8dhpZtnw6cYR/Fp48d7MQdyyYCN3fbCNJfddZdMA9Lc7T6A1TGjC/xNH8vRQXGP9/ftyRwYv/ryfKW9sYkzvcOaM7Ul0SCuO5J7j7XVHmNg/ksExbes+aBXtA1uy5L4reWRxMs99n8qhnMIGj2E0JUngBnMwu5C5P+xjRWoW7dv48urt/W3uBqmqWzt/lj4wlJTMszW+RgG9IwPo0c6/2lacp4fixalx5J0r4c9f7KRtqxYMq2Ganb0t3HiM3MJS3ryuh837TL8ymjfWHebdX47w/MS+Nu2z+XAeZRW6xumDTeFCzZFJCzYy472tfHX/VUS0aVnrPkuTMknoFETHYL8mirJpXJhyeVO/CN5ed4Q31x1i5b4spg+J5kBWAT5eHjw+rmeDju3XwosFdyTw4vL9vLb6EIdzzvHGbxMqGyyNkV9cRpuW9q8dr5ryo8LAgQN1YmJik52vOckrLGHeyjQ+3nKclt6e3D+yC3cOjXGJmSRnz5cx9Y1NpJ8uYvG9V9Y6kNpYFWbNF4npPP99KgOjg3h/1uB67f/Ykl0sTc5k0+OjbZre9/Q3KSxOTCf5b9c7/VrvPXGWaW9uIrCVN0/e2Ivre7Wr9o019eRZxs5bz7MT+tjUD2xk2WfP8/KKAyzelo5Zw1M39eKuqxv/aenrpAweW7KbiEBf3p0xkK5hDZt2e+ZcKfNXpfH5tnR+fHg4Hdo27A1VKbVdaz3w0u2u/flAcL6sggVrDjHihTV8vOU4tw/uyJpHR3D/iK5OTygXBPh6s/DOwQT6tWDm+1s5lnfOIedZeyCHcfPWM+er3XQP9+fv4/vU+xi/HxZDSbnZ5gVN69NyGdI52CWuda/2AXxw52B8vDy598PtTHtrMzvTTZe9bmlSJl4eipuqLOZqrsICfPnXpH4se2gYf7upFzOutM8bVtX6MBNf28haax14W5WUV/D2usNc88JqFm48yvj4SFq2sP/vkLTAHeyln/cTGdSSaYM61nvf1JNn+f3CRDJNxVwbG8acsbF0DbOt79YZDmYXcssbGwls6c2S+64ipHX96mnUZN+ps/xz2T7WHcihU7Afc8b0ZEyf8AYPzs18fyspmfksf+SaWj8ep58uYth/VtutVWcv5RVmPtuWzsvLD5B3rpSb49vz6A09iAryo8KsGTp3FX0i2/DOjMsabKKeMs4U8fuFiRzIKmBC/0hG9AhjWJVxoEtprfl+90n+/eM+0k8XM6JHKI+PjaVHeOMWztXUApcE7kA5BSUM/ucKtIaXpsYxaYDtq70yzhQx6fWNeCjFS9PiuKpL066ka6jtx85wxzub6Rbmz2f3DKmz/kZtss+e56XlB/g8Md0y+2B0N6YP6dTogaWd6SamvLmJ3u0D+OT3Q2psGX285RhPfJ3CitnDG/wR2pEKzpfxxtpDvLP+CBq46+oY4jsEcu+H23nt9gHc2K/5t8CbwrmScp77fi/Ldp8iv7gMpSwrfK/pFsLw7qHEdwjEy9OD7cdO89z3qSQdN9Ez3J8nboy125iQJHAn+Dwxnb8s2UX3dq05nHOOd2cOqrYY0qXOnCtl8hsbyS0osXnWgStZsTeLez5M5Mouwbw0NZ529Zx+V1RaXjlAVVZhZsaV0fxxVFcC/Ro/mHTBjyknue/jHYzqEcab0xOqnXL2hw+3syvDxIY5o1x6Kt4JUzH//Wk/X1lv7+bv48W2J691iW6f5qTCrNmZYV0LcSCHZOtaCH9fL7qFtWbHcRNh/j78+foeTE6IqiyqZg+SwJ3g3g8T2Zmez8+zhzPtzc0cyztX52qv4tIK7nhnMyknzvLRXVfUezqUq/g8MZ0nvt6Nl4cH9wzvzL3XdK52iX9VFWbNl9sz+O/P+8kuKGFc33AeG9OTTsENq45Xlw83H+OppSlMG9iBuZMvXslZXmGm/7PLubFvBHMn93PI+e0tJTOfl5YfYEDHQP44qpuzw2n28ovK2HAol7X7c9iZYWJMn3DuGV7373lD1JTAZRqhg5SUV7A+LZcJ/SMrV3tNfH0js97fxpf3XVVtyc7yCjN/+nQHSekmFtwxwLDJG2DqwA4MiQnm3z/tY97KND7depz/d313bknoUG3LZH1aDs9/n8q+UwX07xjIgt8OIKGTY3/+qjVH2rXxZXaVmiPJ6SYKzpc32bRIe+gT2Yb3Zg5ydhhuo42fN+P6RjDOiYPFMgvFQTYfPk1RaQXXWgsshQX4suiuwZi1Zsb7W8kpuPjmClprnlyaworUbP5xcx/G9DF+/2XHYD9eu30AX953FVFBLXnsy93cOH99ZWlWgANZBcx8fyvT393KudJyXr29P1/dd5XDk/cFs6/rztSBUcxfmXbRzJR1B3LwUHB1E1fxE6I+pAVeh5yCEgrOl9m8cu+ClalZ+Hp7XDT42CW0Ne/NHMTtb2/hzg+28ek9QyrLZr68Io3PtqXzp1Fdm93c3YROQXx531Us232KuT+mMv3drVzTPZSINr58nphOax8vnhgXy++u6lRnrQx7u1BzJK+wlL99Y6k5MqZPOOvSconrEEgbP/svvhDCXmxqgSulHlJKpSil9iilHrZua6uUWq6USrN+DXJsqE2jtNzMxkO5zP1hH+PmrWfQ8ysY80r97mattWZlajZXdw25bCCpf8cgXrujP3tPnuW+j7ZTap2TPH9lGlMHRl30Mb45UUpxY78IVsy+hidvjCXp+BmWbM9gxlXRrH10JHcP79zkyfsCS82RAcR1COTBz5Ksd7Y3Gar7RLinOgcxlVJ9gM+AwUAp8CPwB+Ae4LTWeq5Sag4QpLV+rLZjueog5vG8ItYcyGbdgRw2HcrjXGkFXh6WmsQJnYJ4fc0hHr2hBw+M7GrT8fadOsuYV9bzr0l9uW1w9fO/L8xQGRQdxPZjZxhZy2yI5qjgfBml5WaC7TRX3B5Onyvlljc2ciT3HFrDl/dd2WRdOULUpjGDmLHAFq11kfVAa4FJwM3ACOtrFgJrgFoTuCtan5bDjPe2YtbQsa0fEwdEMrxbKFd2Ccbf1/LxecfxM3y27Tj3XdPFpop/K1OzARjVs+aylFMHdiCnoIQXftpP/46BvHr7ALdJ3kDltXUlbVu1YOGswUxesJGScjNxBqsNLdyPLQk8BXheKRUMFAPjgESgndb6pPU1p4BqKyoppe7B0lqnY8f6r0Z0tNdWHyQ8wJdP7h5S481cbxvckYc+S2bDoVybPlavTM2ib2SbOuc/3z+iC30i29C/Y6BDltmK+uvQ1o9v/jgUU1GZW72hCmOq8zdUa50K/Bv4GUv3STJQcclrNFBtX4zW+i2t9UCt9cDQUNfqU0zJzGfzYUup0NruxD2mTzhBft58uvV4ncfMLSwhKd1U4+29qlLKUiIzwAVbo+4sok1LYiNqvvelEK7CpiaG1vpdrXWC1no4cAY4AGQppSIArF+zHRemY7y9/jCtfbyYNrhDra/z8fLkloQoft6TRXZB7YOZa/bnoDVcG1v/Eq9CCFEfts5CCbN+7Yil//sT4FtghvUlM4BvHBGgo5wwFfPdrpPcOqiDTS3gWwd3pNysWbI9o9bXrUzNol2AT613LxdCCHuwtZPvS6XUXuB/wANaaxMwF7hOKZUGXGt9bhgfbDwKwCwbq8x1CW3NFTFt+WxrOmZz9TN3SsorWHcgh1E9q6/TLIQQ9mRrF8owrXUvrXWc1nqldVue1nq01rqb1vparbXtN+xzsoLzZXy65Tjj+kYQGVj7nU2quv2Kjhw/XcTGQ3nVfn/rkdOcq7L6UgghHMkth9kXb0unoKScu4fVr8bzDb1rH8xcmZqNj5eHYUq/CiGMze0SeHmFmfc3HGVwTNtaqwJWx9fbk8kDovhpz6lqa5msSM3i6q4hMiVQCNEk3C6B/5ByikxTMXcP69yg/S8MZn654+LBzLTsQjLOFDNaZp8IIZqIWxWz0lrzzvrDdA5pxehaVknWpmtYawbHtOXTrce5Z1jnypWZK1KzgNpXX7qcQ6vg+GZnRyGEexh8D7Syb/eqWyXwbUfPsDMjn+cm9LFpSXxNbh/ckYcXJ7PpcB5DreVGV6Vm0ycygPA29bv7jNNk74OPp4C53NmRCOEe+twiCbwx3l5/mCA/bybX496U1RnTJ5zA/3nzydbjDO0awulzpew4foY/GeUuKFrDsj9Di9bwp+12/6USQjQNt+kDP5J7jhWpWUwf0qnRg4wXBjN/3nOK3MISVu/Lxqyxafm8S0j5Eo6uh9F/k+QthIG5TQJ/95fDeHt6MP3KaLsc77bBHSirsNzDcdW+bML8fejTvo1dju1Q58/CT09ARDwkzHR2NEKIRnCLLpQz50pZsj2DifGRhPrbp/501zB/Bke35ZOtxzldWMpNcRGN6ldvMmv/DYVZcOsn4CHTHYUwMrdogX+0+Rjny8z8vp4Ld+py2xUdOJZXREFJOaN6GmD6YNZe2LwAEmZAVIKzoxFCNFKzT+Cl5WYWbjrGiB6hdGvnb9djj+0TQZuW3vh4ebj+zW8vDFz6BsDop50djRDCDpp9F8qeE/nkFpYwdWDtJWMbwtfbkzlje3L6XKnrr77c/QUc2wC/mQd+cpswIZqDZp/Ad6abABjQ0TH3XK7pnpcu5Xw+/PwkRCZA/985OxohhJ00/wSekU+7AB/jLLBxhDVzoTAbbvsMPJp9r5kQbqPZ/zXvTDe5981pT6XAljdh4CyIHODsaIQQdtSsE3h+URmHc88R18FNE3jlwGUbGPWUs6MRQthZs+5C2Zlh6f/u76oJ3GyGxHfBVPfNkhukMBuOb4Lx/ycDl0I0Q807gaebUAr6RLnoCsmdn1hayF6+gIMWAfW8CeJ/65hjCyGcqnkn8AwTXUJb23TT4iZXfAaW/w06DIFZP8jgohCi3ppt1tBak5ye77oDmKuesyTxG/8ryVsI0SDNNnOcyD9PbmEJ8R1csPvkRBJse9dS4D28r7OjEUIYVLNN4BcW8LjcDBSzGb7/M7QKhRGPOzsaIYSBNds+8J3pJlp4etAzPMDZoVws+SPITISJb0JLF3tzEUIYSrNtgSenm+jVPoAWXi70IxadhuVPQ8crod80Z0cjhDA4F8pu9lNh1uzOzCfe1bpPVj1rqUsy7r+gDFA7XAjh0pplAk/LLqCotII4VxrAzNwOie/DFfdCeB9nRyOEaAaaZQKvHMB0lSmE5gr4/v9B6zAYMcfZ0QghmolmOYiZnJ5PgK8X0cGtnB2KxY5FlqmDk9621CURQgg7aLYt8LgOga5xj8pzebDy79Dpaug7xdnRCCGakWaXwItLK9ifVeA6A5gr/265E/yNMnAphLCvZpfA95zIp8KsXaP/OyPR0n0y5D4Ii3V2NEKIZqbZJfBk6wBmP2fPQLkwcOkfLgOXQgiHsCmBK6UeUUrtUUqlKKU+VUr5KqVilFJblFIHlVKLlVItHB2sLXZm5BMZ2JIwfyffQm37B3AyGa5/Dnz8nRuLEKJZqjOBK6UigQeBgVrrPoAncCvwb+BlrXVX4AxwlyMDtVVy+hnnz/8+lwsr/wHRw6DPZOfGIoRotmztQvECWiqlvAA/4CQwClhi/f5CYIL9w6ufvMIS0k8XO7//e8XTUFooKy6FEA5VZwLXWmcC/wWOY0nc+cB2wKS1Lre+LAOIrG5/pdQ9SqlEpVRiTk6OfaKuwa6MfMDJFQjTt0LSRzDkfgjr6bw4hBDNni1dKEHAzUAM0B5oBYyx9QRa67e01gO11gNDQ0MbHKgtktNNeCjoG+mkLhRzBXw/G/zbwzWPOScGIYTbsGUl5rXAEa11DoBS6itgKBColPKytsKjgEzHhWmbnRkmuoX508rHSQtME9+DU7thygfg09o5MQgh3IYtfeDHgSFKKT+llAJGA3uB1cAt1tfMAL5xTIi20VpbV2A6qfVdmAMrn4XOI6CX04cDhBBuwJY+8C1YBit3ALut+7wFPAbMVkodBIKBdx0YZ53STxdzpqjMef3fK56GsiIY+4IMXAohmoRNfQ1a66eBpy/ZfBgYbPeIGig5w4kVCI9vhuSP4epHILR7059fCOGWms1KzJ3pJny9PegR3sSLZirKLfe4DIiC4Y827bmFEG6t2ZSTTU430ad9G7w96/medC4P1r8IJWcbduLCLMjaDVMXQQsXKV8rhHALzSKBl1WYScnM57dDOtV/5x/nQMqX0LpdwwNImAmx4xu+vxBCNECzSOD7TxVQUm6u/wDm0V9g9+eWro9RTzomOCGEcJBm0Qe+0zqAGV+fAcyKMkvfdZuOcPVsB0UmhBCO0yxa4DvTTQT5edOhbUvbd9ryJuSkwq2fQgs/xwUnhBAO0jxa4On5xHUIRNk6//rsSVjzL+h2A/QY69jghBDCQZpFAs80FdfvBsY/P2npQhk7VxbdCCEMy/AJvKzCTGFJOUF+Nt5P4sg6SFliWXTTtrNjgxNCCAcyfAI/W1wGQJuWNnTnXxi4DOwEVz/s4MiEEMKxDD+IabIm8EBbWuCbF0DufrhtMXjXY8BTCCFckOFb4KYiawvcz7v2F+Znwpq50H0s9LC5nLkQQrgswyfw/OJSAAJb1pHAf34CdIVl4FIIIZqBZpDAL/SB15LAD62GPV9bFuwERTdNYEII4WDG7wMvKmOW5w9ErvoSvGp4Pzq2CYJiYOhDTSx0pxsAABOHSURBVBucEEI4kOETeEHhOR73+gTvo22gZQ1L6X0DLHeI9/Zt2uCEEMKBDJ/Afc7sp4WqgJtegt4TnR2OEEI0GcP3gQeZ9lgetO/v3ECEEKKJGT6BhxWmUqBaWxbnCCGEGzF8Au9w/gBHW3STmiZCCLdj7AReXkLH8qOc8It1diRCCNHkjJ3As/bgTTl5AZLAhRDux9AJXJ9IBqAgqI+TIxFCiKZn6GmE5Rk7KNStIbCjs0MRQogmZ/AWeBK7zTEEtrKxFrgQQjQjxk3gZefxyttPio6hTUtJ4EII92PcBJ69Bw9zGbvMnWsvZCWEEM2UcRO4dQAzRccQWFctcCGEaIYMnMCTKPFuQ4YOkQQuhHBLxk3gJ5PJah0LKOlCEUK4JWMm8LLzkJ1KRssetPD0oKW3p7MjEkKIJmfMBJ61B8zlHPbqShs/b5TUQRFCuCFjJvCTSQCkqi7SfSKEcFt1JnClVA+lVHKVf2eVUg8rpdoqpZYrpdKsX4OaImDAMgOlZVsOl7at+2bGQgjRTNWZwLXW+7XW8VrreCABKAK+BuYAK7XW3YCV1udN40QytI/HdL5cZqAIIdxWfbtQRgOHtNbHgJuBhdbtC4EJ9gysRmXFkJMK7ftztrhMVmEKIdxWfRP4rcCn1sfttNYnrY9PAe2q20EpdY9SKlEplZiTk9PAMKuwDmASEY+pqFT6wIUQbsvmBK6UagGMB7649Htaaw3o6vbTWr+ltR6otR4YGhra4EArnbAMYJa168e50grpQhFCuK36tMDHAju01lnW51lKqQgA69dsewdXrZPJ4BdMfotwAEngQgi3VZ8Efhu/dp8AfAvMsD6eAXxjr6BqdSLZ0n1SXA4gXShCCLdlUwJXSrUCrgO+qrJ5LnCdUioNuNb63LHKiiHbMoCZX1wKSAIXQrgvm+7Io7U+BwRfsi0Py6yUppO1B3QFtI8nv7gMgEA/mYUihHBPxlqJaR3AtMxAsSRwaYELIdyVwRJ4MviFQJuoygQuKzGFEO7KWAn8pGUFJkpVdqEESAIXQrgp4yTwCwOYEfEA5BeX4e/rhaeHVCIUQrgn4yTwUynWAcz+AJiKSmUOuBDCrRkngV8YwGxvaYGbissIlDooQgg3ZpwEftI6gBkQCVi6UKQFLoRwZ8ZJ4CeSLd0n1rvv5BeVyQCmEMKtGSOBlxZZS8jGV26ydKFIAhdCuC9jJPCsFNDmyhkoWmvpQhFCuD1jJPATyZav1hkohSXlVJi1rMIUQrg1gyTwJGgVCgHtAaqswpRZKEII92WMBN46FHqM+3UA07oKs410oQgh3JhN1Qid7rp/XPS0MoFLF4oQwo0ZowV+icouFGmBCyHcmCETeGUtcOkDF0K4MUMmcJPcjUcIIYyZwPOLymjh5YGvtyHDF0IIuzBkBsy3rsJUSkrJCiHclyETuKlIVmEKIYQxE3hxqfR/CyHcnjETeFEZbWQGihDCzRkygZ+VQlZCCGHMBG4qLpMuFCGE2zNcAi8tN1NUWiG1wIUQbs9wCbxyFaZ0oQgh3JwBE7hlFabcTk0I4e4Ml8B/LWQls1CEEO7NcAn810JW0gIXQrg3wyVwKSUrhBAWxkvgcjMHIYQADJjA84vLUAr8fSWBCyHcm00JXCkVqJRaopTap5RKVUpdqZRqq5RarpRKs34NcnSwAPlFpQT4euPpIZUIhRDuzdYW+DzgR611TyAOSAXmACu11t2AldbnDierMIUQwqLOBK6UagMMB94F0FqXaq1NwM3AQuvLFgITHBVkVflSB0UIIQDbWuAxQA7wvlIqSSn1jlKqFdBOa33S+ppTQLvqdlZK3aOUSlRKJebk5DQ6YEslQkngQghhSwL3AgYAC7TW/YFzXNJdorXWgK5uZ631W1rrgVrrgaGhoY2Nl3zpQhFCCMC2BJ4BZGitt1ifL8GS0LOUUhEA1q/ZjgnxYqaiUulCEUIIbEjgWutTQLpSqod102hgL/AtMMO6bQbwjUMirMJs1tb7YcoyeiGE8LLxdX8CPlZKtQAOA7OwJP/PlVJ3AceAqY4J8VeFpeWYtSziEUIIsDGBa62TgYHVfGu0fcOpXb51GX0b6UIRQghjrcSUQlZCCPErQyVwKSUrhBC/MlYCt97MQfrAhRDCYAlcbqcmhBC/MlQCv9CFIi1wIYQwWALPLy7Dx8sDX29PZ4cihBBOZ6wEXiSFrIQQ4gJbF/K4BFNxqazCFMLJysrKyMjI4Pz5884Opdnx9fUlKioKb2/bGqrGSuBSiVAIp8vIyMDf35/o6GiUkhur2IvWmry8PDIyMoiJibFpH2N1oRSXySpMIZzs/PnzBAcHS/K2M6UUwcHB9fpkY7gELqswhXA+Sd6OUd/raqgELl0oQgjxK8Mk8JLyCorLKmQWihBCWBkmgV9YhdlG6qAI4dZMJhOvv/56vfcbN24cJpPJARHV7aWXXqJXr17069eP0aNHc+zYMbsc1zCzUC6UkpU+cCFcx9//t4e9J87a9Zi92gfw9G961/j9Cwn8/vvvv2h7eXk5Xl41p7Rly5bZLcb66t+/P4mJifj5+bFgwQL+8pe/sHjx4kYf1zAtcFOxLKMXQsCcOXM4dOgQ8fHxDBo0iGHDhjF+/Hh69eoFwIQJE0hISKB379689dZblftFR0eTm5vL0aNHiY2N5e6776Z3795cf/31FBcX13i+t99+m0GDBhEXF8fkyZMpKioCICsri4kTJxIXF0dcXBwbN24EYNGiRfTr14+4uDimT58OwMiRI/Hz8wNgyJAhZGRk2OdiaK2b7F9CQoJuqOV7TulOj32nd6afafAxhBCNt3fvXqee/8iRI7p3795aa61Xr16t/fz89OHDhyu/n5eXp7XWuqioSPfu3Vvn5uZqrbXu1KmTzsnJ0UeOHNGenp46KSlJa631lClT9Icffljj+S7sr7XWTzzxhJ4/f77WWuupU6fql19+WWutdXl5uTaZTDolJUV369ZN5+TkXBRLVQ888IB+9tlnazxfddcXSNTV5FTDdKGYKm/mIH3gQohfDR48+KKFL/Pnz+frr78GID09nbS0NIKDgy/aJyYmhvj4eAASEhI4evRojcdPSUnhySefxGQyUVhYyA033ADAqlWrWLRoEQCenp60adOGRYsWMWXKFEJCQgBo27btRcf66KOPSExMZO3atY37oa2Mk8CLpBa4EOJyrVq1qny8Zs0aVqxYwaZNm/Dz82PEiBHVLozx8fGpfOzp6VlrF8rMmTNZunQpcXFxfPDBB6xZs6ZBca5YsYLnn3+etWvXXnT+xjBMH/jZ4jKUAn9fw7znCCEcwN/fn4KCgmq/l5+fT1BQEH5+fuzbt4/Nmzc3+nwFBQVERERQVlbGxx9/XLl99OjRLFiwAICKigry8/MZNWoUX3zxBXl5eQCcPn0agKSkJO69916+/fZbwsLCGh3TBYZJ4KZiyyIeDw9ZASaEOwsODmbo0KH06dOHRx999KLvjRkzhvLycmJjY5kzZw5Dhgxp9PmeffZZrrjiCoYOHUrPnj0rt8+bN4/Vq1fTt29fEhIS2Lt3L7179+aJJ57gmmuuIS4ujtmzZwPw6KOPUlhYyJQpU4iPj2f8+PGNjgtAWfrHm8bAgQN1YmJig/Z98NMkdmaYWPvoSDtHJYSoj9TUVGJjY50dRrNV3fVVSm3XWg+89LWGaYFLHRQhhLiYYTqUTcVlsgpTCOEwDzzwABs2bLho20MPPcSsWbOcFFHdDJPA84tK6dTWz9lhCCGaqddee83ZIdSbobpQZAqhEEL8yhAJ3GzWlj5wqUQohBCVDJHAC0rKMWtZxCOEEFUZIoGflUJWQghxGUMkcNOFUrIyC0UIUU+tW7d26PHT09MZOXIkvXr1onfv3sybN8+h56vKELNQTMWWOijSBy6Ei/lhDpzabd9jhveFsXPte0wH8vLy4sUXX2TAgAEUFBSQkJDAddddV1ne1pEM1QKXLhQhxJw5cy6a8vfMM8/w3HPPMXr0aAYMGEDfvn355ptvbDpWYWFhjftVV9e7uhrgERERDBgwALDUaYmNjSUzM9OOP3Etqqsx66h/Da0H/uGmo7rTY9/prPziBu0vhLAfZ9cD37Fjhx4+fHjl89jYWH38+HGdn5+vtdY6JydHd+nSRZvNZq211q1atarxWGVlZdXuV1Nd7+pqgFd15MgR3aFDh8pjNoTd64ErpY4CBUAFUK61HqiUagssBqKBo8BUrfUZR7zJXLgfZoC0wIVwe/379yc7O5sTJ06Qk5NDUFAQ4eHhPPLII6xbtw4PDw8yMzPJysoiPDy81mNprfnrX/962X6rVq2qtq53dTXALygsLGTy5Mm88sorBAQEOOinv1h9+sBHaq1zqzyfA6zUWs9VSs2xPn/MrtFZmYpK8fX2wNfb0xGHF0IYzJQpU1iyZAmnTp1i2rRpfPzxx+Tk5LB9+3a8vb2Jjo6utg74pRq636XKysqYPHkyd9xxB5MmTWrIj9QgjekDvxlYaH28EJjQ+HCqZylkJTNQhBAW06ZN47PPPmPJkiVMmTKF/Px8wsLC8Pb2ZvXq1Tbf9b2m/Wqq611dDXCtNXfddRexsbGV5WObiq0JXAM/K6W2K6XusW5rp7U+aX18CmhX3Y5KqXuUUolKqcScnJwGBWkqklWYQohf9e7dm4KCAiIjI4mIiOCOO+4gMTGRvn37smjRoovqdtempv1qqutdXQ3wDRs28OGHH7Jq1Sri4+OJj49n2bJlDvvZq7KpHrhSKlJrnamUCgOWA38CvtVaB1Z5zRmtdVBtx2loPfDXVh+ksKScx8bY9p8ihHAcqQfuWPWpB25TH7jWOtP6NVsp9TUwGMhSSkVorU8qpSKA7MaHXr0HRnZ11KGFEMKw6kzgSqlWgIfWusD6+HrgH8C3wAxgrvWrbRMvhRCiie3evbtyLvcFPj4+bNmyxUkR2YctLfB2wNdKqQuv/0Rr/aNSahvwuVLqLuAYMNVxYQohXInWGmtOMIS+ffuSnJzs7DDqZEuXdlV1JnCt9WEgrprtecDoep1NCGF4vr6+5OXlERwcbKgk7uq01uTl5eHr62vzPoaohSKEcB1RUVFkZGTQ0Flloma+vr5ERUXZ/HpJ4EKIevH29iYmJsbZYQgMUsxKCCHE5SSBCyGEQUkCF0IIg7JpJabdTqZUDpYph9UJAXJr+J6zSWwNI7E1jMTWMM05tk5a69BLNzZpAq+NUiqxuqWirkBiaxiJrWEktoZxx9ikC0UIIQxKErgQQhiUKyXwt5wdQC0ktoaR2BpGYmsYt4vNZfrAhRBC1I8rtcCFEELUgyRwIYQwKJdI4EqpMUqp/Uqpg9YbJLsMpdRRpdRupVSyUqr+txOybyzvKaWylVIpVba1VUotV0qlWb/WelekJo7tGaVUpvXaJSulxjkptg5KqdVKqb1KqT1KqYes251+7WqJzenXTinlq5TaqpTaaY3t79btMUqpLda/18VKqSa/YW0tsX2glDpS5brFN3VsVWL0VEolKaW+sz63/3XTWjv1H+AJHAI6Ay2AnUAvZ8dVJb6jQIiz47DGMhwYAKRU2fYfYI718Rzg3y4U2zPAn13gukUAA6yP/YEDQC9XuHa1xOb0awcooLX1sTewBRgCfA7cat3+BnCfC8X2AXCLs3/nrHHNBj4BvrM+t/t1c4UW+GDgoNb6sNa6FPgMyx3vxSW01uuA05dsvhlYaH28EJjQpEFZ1RCbS9Ban9Ra77A+LgBSgUhc4NrVEpvTaYtC61Nv6z8NjAKWWLc767rVFJtLUEpFATcC71ifKxxw3VwhgUcC6VWeZ+Aiv8BWGvhZKbVdKXWPs4OpRjut9Unr41NY7qDkSv6olNpl7WJxSvdOVUqpaKA/lhabS127S2IDF7h21m6AZCz3vF2O5dOySWtdbn2J0/5eL41Na33huj1vvW4vK6V8nBEb8ArwF8BsfR6MA66bKyRwV3e11noAMBZ4QCk13NkB1URbPpu5TCsEWAB0AeKBk8CLzgxGKdUa+BJ4WGt9tur3nH3tqonNJa6d1rpCax0PRGH5tNzTGXFU59LYlFJ9gMexxDgIaAs81tRxKaVuArK11tsdfS5XSOCZQIcqz6Os21yC1jrT+jUb+BrLL7EryVJKRQBYv2Y7OZ5KWuss6x+ZGXgbJ147pZQ3lgT5sdb6K+tml7h21cXmStfOGo8JWA1cCQQqpS7cDMbpf69VYhtj7ZLSWusS4H2cc92GAuOVUkexdAmPAubhgOvmCgl8G9DNOkLbArgVyx3vnU4p1Uop5X/hMXA9kFL7Xk3uW2CG9fEM4BsnxnKRC8nRaiJOunbW/sd3gVSt9UtVvuX0a1dTbK5w7ZRSoUqpQOvjlsB1WProVwO3WF/mrOtWXWz7qrwhKyx9zE1+3bTWj2uto7TW0Vjy2Sqt9R044ro5e6TWOiI7Dsvo+yHgCWfHUyWuzlhmxewE9jg7NuBTLB+ny7D0od2FpW9tJZAGrADaulBsHwK7gV1YkmWEk2K7Gkv3yC4g2fpvnCtcu1pic/q1A/oBSdYYUoC/Wbd3BrYCB4EvAB8Xim2V9bqlAB9hnanirH/ACH6dhWL36yZL6YUQwqBcoQtFCCFEA0gCF0IIg5IELoQQBiUJXAghDEoSuBBCGJQkcCGEMChJ4EIIYVD/H2Cv2abYq/XXAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# Test Set"],"metadata":{"id":"CKb0QIw72KxA"}},{"cell_type":"code","source":["test_loader, samples = get_val_loader(\n","    root_path + 'Split_images',\n","    lambda x: labels_df.loc[x].to_numpy(),\n","    2,\n","    test=True)"],"metadata":{"id":"8zABZkLoI-Gd","executionInfo":{"status":"ok","timestamp":1651694109707,"user_tz":420,"elapsed":38,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["cpkt = torch.load(root_path + 'outputs/' + train_folder_name + 'eval'+ eval_suffix + epoch + '/model_best.pth.tar')\n","backbone = cpkt['backbone']\n","linear = cpkt['linear']\n","best_epoch = cpkt['epoch']\n","print(cpkt['history_df']['val_acc1'][best_epoch])\n","print(best_epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKcqFCTxDjwW","executionInfo":{"status":"ok","timestamp":1651694110341,"user_tz":420,"elapsed":669,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"0c3ca057-797a-4d52-a014-b21eb1867b0f"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["71.875\n","31\n"]}]},{"cell_type":"code","source":["cpkt['history_df']['val_loss']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-gWDDIjYYu-","executionInfo":{"status":"ok","timestamp":1651694110342,"user_tz":420,"elapsed":18,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"f7ad22fa-4c17-4192-fa71-00627f1822ba"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1     0.602392\n","2     0.536525\n","3     0.506296\n","4     0.484643\n","5     0.467651\n","6     0.453867\n","7     0.444918\n","8     0.435694\n","9     0.433609\n","10    0.424915\n","11    0.423297\n","12    0.412362\n","13    0.419809\n","14    0.418625\n","15    0.411124\n","16    0.417358\n","17    0.413851\n","18    0.412123\n","19    0.417986\n","20    0.416252\n","21    0.416487\n","22    0.413584\n","23    0.414525\n","24    0.411176\n","25    0.421160\n","26    0.411555\n","27    0.418032\n","28    0.415575\n","29    0.420663\n","30    0.413475\n","31    0.410148\n","32         NaN\n","33         NaN\n","34         NaN\n","35         NaN\n","36         NaN\n","37         NaN\n","38         NaN\n","39         NaN\n","40         NaN\n","Name: val_loss, dtype: float64"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["backbone.eval()\n","linear.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25e8fnGS-ER6","executionInfo":{"status":"ok","timestamp":1651694110342,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"02bfcb45-17e4-4712-c1dd-4c3edbc5940e"},"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Normalize()\n","  (1): FullBatchNorm()\n","  (2): Linear(in_features=16, out_features=16, bias=True)\n","  (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU(inplace=True)\n","  (5): Linear(in_features=16, out_features=4, bias=True)\n",")"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["preds, names, labels = None, None, None\n","\n","with torch.no_grad():\n","    for indices, images, labels in test_loader:\n","        preds = linear(backbone(images)).softmax(dim=1).cpu().numpy()\n","        names = np.array([x.split('/')[-1] for x in samples])\n","        labels = labels.numpy()\n","\n","df = pd.DataFrame(index=names)\n","preds = [list(x) for x in preds]\n","labels = [list(x) for x in labels]\n","df['target'] = labels\n","df['pred'] = preds\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"S8tMVLC8fLGY","executionInfo":{"status":"ok","timestamp":1651694111489,"user_tz":420,"elapsed":1154,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"e4cd7aaf-56e9-4749-8c5a-6d077a983c95"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","\n","                                                                pred  \n","Day 14_Y8-4-L.png  [0.0029474956, 0.016235573, 0.116620004, 0.864...  \n","Day 7_Y8-4-L.png    [0.010107954, 0.06277336, 0.7772346, 0.14988399]  \n","Day 9_A8-1-R.png    [0.15976118, 0.24405041, 0.23128378, 0.36490467]  \n","Day 4_A8-1-R.png     [0.539062, 0.38756284, 0.05633946, 0.017035682]  \n","Day 12_A8-1-R.png   [0.13726066, 0.18123928, 0.12350234, 0.55799776]  "],"text/html":["\n","  <div id=\"df-75cd4fcd-e19d-44da-a21c-4b48e091e883\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.0029474956, 0.016235573, 0.116620004, 0.864...</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.010107954, 0.06277336, 0.7772346, 0.14988399]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.15976118, 0.24405041, 0.23128378, 0.36490467]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.539062, 0.38756284, 0.05633946, 0.017035682]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.13726066, 0.18123928, 0.12350234, 0.55799776]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75cd4fcd-e19d-44da-a21c-4b48e091e883')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-75cd4fcd-e19d-44da-a21c-4b48e091e883 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-75cd4fcd-e19d-44da-a21c-4b48e091e883');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["props = df.index.map(lambda x: re.match('^Day (\\d+)_(Y|A)8-(\\d)-(L|R)', x).groups())\n","df['Day'] = props.map(lambda x: int(x[0]))\n","df['Age'] = props.map(lambda x: x[1])\n","df['Mouse'] = props.map(lambda x: int(x[2]))\n","df['Side'] = props.map(lambda x: x[3])\n","df['True, Pred'] = (df.index.map(lambda x: [np.argmax(df.loc[x]['target']), np.argmax(df.loc[x]['pred'])]))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"id":"nhlvlmmh8xPN","executionInfo":{"status":"ok","timestamp":1651694111491,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"90d2fcb4-ca47-4817-ad82-3f4de1da2ba6"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","\n","                                                                pred  Day Age  \\\n","Day 14_Y8-4-L.png  [0.0029474956, 0.016235573, 0.116620004, 0.864...   14   Y   \n","Day 7_Y8-4-L.png    [0.010107954, 0.06277336, 0.7772346, 0.14988399]    7   Y   \n","Day 9_A8-1-R.png    [0.15976118, 0.24405041, 0.23128378, 0.36490467]    9   A   \n","Day 4_A8-1-R.png     [0.539062, 0.38756284, 0.05633946, 0.017035682]    4   A   \n","Day 12_A8-1-R.png   [0.13726066, 0.18123928, 0.12350234, 0.55799776]   12   A   \n","\n","                   Mouse Side True, Pred  \n","Day 14_Y8-4-L.png      4    L     [3, 3]  \n","Day 7_Y8-4-L.png       4    L     [3, 2]  \n","Day 9_A8-1-R.png       1    R     [1, 3]  \n","Day 4_A8-1-R.png       1    R     [1, 0]  \n","Day 12_A8-1-R.png      1    R     [2, 3]  "],"text/html":["\n","  <div id=\"df-a0e84086-9007-48c6-a358-15efa4ea361c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>Day</th>\n","      <th>Age</th>\n","      <th>Mouse</th>\n","      <th>Side</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.0029474956, 0.016235573, 0.116620004, 0.864...</td>\n","      <td>14</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.010107954, 0.06277336, 0.7772346, 0.14988399]</td>\n","      <td>7</td>\n","      <td>Y</td>\n","      <td>4</td>\n","      <td>L</td>\n","      <td>[3, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.15976118, 0.24405041, 0.23128378, 0.36490467]</td>\n","      <td>9</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.539062, 0.38756284, 0.05633946, 0.017035682]</td>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.13726066, 0.18123928, 0.12350234, 0.55799776]</td>\n","      <td>12</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>R</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0e84086-9007-48c6-a358-15efa4ea361c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a0e84086-9007-48c6-a358-15efa4ea361c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a0e84086-9007-48c6-a358-15efa4ea361c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["young_df = df[df.Age == 'Y']\n","young_df.sort_values('Day')[['target', 'pred', 'True, Pred']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"t7gfkMTdFq19","executionInfo":{"status":"ok","timestamp":1651694111492,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"4d46da2d-db44-4ae4-e7a7-345307a9b6f2"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_Y8-4-L.png                                [1.0, 0.0, 0.0, 0.0]   \n","Day 1_Y8-4-L.png                              [0.57, 0.43, 0.0, 0.0]   \n","Day 2_Y8-4-L.png                                [0.8, 0.2, 0.0, 0.0]   \n","Day 3_Y8-4-L.png                                [0.2, 0.8, 0.0, 0.0]   \n","Day 4_Y8-4-L.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 5_Y8-4-L.png                                [0.3, 0.5, 0.2, 0.0]   \n","Day 6_Y8-4-L.png                                [0.1, 0.3, 0.6, 0.0]   \n","Day 7_Y8-4-L.png    [0.0, 0.0, 0.454545454545455, 0.545454545454545]   \n","Day 8_Y8-4-L.png                                [0.0, 0.0, 0.6, 0.4]   \n","Day 9_Y8-4-L.png                                [0.0, 0.0, 0.6, 0.4]   \n","Day 10_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 11_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 12_Y8-4-L.png                               [0.0, 0.0, 0.1, 0.9]   \n","Day 13_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","Day 14_Y8-4-L.png  [0.0, 0.0, 0.0909090909090909, 0.909090909090909]   \n","Day 15_Y8-4-L.png                               [0.0, 0.0, 0.0, 1.0]   \n","\n","                                                                pred  \\\n","Day 0_Y8-4-L.png    [0.8410593, 0.1367193, 0.01808941, 0.0041319956]   \n","Day 1_Y8-4-L.png    [0.48430136, 0.25785705, 0.15632357, 0.10151802]   \n","Day 2_Y8-4-L.png   [0.68951416, 0.26232395, 0.042712938, 0.005448...   \n","Day 3_Y8-4-L.png   [0.47400144, 0.38529718, 0.089529365, 0.05117209]   \n","Day 4_Y8-4-L.png      [0.12686983, 0.32413757, 0.4670402, 0.0819524]   \n","Day 5_Y8-4-L.png    [0.24788265, 0.39639726, 0.30622745, 0.04949268]   \n","Day 6_Y8-4-L.png    [0.015269355, 0.07105045, 0.7594013, 0.15427889]   \n","Day 7_Y8-4-L.png    [0.010107954, 0.06277336, 0.7772346, 0.14988399]   \n","Day 8_Y8-4-L.png   [0.004684767, 0.024324415, 0.60114783, 0.36984...   \n","Day 9_Y8-4-L.png   [0.005250775, 0.038442712, 0.77487946, 0.18142...   \n","Day 10_Y8-4-L.png  [0.0039274697, 0.024462586, 0.42674235, 0.5448...   \n","Day 11_Y8-4-L.png  [0.0025155572, 0.009787307, 0.045887172, 0.941...   \n","Day 12_Y8-4-L.png  [0.0027553942, 0.014532903, 0.0858542, 0.8968575]   \n","Day 13_Y8-4-L.png  [0.003953661, 0.012449285, 0.07000323, 0.9135939]   \n","Day 14_Y8-4-L.png  [0.0029474956, 0.016235573, 0.116620004, 0.864...   \n","Day 15_Y8-4-L.png  [0.0038620522, 0.013753176, 0.07867562, 0.9037...   \n","\n","                  True, Pred  \n","Day 0_Y8-4-L.png      [0, 0]  \n","Day 1_Y8-4-L.png      [0, 0]  \n","Day 2_Y8-4-L.png      [0, 0]  \n","Day 3_Y8-4-L.png      [1, 0]  \n","Day 4_Y8-4-L.png      [1, 2]  \n","Day 5_Y8-4-L.png      [1, 1]  \n","Day 6_Y8-4-L.png      [2, 2]  \n","Day 7_Y8-4-L.png      [3, 2]  \n","Day 8_Y8-4-L.png      [2, 2]  \n","Day 9_Y8-4-L.png      [2, 2]  \n","Day 10_Y8-4-L.png     [3, 3]  \n","Day 11_Y8-4-L.png     [3, 3]  \n","Day 12_Y8-4-L.png     [3, 3]  \n","Day 13_Y8-4-L.png     [3, 3]  \n","Day 14_Y8-4-L.png     [3, 3]  \n","Day 15_Y8-4-L.png     [3, 3]  "],"text/html":["\n","  <div id=\"df-fec147b3-d33b-46c2-8237-84d3144e99d4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_Y8-4-L.png</th>\n","      <td>[1.0, 0.0, 0.0, 0.0]</td>\n","      <td>[0.8410593, 0.1367193, 0.01808941, 0.0041319956]</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_Y8-4-L.png</th>\n","      <td>[0.57, 0.43, 0.0, 0.0]</td>\n","      <td>[0.48430136, 0.25785705, 0.15632357, 0.10151802]</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_Y8-4-L.png</th>\n","      <td>[0.8, 0.2, 0.0, 0.0]</td>\n","      <td>[0.68951416, 0.26232395, 0.042712938, 0.005448...</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_Y8-4-L.png</th>\n","      <td>[0.2, 0.8, 0.0, 0.0]</td>\n","      <td>[0.47400144, 0.38529718, 0.089529365, 0.05117209]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_Y8-4-L.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.12686983, 0.32413757, 0.4670402, 0.0819524]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_Y8-4-L.png</th>\n","      <td>[0.3, 0.5, 0.2, 0.0]</td>\n","      <td>[0.24788265, 0.39639726, 0.30622745, 0.04949268]</td>\n","      <td>[1, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_Y8-4-L.png</th>\n","      <td>[0.1, 0.3, 0.6, 0.0]</td>\n","      <td>[0.015269355, 0.07105045, 0.7594013, 0.15427889]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.454545454545455, 0.545454545454545]</td>\n","      <td>[0.010107954, 0.06277336, 0.7772346, 0.14988399]</td>\n","      <td>[3, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.6, 0.4]</td>\n","      <td>[0.004684767, 0.024324415, 0.60114783, 0.36984...</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.6, 0.4]</td>\n","      <td>[0.005250775, 0.038442712, 0.77487946, 0.18142...</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[0.0039274697, 0.024462586, 0.42674235, 0.5448...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.0025155572, 0.009787307, 0.045887172, 0.941...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.1, 0.9]</td>\n","      <td>[0.0027553942, 0.014532903, 0.0858542, 0.8968575]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.003953661, 0.012449285, 0.07000323, 0.9135939]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0909090909090909, 0.909090909090909]</td>\n","      <td>[0.0029474956, 0.016235573, 0.116620004, 0.864...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_Y8-4-L.png</th>\n","      <td>[0.0, 0.0, 0.0, 1.0]</td>\n","      <td>[0.0038620522, 0.013753176, 0.07867562, 0.9037...</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fec147b3-d33b-46c2-8237-84d3144e99d4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fec147b3-d33b-46c2-8237-84d3144e99d4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fec147b3-d33b-46c2-8237-84d3144e99d4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["aged_df = df[df.Age == 'A']\n","aged_df.sort_values('Day')[['target', 'pred', 'True, Pred']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"R9VQDT9nHDUj","executionInfo":{"status":"ok","timestamp":1651694111493,"user_tz":420,"elapsed":24,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"a7f54cbe-e961-4d10-b932-bb8e72a20160"},"execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              target  \\\n","Day 0_A8-1-R.png                                [0.9, 0.1, 0.0, 0.0]   \n","Day 1_A8-1-R.png                                [0.1, 0.8, 0.1, 0.0]   \n","Day 2_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 3_A8-1-R.png                                [0.4, 0.5, 0.1, 0.0]   \n","Day 4_A8-1-R.png    [0.363636363636364, 0.636363636363636, 0.0, 0.0]   \n","Day 5_A8-1-R.png                                [0.2, 0.5, 0.3, 0.0]   \n","Day 6_A8-1-R.png                                [0.2, 0.7, 0.1, 0.0]   \n","Day 7_A8-1-R.png                                [0.1, 0.7, 0.1, 0.1]   \n","Day 8_A8-1-R.png                                [0.2, 0.6, 0.2, 0.0]   \n","Day 9_A8-1-R.png   [0.0909090909090909, 0.454545454545455, 0.4545...   \n","Day 10_A8-1-R.png                               [0.1, 0.4, 0.5, 0.0]   \n","Day 11_A8-1-R.png                               [0.0, 0.1, 0.8, 0.1]   \n","Day 12_A8-1-R.png                               [0.0, 0.2, 0.5, 0.3]   \n","Day 13_A8-1-R.png                               [0.0, 0.1, 0.5, 0.4]   \n","Day 14_A8-1-R.png                               [0.0, 0.1, 0.3, 0.6]   \n","Day 15_A8-1-R.png                               [0.0, 0.1, 0.6, 0.3]   \n","\n","                                                                pred  \\\n","Day 0_A8-1-R.png      [0.7202304, 0.2381088, 0.0317945, 0.009866328]   \n","Day 1_A8-1-R.png     [0.50558037, 0.3885423, 0.09046952, 0.01540781]   \n","Day 2_A8-1-R.png    [0.5775473, 0.29807308, 0.08068334, 0.043696243]   \n","Day 3_A8-1-R.png    [0.42498234, 0.4370161, 0.10519641, 0.032805104]   \n","Day 4_A8-1-R.png     [0.539062, 0.38756284, 0.05633946, 0.017035682]   \n","Day 5_A8-1-R.png     [0.081605904, 0.2752797, 0.12638704, 0.5167274]   \n","Day 6_A8-1-R.png     [0.04047332, 0.2547101, 0.54595345, 0.15886307]   \n","Day 7_A8-1-R.png    [0.08138886, 0.18430202, 0.32808727, 0.40622178]   \n","Day 8_A8-1-R.png    [0.020742822, 0.10390468, 0.7356814, 0.13967109]   \n","Day 9_A8-1-R.png    [0.15976118, 0.24405041, 0.23128378, 0.36490467]   \n","Day 10_A8-1-R.png  [0.015868254, 0.099262856, 0.7678309, 0.117037...   \n","Day 11_A8-1-R.png    [0.022902986, 0.080397874, 0.62067914, 0.27602]   \n","Day 12_A8-1-R.png   [0.13726066, 0.18123928, 0.12350234, 0.55799776]   \n","Day 13_A8-1-R.png   [0.026897088, 0.11719483, 0.5992057, 0.25670242]   \n","Day 14_A8-1-R.png  [0.019865751, 0.09360287, 0.35731417, 0.52921724]   \n","Day 15_A8-1-R.png  [0.0038045305, 0.010790544, 0.030650334, 0.954...   \n","\n","                  True, Pred  \n","Day 0_A8-1-R.png      [0, 0]  \n","Day 1_A8-1-R.png      [1, 0]  \n","Day 2_A8-1-R.png      [1, 0]  \n","Day 3_A8-1-R.png      [1, 1]  \n","Day 4_A8-1-R.png      [1, 0]  \n","Day 5_A8-1-R.png      [1, 3]  \n","Day 6_A8-1-R.png      [1, 2]  \n","Day 7_A8-1-R.png      [1, 3]  \n","Day 8_A8-1-R.png      [1, 2]  \n","Day 9_A8-1-R.png      [1, 3]  \n","Day 10_A8-1-R.png     [2, 2]  \n","Day 11_A8-1-R.png     [2, 2]  \n","Day 12_A8-1-R.png     [2, 3]  \n","Day 13_A8-1-R.png     [2, 2]  \n","Day 14_A8-1-R.png     [3, 3]  \n","Day 15_A8-1-R.png     [2, 3]  "],"text/html":["\n","  <div id=\"df-2c546e78-6580-4e9f-a2fb-211d0afa004d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>True, Pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Day 0_A8-1-R.png</th>\n","      <td>[0.9, 0.1, 0.0, 0.0]</td>\n","      <td>[0.7202304, 0.2381088, 0.0317945, 0.009866328]</td>\n","      <td>[0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 1_A8-1-R.png</th>\n","      <td>[0.1, 0.8, 0.1, 0.0]</td>\n","      <td>[0.50558037, 0.3885423, 0.09046952, 0.01540781]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 2_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.5775473, 0.29807308, 0.08068334, 0.043696243]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 3_A8-1-R.png</th>\n","      <td>[0.4, 0.5, 0.1, 0.0]</td>\n","      <td>[0.42498234, 0.4370161, 0.10519641, 0.032805104]</td>\n","      <td>[1, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 4_A8-1-R.png</th>\n","      <td>[0.363636363636364, 0.636363636363636, 0.0, 0.0]</td>\n","      <td>[0.539062, 0.38756284, 0.05633946, 0.017035682]</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 5_A8-1-R.png</th>\n","      <td>[0.2, 0.5, 0.3, 0.0]</td>\n","      <td>[0.081605904, 0.2752797, 0.12638704, 0.5167274]</td>\n","      <td>[1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 6_A8-1-R.png</th>\n","      <td>[0.2, 0.7, 0.1, 0.0]</td>\n","      <td>[0.04047332, 0.2547101, 0.54595345, 0.15886307]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 7_A8-1-R.png</th>\n","      <td>[0.1, 0.7, 0.1, 0.1]</td>\n","      <td>[0.08138886, 0.18430202, 0.32808727, 0.40622178]</td>\n","      <td>[1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 8_A8-1-R.png</th>\n","      <td>[0.2, 0.6, 0.2, 0.0]</td>\n","      <td>[0.020742822, 0.10390468, 0.7356814, 0.13967109]</td>\n","      <td>[1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 9_A8-1-R.png</th>\n","      <td>[0.0909090909090909, 0.454545454545455, 0.4545...</td>\n","      <td>[0.15976118, 0.24405041, 0.23128378, 0.36490467]</td>\n","      <td>[1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 10_A8-1-R.png</th>\n","      <td>[0.1, 0.4, 0.5, 0.0]</td>\n","      <td>[0.015868254, 0.099262856, 0.7678309, 0.117037...</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 11_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.8, 0.1]</td>\n","      <td>[0.022902986, 0.080397874, 0.62067914, 0.27602]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 12_A8-1-R.png</th>\n","      <td>[0.0, 0.2, 0.5, 0.3]</td>\n","      <td>[0.13726066, 0.18123928, 0.12350234, 0.55799776]</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 13_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.5, 0.4]</td>\n","      <td>[0.026897088, 0.11719483, 0.5992057, 0.25670242]</td>\n","      <td>[2, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 14_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.3, 0.6]</td>\n","      <td>[0.019865751, 0.09360287, 0.35731417, 0.52921724]</td>\n","      <td>[3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>Day 15_A8-1-R.png</th>\n","      <td>[0.0, 0.1, 0.6, 0.3]</td>\n","      <td>[0.0038045305, 0.010790544, 0.030650334, 0.954...</td>\n","      <td>[2, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c546e78-6580-4e9f-a2fb-211d0afa004d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2c546e78-6580-4e9f-a2fb-211d0afa004d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2c546e78-6580-4e9f-a2fb-211d0afa004d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["test_acc = df['True, Pred'].map(lambda x: x[0] == x[1]).to_numpy().mean()\n","test_acc"],"metadata":{"id":"1vlydbcZHgRL","executionInfo":{"status":"ok","timestamp":1651694111493,"user_tz":420,"elapsed":21,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22ad1138-635f-41a1-b21f-9c798eb1a341"},"execution_count":129,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.59375"]},"metadata":{},"execution_count":129}]},{"cell_type":"code","source":[""],"metadata":{"id":"hHOYI19EiGBv","executionInfo":{"status":"ok","timestamp":1651694111495,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":["# Some Cluster Analysis"],"metadata":{"id":"z1r-ZKrKArj2"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"yKXouvMNdcfF"}},{"cell_type":"code","source":["!pip install fuzzy-c-means\n","from fcmeans import FCM"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzdG_JAidlif","executionInfo":{"status":"ok","timestamp":1651694202734,"user_tz":420,"elapsed":10126,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"2a4d8540-0616-4998-bccb-dc1b305d79ae"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fuzzy-c-means\n","  Downloading fuzzy_c_means-1.6.3-py3-none-any.whl (9.1 kB)\n","Collecting pydantic<2.0.0,>=1.8.2\n","  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n","\u001b[K     |████████████████████████████████| 10.9 MB 10.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (1.21.6)\n","Collecting typer<0.4.0,>=0.3.2\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (4.2.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n","Installing collected packages: typer, pydantic, fuzzy-c-means\n","Successfully installed fuzzy-c-means-1.6.3 pydantic-1.9.0 typer-0.3.2\n"]}]},{"cell_type":"code","source":["def fuzzy_c_means(feats, nmb_clusters):\n","    feats = feats.numpy()\n","    \n","    fcm = FCM(n_clusters=nmb_clusters)\n","    fcm.fit(feats)\n","\n","    return fcm.predict(feats), fcm"],"metadata":{"id":"lWZVJ6YvdtF2","executionInfo":{"status":"ok","timestamp":1651694202735,"user_tz":420,"elapsed":14,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":131,"outputs":[]},{"cell_type":"markdown","source":["### Analysis"],"metadata":{"id":"3w9wsG1qdeEa"}},{"cell_type":"code","source":["data_path = root_path + 'Split_images'\n","weights_path = root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + epoch + '.pth'\n","\n","encoder = get_model('resnet', 16, weights_path)\n","train_val_loader, train_samples = get_val_loader(data_path, lambda x: labels_df.loc[x].to_numpy(), 0, train=True)"],"metadata":{"id":"pn2NYH1DaE8b","executionInfo":{"status":"ok","timestamp":1651694203510,"user_tz":420,"elapsed":786,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["encoder.eval()\n","\n","with torch.no_grad():\n","    for indices, images, labels in train_val_loader:\n","        embeddings = encoder(images)\n","\n","        _, fcm = fuzzy_c_means(embeddings, 4)\n","        preds = fcm.soft_predict(embeddings.numpy())\n","        labels = labels.numpy()\n","        x = 4\n"],"metadata":{"id":"BIlbNPTokWFO","executionInfo":{"status":"ok","timestamp":1651694233965,"user_tz":420,"elapsed":30458,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["single_preds = preds.argmax(axis=1)\n","single_labels = labels.argmax(axis=1)"],"metadata":{"id":"ImDAchhFqSgS","executionInfo":{"status":"ok","timestamp":1651694233968,"user_tz":420,"elapsed":25,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["pred_indices_0 = [i for (i, x) in enumerate(single_preds) if x == 0]\n","pred_indices_1 = [i for (i, x) in enumerate(single_preds) if x == 1]\n","pred_indices_2 = [i for (i, x) in enumerate(single_preds) if x == 2]\n","pred_indices_3 = [i for (i, x) in enumerate(single_preds) if x == 3]"],"metadata":{"id":"rTOobcZirIj3","executionInfo":{"status":"ok","timestamp":1651694233969,"user_tz":420,"elapsed":23,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["print(stats.mode(single_labels[pred_indices_0])[0][0])\n","print(stats.mode(single_labels[pred_indices_1])[0][0])\n","print(stats.mode(single_labels[pred_indices_2])[0][0])\n","print(stats.mode(single_labels[pred_indices_3])[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"804Y7tU3sNp_","executionInfo":{"status":"ok","timestamp":1651694233970,"user_tz":420,"elapsed":22,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"e748396e-238c-403b-9e42-9b72d7382ac1"},"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","0\n","3\n","1\n"]}]},{"cell_type":"code","source":["single_labels[pred_indices_1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDFh9Lb6sxZX","executionInfo":{"status":"ok","timestamp":1651691460615,"user_tz":420,"elapsed":183,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"61953d8d-9a54-487f-b250-614d2cb68d1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 3, 2, 1, 3, 0, 2, 2, 0, 0, 2, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1,\n","       1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 1, 2, 2, 2, 0, 1, 1])"]},"metadata":{},"execution_count":201}]},{"cell_type":"code","source":["single_labels[pred_indices_2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQiam4hquTAz","executionInfo":{"status":"ok","timestamp":1651691460616,"user_tz":420,"elapsed":7,"user":{"displayName":"Theophanis Fox","userId":"02229710404136063587"}},"outputId":"012da2ef-8a77-4cef-a8c8-410afa13d06b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n","       0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n","       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])"]},"metadata":{},"execution_count":202}]},{"cell_type":"code","source":["m = {2:0, 0:1, 3:2, 1:3}\n","preds = np.array([[p[m[0]], p[m[1]], p[m[2]], p[m[3]]] for p in preds])"],"metadata":{"id":"uGydNTeWucNe","executionInfo":{"status":"ok","timestamp":1651694255159,"user_tz":420,"elapsed":236,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["single_preds = preds.argmax(axis=1)"],"metadata":{"id":"x0chNz7cwHy1","executionInfo":{"status":"ok","timestamp":1651694256878,"user_tz":420,"elapsed":11,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["acc = (single_preds == single_labels).mean()\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_6a2nW-wI88","executionInfo":{"status":"ok","timestamp":1651694257176,"user_tz":420,"elapsed":7,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"ab89c229-4184-42d5-cfea-8249914586ef"},"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.675392670157068"]},"metadata":{},"execution_count":139}]},{"cell_type":"markdown","source":["# KNN Evaluation"],"metadata":{"id":"a7Wgnq2pySgP"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"Yz48LOQOfdIK"}},{"cell_type":"code","source":["!pip install faiss-gpu\n","import faiss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCa1aiWrfe2n","executionInfo":{"status":"ok","timestamp":1651694267326,"user_tz":420,"elapsed":3531,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"5d33723f-eb6e-4657-960d-dd822f576dc2"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.2)\n"]}]},{"cell_type":"markdown","source":["### Misc Functions"],"metadata":{"id":"dlJFZPYmzNQT"}},{"cell_type":"code","source":["def l2_normalize(x):\n","    return x / x.norm(2, dim=1, keepdim=True)"],"metadata":{"id":"cmvGyL_GyVGO","executionInfo":{"status":"ok","timestamp":1651694267329,"user_tz":420,"elapsed":28,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["def log(string, file):\n","    print(string)\n","    file.write(string + '\\n')"],"metadata":{"id":"UKLUR-fYR_aw","executionInfo":{"status":"ok","timestamp":1651694267330,"user_tz":420,"elapsed":27,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["def faiss_knn(feats_train, targets_train, feats_val, targets_val, k):\n","    feats_train = feats_train.numpy()\n","    targets_train = targets_train.numpy()\n","    feats_val = feats_val.numpy()\n","    targets_val = targets_val.numpy()\n","\n","    d = feats_train.shape[-1]\n","\n","    index = faiss.IndexFlatL2(d)  # build the index\n","    co = faiss.GpuMultipleClonerOptions()\n","    co.useFloat16 = True\n","    co.shard = True\n","    gpu_index = faiss.index_cpu_to_all_gpus(index, co)\n","    gpu_index.add(feats_train)\n","\n","    D, I = gpu_index.search(feats_val, k)\n","\n","    pred = np.zeros(I.shape[0], dtype=np.int)\n","    conf_mat = np.zeros((1000, 1000), dtype=np.int)\n","    for i in range(I.shape[0]):\n","        votes = list(Counter(targets_train[I[i]]).items())\n","        shuffle(votes)\n","        pred[i] = max(votes, key=lambda x: x[1])[0]\n","        conf_mat[targets_val[i], pred[i]] += 1\n","\n","    acc = 100.0 * (pred == targets_val).mean()\n","    assert acc == (100.0 * (np.trace(conf_mat) / np.sum(conf_mat)))\n","\n","    # per_cat_acc = 100.0 * (np.diag(conf_mat) / np.sum(conf_mat, axis=1))\n","    # sparse_cats = [58, 155, 356, 747, 865, 234, 268, 384, 385, 491, 498, 538, 646, 650, 726, 860, 887, 15, 170, 231]\n","    # s = ' '.join('{}'.format(c) for c in sparse_cats)\n","    # print('==> cats: {}'.format(s))\n","    # s = ' '.join('{:.1f}'.format(a) for a in per_cat_acc[sparse_cats])\n","    # print('==> acc/cat: {}'.format(s))\n","    # print('==> mean acc: {}'.format(per_cat_acc[sparse_cats].mean()))\n","\n","    return acc"],"metadata":{"id":"EQI68Ji_zc2O","executionInfo":{"status":"ok","timestamp":1651694267332,"user_tz":420,"elapsed":28,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["def get_feats(loader, model, print_freq):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    progress = ProgressMeter(\n","        len(loader),\n","        [batch_time],\n","        prefix='Test: ')\n","\n","    # switch to evaluate mode\n","    model.eval()\n","    feats, labels, indices, ptr = None, None, None, 0\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, (index, images, target) in enumerate(loader):\n","            images = images.cuda(non_blocking=True)\n","            cur_targets = target.cpu()\n","            cur_feats = model(images).cpu()\n","            cur_indices = index.cpu()\n","\n","            B, D = cur_feats.shape\n","            inds = torch.arange(B) + ptr\n","\n","            if not ptr:\n","                feats = torch.zeros((len(loader.dataset), D)).float()\n","                labels = torch.zeros(len(loader.dataset)).long()\n","                indices = torch.zeros(len(loader.dataset)).long()\n","\n","            feats.index_copy_(0, inds, cur_feats)\n","            labels.index_copy_(0, inds, cur_targets)\n","            indices.index_copy_(0, inds, cur_indices)\n","            ptr += B\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:\n","                print(progress.display(i))\n","\n","    return feats, labels, indices"],"metadata":{"id":"lWa_4FlEzsjb","executionInfo":{"status":"ok","timestamp":1651694267333,"user_tz":420,"elapsed":25,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["def subset_classes(dataset, num_classes=10):\n","    np.random.seed(1234)\n","    all_classes = sorted(dataset.class_to_idx.items(), key=lambda x: x[1])\n","    subset_classes = [all_classes[i] for i in np.random.permutation(len(all_classes))[:num_classes]]\n","    subset_classes = sorted(subset_classes, key=lambda x: x[1])\n","    dataset.classes_to_idx = {c: i for i, (c, _) in enumerate(subset_classes)}\n","    dataset.classes = [c for c, _ in subset_classes]\n","    orig_to_new_inds = {orig_ind: new_ind for new_ind, (_, orig_ind) in enumerate(subset_classes)}\n","    dataset.samples = [(p, orig_to_new_inds[i]) for p, i in dataset.samples if i in orig_to_new_inds]"],"metadata":{"id":"q3Th4r2zzwCr","executionInfo":{"status":"ok","timestamp":1651694267335,"user_tz":420,"elapsed":26,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":["### Main Function"],"metadata":{"id":"qZWaHcM6z1gg"}},{"cell_type":"code","source":["def main_worker(arch, output_dim, data_path, wts_path, output_path, batch_size, \n","                label_fn, num_workers=2, print_freq=10, k_s=range(1,21)):\n","\n","    start = time.time()\n","    # Get train/val loader \n","    # ---------------------------------------------------------------\n","    train_loader, _ = get_val_loader(data_path, label_fn, num_workers, batch_size, train=True)\n","    val_loader, _   = get_val_loader(data_path, label_fn, num_workers, batch_size)\n","    test_loader, _  = get_val_loader(data_path, label_fn, num_workers, batch_size, test=True)\n","\n","    # Create and load the model\n","    # If you want to evaluate your model, modify this part and load your model\n","    # ------------------------------------------------------------------------\n","    # MODIFY 'get_model' TO EVALUATE YOUR MODEL\n","    model = get_model(arch, output_dim, wts_path).cuda()\n","\n","    # ------------------------------------------------------------------------\n","    # Forward training samples throw the model and cache feats\n","    # ------------------------------------------------------------------------\n","    cudnn.benchmark = True\n","\n","    train_feats, train_labels, train_inds = get_feats(train_loader, model, print_freq)\n","\n","    val_feats, val_labels, val_inds = get_feats(val_loader, model, print_freq)\n","\n","    test_feats, test_labels, test_inds = get_feats(test_loader, model, print_freq)\n","\n","    # ------------------------------------------------------------------------\n","    # Calculate NN accuracy on validation set\n","    # ------------------------------------------------------------------------\n","\n","    # train_feats = l2_normalize(train_feats)\n","    # val_feats = l2_normalize(val_feats)\n","\n","    # mean = torch.mean(train_feats, dim=0)\n","    # std = torch.std(train_feats, dim=0)\n","\n","    # stdmean = std.mean()\n","    # train_feats = train_feats / stdmean\n","    # val_feats = val_feats / stdmean\n","\n","    # train_feats = train_feats / std\n","    # val_feats = val_feats / std\n","\n","    # train_feats = (train_feats - mean) / std\n","    # val_feats = (val_feats - mean) / std\n","\n","    # train_feats = train_feats - mean\n","    # val_feats = val_feats - mean\n","\n","    # train_feats = train_feats / TEMP\n","    # val_feats = val_feats / TEMP\n","\n","    train_feats = l2_normalize(train_feats)\n","    val_feats = l2_normalize(val_feats)\n","    test_feats = l2_normalize(test_feats)\n","\n","    output = open(output_path, 'w')\n","\n","    for k in k_s:\n","        log(f'k: {k}', output)\n","        val_acc  = faiss_knn(train_feats, train_labels, val_feats, val_labels, k)\n","        test_acc = faiss_knn(train_feats, train_labels, test_feats, test_labels, k)\n","        nn_time = time.time() - start\n","        log('=> time : {:.2f}s'.format(nn_time), output)\n","        log(' * Val_Acc {:.2f}'.format(val_acc), output)\n","        log(' * Test_Acc {:.2f}'.format(test_acc), output)\n","\n","    output.close()"],"metadata":{"id":"4mWQSYGXz3v1","executionInfo":{"status":"ok","timestamp":1651694270888,"user_tz":420,"elapsed":3,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"Iw2uh2AJzR-l"}},{"cell_type":"code","source":["for epoch in range(10, 201, 10):\n","    print(f\"Epoch: {epoch}\")\n","    main_worker(arch='resnet', \n","                output_dim=16, \n","                data_path=root_path + 'Split_images', \n","                wts_path=root_path + 'outputs/' + train_folder_name + 'ckpt_epoch_' + str(epoch) + '.pth', \n","                output_path=root_path + 'outputs/' + train_folder_name + 'eval' + eval_suffix + 'knn_' + str(epoch), \n","                batch_size=8, \n","                label_fn=lambda x: labels_map[x], \n","                num_workers=2, \n","                print_freq=10,\n","                k_s=[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmWFCVGxzTqg","executionInfo":{"status":"ok","timestamp":1651694355309,"user_tz":420,"elapsed":82577,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}},"outputId":"48efc113-c219-40eb-9ab1-6b4fab373e9c"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10\n","Test: [ 0/24]\tTime  0.259 ( 0.259)\n","Test: [10/24]\tTime  0.044 ( 0.060)\n","Test: [20/24]\tTime  0.039 ( 0.053)\n","Test: [0/4]\tTime  0.251 ( 0.251)\n","Test: [0/4]\tTime  0.232 ( 0.232)\n","k: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]},{"output_type":"stream","name":"stdout","text":["=> time : 4.02s\n"," * Val_Acc 53.12\n"," * Test_Acc 50.00\n","Epoch: 20\n","Test: [ 0/24]\tTime  0.434 ( 0.434)\n","Test: [10/24]\tTime  0.091 ( 0.099)\n","Test: [20/24]\tTime  0.049 ( 0.077)\n","Test: [0/4]\tTime  0.448 ( 0.448)\n","Test: [0/4]\tTime  0.439 ( 0.439)\n","k: 1\n","=> time : 5.98s\n"," * Val_Acc 56.25\n"," * Test_Acc 53.12\n","Epoch: 30\n","Test: [ 0/24]\tTime  0.419 ( 0.419)\n","Test: [10/24]\tTime  0.079 ( 0.091)\n","Test: [20/24]\tTime  0.123 ( 0.076)\n","Test: [0/4]\tTime  0.350 ( 0.350)\n","Test: [0/4]\tTime  0.376 ( 0.376)\n","k: 1\n","=> time : 5.54s\n"," * Val_Acc 59.38\n"," * Test_Acc 53.12\n","Epoch: 40\n","Test: [ 0/24]\tTime  0.409 ( 0.409)\n","Test: [10/24]\tTime  0.066 ( 0.094)\n","Test: [20/24]\tTime  0.033 ( 0.082)\n","Test: [0/4]\tTime  0.378 ( 0.378)\n","Test: [0/4]\tTime  0.420 ( 0.420)\n","k: 1\n","=> time : 5.94s\n"," * Val_Acc 75.00\n"," * Test_Acc 56.25\n","Epoch: 50\n","Test: [ 0/24]\tTime  0.360 ( 0.360)\n","Test: [10/24]\tTime  0.071 ( 0.093)\n","Test: [20/24]\tTime  0.114 ( 0.081)\n","Test: [0/4]\tTime  0.480 ( 0.480)\n","Test: [0/4]\tTime  0.389 ( 0.389)\n","k: 1\n","=> time : 6.75s\n"," * Val_Acc 68.75\n"," * Test_Acc 59.38\n","Epoch: 60\n","Test: [ 0/24]\tTime  0.230 ( 0.230)\n","Test: [10/24]\tTime  0.054 ( 0.061)\n","Test: [20/24]\tTime  0.025 ( 0.052)\n","Test: [0/4]\tTime  0.231 ( 0.231)\n","Test: [0/4]\tTime  0.213 ( 0.213)\n","k: 1\n","=> time : 4.40s\n"," * Val_Acc 65.62\n"," * Test_Acc 62.50\n","Epoch: 70\n","Test: [ 0/24]\tTime  0.224 ( 0.224)\n","Test: [10/24]\tTime  0.059 ( 0.059)\n","Test: [20/24]\tTime  0.039 ( 0.051)\n","Test: [0/4]\tTime  0.239 ( 0.239)\n","Test: [0/4]\tTime  0.220 ( 0.220)\n","k: 1\n","=> time : 3.51s\n"," * Val_Acc 65.62\n"," * Test_Acc 62.50\n","Epoch: 80\n","Test: [ 0/24]\tTime  0.233 ( 0.233)\n","Test: [10/24]\tTime  0.056 ( 0.060)\n","Test: [20/24]\tTime  0.045 ( 0.052)\n","Test: [0/4]\tTime  0.219 ( 0.219)\n","Test: [0/4]\tTime  0.223 ( 0.223)\n","k: 1\n","=> time : 3.58s\n"," * Val_Acc 75.00\n"," * Test_Acc 78.12\n","Epoch: 90\n","Test: [ 0/24]\tTime  0.230 ( 0.230)\n","Test: [10/24]\tTime  0.025 ( 0.059)\n","Test: [20/24]\tTime  0.025 ( 0.053)\n","Test: [0/4]\tTime  0.218 ( 0.218)\n","Test: [0/4]\tTime  0.230 ( 0.230)\n","k: 1\n","=> time : 3.60s\n"," * Val_Acc 71.88\n"," * Test_Acc 56.25\n","Epoch: 100\n","Test: [ 0/24]\tTime  0.237 ( 0.237)\n","Test: [10/24]\tTime  0.059 ( 0.062)\n","Test: [20/24]\tTime  0.056 ( 0.053)\n","Test: [0/4]\tTime  0.214 ( 0.214)\n","Test: [0/4]\tTime  0.232 ( 0.232)\n","k: 1\n","=> time : 3.36s\n"," * Val_Acc 71.88\n"," * Test_Acc 65.62\n","Epoch: 110\n","Test: [ 0/24]\tTime  0.230 ( 0.230)\n","Test: [10/24]\tTime  0.025 ( 0.063)\n","Test: [20/24]\tTime  0.025 ( 0.053)\n","Test: [0/4]\tTime  0.220 ( 0.220)\n","Test: [0/4]\tTime  0.236 ( 0.236)\n","k: 1\n","=> time : 3.60s\n"," * Val_Acc 71.88\n"," * Test_Acc 65.62\n","Epoch: 120\n","Test: [ 0/24]\tTime  0.367 ( 0.367)\n","Test: [10/24]\tTime  0.070 ( 0.074)\n","Test: [20/24]\tTime  0.047 ( 0.058)\n","Test: [0/4]\tTime  0.230 ( 0.230)\n","Test: [0/4]\tTime  0.253 ( 0.253)\n","k: 1\n","=> time : 3.70s\n"," * Val_Acc 71.88\n"," * Test_Acc 65.62\n","Epoch: 130\n","Test: [ 0/24]\tTime  0.250 ( 0.250)\n","Test: [10/24]\tTime  0.030 ( 0.059)\n","Test: [20/24]\tTime  0.026 ( 0.050)\n","Test: [0/4]\tTime  0.223 ( 0.223)\n","Test: [0/4]\tTime  0.234 ( 0.234)\n","k: 1\n","=> time : 3.55s\n"," * Val_Acc 65.62\n"," * Test_Acc 65.62\n","Epoch: 140\n","Test: [ 0/24]\tTime  0.228 ( 0.228)\n","Test: [10/24]\tTime  0.030 ( 0.060)\n","Test: [20/24]\tTime  0.025 ( 0.054)\n","Test: [0/4]\tTime  0.219 ( 0.219)\n","Test: [0/4]\tTime  0.228 ( 0.228)\n","k: 1\n","=> time : 3.61s\n"," * Val_Acc 71.88\n"," * Test_Acc 68.75\n","Epoch: 150\n","Test: [ 0/24]\tTime  0.225 ( 0.225)\n","Test: [10/24]\tTime  0.026 ( 0.060)\n","Test: [20/24]\tTime  0.026 ( 0.053)\n","Test: [0/4]\tTime  0.214 ( 0.214)\n","Test: [0/4]\tTime  0.236 ( 0.236)\n","k: 1\n","=> time : 3.57s\n"," * Val_Acc 68.75\n"," * Test_Acc 71.88\n","Epoch: 160\n","Test: [ 0/24]\tTime  0.225 ( 0.225)\n","Test: [10/24]\tTime  0.026 ( 0.061)\n","Test: [20/24]\tTime  0.025 ( 0.052)\n","Test: [0/4]\tTime  0.215 ( 0.215)\n","Test: [0/4]\tTime  0.246 ( 0.246)\n","k: 1\n","=> time : 3.58s\n"," * Val_Acc 62.50\n"," * Test_Acc 75.00\n","Epoch: 170\n","Test: [ 0/24]\tTime  0.252 ( 0.252)\n","Test: [10/24]\tTime  0.026 ( 0.060)\n","Test: [20/24]\tTime  0.025 ( 0.052)\n","Test: [0/4]\tTime  0.230 ( 0.230)\n","Test: [0/4]\tTime  0.224 ( 0.224)\n","k: 1\n","=> time : 3.60s\n"," * Val_Acc 68.75\n"," * Test_Acc 71.88\n","Epoch: 180\n","Test: [ 0/24]\tTime  0.237 ( 0.237)\n","Test: [10/24]\tTime  0.056 ( 0.060)\n","Test: [20/24]\tTime  0.059 ( 0.054)\n","Test: [0/4]\tTime  0.217 ( 0.217)\n","Test: [0/4]\tTime  0.253 ( 0.253)\n","k: 1\n","=> time : 3.60s\n"," * Val_Acc 62.50\n"," * Test_Acc 71.88\n","Epoch: 190\n","Test: [ 0/24]\tTime  0.231 ( 0.231)\n","Test: [10/24]\tTime  0.045 ( 0.061)\n","Test: [20/24]\tTime  0.054 ( 0.053)\n","Test: [0/4]\tTime  0.229 ( 0.229)\n","Test: [0/4]\tTime  0.271 ( 0.271)\n","k: 1\n","=> time : 3.64s\n"," * Val_Acc 65.62\n"," * Test_Acc 68.75\n","Epoch: 200\n","Test: [ 0/24]\tTime  0.224 ( 0.224)\n","Test: [10/24]\tTime  0.043 ( 0.059)\n","Test: [20/24]\tTime  0.057 ( 0.054)\n","Test: [0/4]\tTime  0.231 ( 0.231)\n","Test: [0/4]\tTime  0.223 ( 0.223)\n","k: 1\n","=> time : 3.37s\n"," * Val_Acc 75.00\n"," * Test_Acc 75.00\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0j-ob7dW5XJt","executionInfo":{"status":"ok","timestamp":1651692091724,"user_tz":420,"elapsed":16,"user":{"displayName":"Theophanis Fox","userId":"16001616154014161331"}}},"execution_count":46,"outputs":[]}]}